[{

    "course_id": 1,
    "points": 0,
    "chapter_id": null,
    "type": "document",
    "name": "DISEÑO DEL SISTEMA OPERATIVO UNIX ",
    "properties":
    {"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
        "content":
            "Un programa es un fichero ejecutable y un proceso es una instancia de un programa en ejecución. Muchos procesos pueden ser ejecutados simultáneamente en el sistema UNIX y varias instancias de un mismo programa pueden existir simultáneamente en el sistema.\nEl sistema operativo UNIX es un programa (a menudo denominado núcleo) que controla el hardware. Asimismo el núcleo administra (crea, destruye y controla) a los procesos y suministra varios servicios para ellos.\n\n![Nucleo](https://media.giphy.com/media/P07JtCEMQF9N6/giphy.gif)\n\nEl núcleo reside en memoria secundaria en un archivo denominado típicamente ```/vmmunix, /unix, /vmlinuz, etc...``` (dependiendo de la distribución de UNIX). Cuando la computadora arranca, carga el núcleo desde el disco a memoria principal usando un procedimiento especial de arranque. El núcleo inicializa el sistema y con el entorno para la ejecución de procesos. A continuación crea unos pocos procesos iniciales, los cuales a su vez crean otros procesos. Una vez cargado, el núcleo permanece en memoria principal hasta que el sistema se apaga.\n\nDesde un punto de vista más general, el sistema operativo UNIX no incluye solo el núcleo, sino también es el anfitrión para otros programas y utilidades (como los intérpretes de comandos (shells), editores, compiladores, etc.) que se suelen distribuir conjuntamente con el núcleo. El núcleo, sin embargo, es especial por varios motivos. En primer lugar es el único programa indispensable sin el cual ningún otro podría ejecutarse. Y en segundo lugar define la interfaz de programación del sistema. Mientras que distintos editores e intérpretes de comandos deben ejecutarse concurrentemente, solamente un único núcleo puede ser cargado a la vez.\n\n![Alt Text](https://media.giphy.com/media/elUGwgiPOdq7e/giphy.gif)\n\nPor un abuso del lenguaje, en muchas ocasiones cuando los usuarios utilizan el término sistema UNIX están englobando tanto al núcleo como a los programas y a las aplicaciones que le acompañan. En este libro se usaran de forma frecuente los términos “sistema UNIX”, núcleo o sistema para hacer referencia exclusivamente al núcleo del sistema operativo UNIX.\n\nEntre las principales características que han contribuido al éxito y popularidad de UNIX se encuentran:\n- Está escrito en C, que es un lenguaje de programación de alto nivel, lo que hace que UNIX sea fácil de leer, entender, modificar y utilizar en diferentes computadoras.\n- Posee una interfaz de usuario sencilla pero con muchas funcionalidades.\n- Suministra primitivas que posibilitan el escribir programas complejos a partir de otros más sencillos.\n- Utiliza un sistema de ficheros jerarquizado que posibilita su fácil mantenimiento y una eficiente implementación.\n- Utiliza un formato consistente para los archivos, lo que posibilita que los programas de aplicación sean relativamente fáciles de escribir.\n- Suministra una interfaz simple y consistente para los dispositivos periféricos.          - - Es un sistema multiusuario y multiproceso; cada usuario puede ejecutar varios procesos simultáneamente.\n- Oculta la arquitectura de la máquina al usuario, lo que simplifica la escritura de programas que pueden ser ejecutados sobre distintas implementaciones de hardware, es decir, son portables.\nDe acuerdo con las características anteriores, se puede afirmar que el sistema UNIX sigue una filosofía de simplicidad y consistencia.\n\nExisten diferentes distribuciones de UNIX, como por ejemplo: System V de AT&T (American Telephone & Telegraph), BSD (Berkeley Software Distribution) de la Universidad de California en Berkeley, OSF/1 de Open Sotfware Foundation, SunOS y Solaris de Sun Microsystems, etc. Además dentro de cada distribución existen diferentes versiones."
    }
},
    {
        "course_id": 1,
        "points": 0,
        "chapter_id": "1",
        "type": "document",
        "name": "Historia del sistema operativo ",
        "properties":
        {"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,"content":"### La Historia de Unix\n[![La historia de unix](http://img.youtube.com/vi/XS0WLu4SD6k/0.jpg)](http://www.youtube.com/watch?v=XS0WLu4SD6k \"La historia de Unix\")"
        }
    },
    {

        "course_id": 1,
        "points": 1,
        "chapter_id": "1",
        "type": "document",
        "name": "Arquitectura del sistema operativo UNIX",
        "properties":
        {"card": {"back": null, "front": null}, "quiz": {"question": null, "responses": [], "correctAnswer": [0]}, "content": "## Nivel de usuario\nEn el nivel de usuario se encuentran los programas de usuario y los programas demonio. Estos programas interaccionan con el núcleo haciendo uso de las llamadas al sistema. Los programas pueden invocar a las llamadas al sistema de dos formas:\nMediante el uso de librerías de llamadas al sistema. Las llamadas al sistema se realizan de forma semejante a como se realizan las llamadas a cualquier función de un programa escrito en lenguaje C. Existen librerías de llamadas al sistema que trasladan estas llamadas a las funciones primitivas necesarias que permiten acceder al núcleo. Estas librerías se enlazan por defecto con el código de los programas en tiempo de compilación, formando así parte del fichero objeto asociado al programa.\nForma directa. Los programas escritos en lenguaje ensamblador pueden invocar a las llamadas al sistema de forma directa sin usar una librería de llamadas al sistema\nAl invocar un proceso a una llamada al sistema se ejecuta una instrucción especial que es una interrupción software o trap que provoca la conmutación hardware al modo supervisor.\n## Nivel del núcleo\nEn este nivel se encuentran el subsistema de ficheros y el subsistema de control de procesos, que son los dos módulos más importantes del núcleo. El esquema de la AQUÍ VA UNA IMAGEN1-3 ofrece solamente una visión lógica útil del núcleo, en la práctica el comportamiento real del núcleo se desvía del modelo propuesto, puesto que algunos de los módulos interactúan con las operaciones internas de otros módulos.\nLa interfaz de llamadas al sistema representa la frontera entre los programas de usuario y el núcleo. Las llamadas al sistema pueden interactuar tanto con el subsistema de ficheros como con el subsistema de control de procesos. Asimismo el núcleo está en contacto con el hardware de la máquina a través de su módulo de control del hardware.\n### Subsistema de ficheros\nEl subsistema de ficheros se encarga de realizar todas las tareas del sistema asociadas a los ficheros: reserva espacio en memoria principal para las copias de los ficheros, administra el espacio libre del sistema de ficheros, controla el acceso a los ficheros, regula el intercambio de datos (lectura o escritura) entre los ficheros y los usuarios, etc.Los procesos interactúan con el subsistema de ficheros mediante una interfaz bien definido, que encapsula la visión que tiene el usuario del sistema de ficheros. Además esta interfaz especifica el comportamiento y la semántica de todas las llamadas al sistema pertinentes tales como: open (abre un fichero para la lectura o escritura), close (cierra un fichero), read (lee en un fichero), write (escribe en un fichero), stat (devuelve los atributos de un fichero), chown (cambia el propietario de un fichero), chmod (cambia los permisos de acceso al fichero), etc. La interfaz exporta al usuario un pequeño número de abstracciones tales como: ficheros, directorios, descriptores de ficheros y sistemas de ficheros.\nAsimismo dentro del subsistema de ficheros se encuentra la interfaz nodo-v/sfv que permite a UNIX soportar diferentes tipos de sistemas de ficheros tanto UNIX (s5fs, FFS, Ext4, ReiserFS, Btrfs, etc) como formatos de Windows, (FAT, NTFS). Esta interfaz será objeto de estudio en el Capítulo 8.\nEn UNIX hay diferentes tipos de ficheros: ordinarios (también denominados regulares o de datos), directorios, enlaces simbólicos, tuberías, ficheros de dispositivos (también denominados ficheros especiales), etc.\nLos ficheros ordinarios contienen bytes de datos organizados como un array lineal. Los directorios son ficheros que permiten dar una estructura jerárquica a los sistemas de ficheros de UNIX. Los enlaces simbólicos son ficheros que contienen el nombre de otro fichero. Las tuberías (sin nombre y ficheros FIFO (First In First Out)) son un mecanismo de comunicación que permite la transmisión de un flujo de datos no estructurados de tamaño fijo. Los ficheros de dispositivos permiten a los procesos comunicarse con los dispositivos periféricos (discos, CD-ROM, cintas, impresoras, terminales, redes, etc.)\nExisten dos tipos de ficheros de dispositivos: dispositivos modo bloque y dispositivos modo carácter, cada uno de ellos tiene asignado un tipo de fichero de dispositivo.\nEn los dispositivos modo bloque, el dispositivo contiene un array de bloques de tamaño fijo (generalmente un múltiplo de 512 bytes). La transferencia de datos entre el dispositivo y el núcleo, o viceversa, se realiza a través de un espacio en la memoria principal denominado caché de buffers de bloques que es gestionado por el núcleo. Esta caché está implementada por software y no debe confundirse con las memorias caché hardware que poseen muchas computadoras. El uso de esta caché permite regular el flujode datos lográndose así un incremento en la velocidad de transferencia de los datos. Ejemplos típicos de dispositivos modo bloque son los discos y las unidades de cinta.\nLos dispositivos modo carácter son aquellos dispositivos que no utilizan buffers de almacenamiento en memoria principal para regular el flujo de datos con el núcleo. En consecuencia las transferencias de datos se van a realizar a menor velocidad. Ejemplos típicos de dispositivos modo carácter son los terminales serie y las impresoras en línea. En los ficheros de dispositivos modo carácter la información no se organiza según una estructura concreta y es vista por el núcleo, o por el usuario, como una secuencia lineal de bytes.\nUn mismo dispositivo físico puede soportar los dos modos de acceso: bloque y carácter, de hecho esto suele ser habitual en el caso de los discos.\nLos módulos del núcleo que gestionan la comunicación con los dispositivos se denominan manejadores o drivers de dispositivos. Lo normal es que cada dispositivo tenga su manejador propio, aunque puede haber manejadores que controlen a toda una familia de dispositivos con características comunes (por ejemplo, el manejador que controla los terminales).\n ### Subsistema de control de procesos\nEl subsistema de control de procesos se encarga, entre otras, de las siguientes tareas: sincronización de procesos, comunicación entre procesos, administración de la memoria principal y planificación de procesos.\nEl subsistema de ficheros y el subsistema de control de procesos interactúan cuando se carga un fichero en memoria principal para su ejecución. El subsistema de procesos es el encargado de cargar los ficheros ejecutables en la memoria principal antes de ejecutarlos.\nAlgunas de las llamadas del sistema para control de procesos son: fork (crea un nuevo proceso), exec (ejecuta un programa), exit (finaliza la ejecución de un proceso), wait (sincroniza la ejecución de un proceso con la terminación de uno de sus procesos hijos), signal (controla la respuesta de un proceso ante un determinado tipo de señal), etc.El subsistema de control de procesos está formado por tres módulos: módulo de administración de memoria, módulo de planificación y módulo de comunicación entre procesos.\nEl módulo de administración o gestión de memoria controla la asignación de memoria principal a los procesos. Si en algún momento el sistema no dispone de suficiente memoria principal, el núcleo transferirá algunos procesos de la memoria principal a la secundaria. A esta operación se le denomina intercambio (swapping) y con ella se intenta garantizar que todos los procesos tengan la oportunidad de ser ejecutados\nEl módulo de planificación (scheduler) asigna el uso de la CPU a los procesos. Un proceso (A) se ejecutará hasta que voluntariamente ceda el uso de la CPU (por ejemplo al tener que esperar por un recurso ocupado) o hasta que el núcleo lo expropie debido a que su tiempo de utilización del procesador o cuanto haya expirado. En ese momento, el planificador seleccionará para ejecutar al proceso de mayor prioridad de planificación que se encuentre listo para ser ejecutado. El proceso (A) volverá a ser ejecutado cuando sea el proceso de mayor prioridad de planificación listo para ejecución.\nExisten diferentes formas de comunicación entre procesos, desde los mecanismos asíncronos de señalización de eventos (señales) hasta la transmisión síncrona de mensajes entre procesos.\n### Módulo de control del hardware\nFinalmente, el módulo de control del hardware es el responsable del manejo de las interrupciones y de la comunicación con el hardware de la máquina.\n\n![image](../../../storage/courseImages/estructura_unix_t1.png)", "code_url": null, "scriptAfter": false, "scriptPrevious": false}    },
    {
        "course_id": 1,
        "points": 1,
        "chapter_id": null,
        "type": "document",
        "name": "Servicios realizados por el núcleo",
        "properties":
        {"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
            "content":
                "Los principales servicios realizados por el núcleo son:\n- **Control de la ejecución** de los procesos posibilitando su creación, terminación o suspensión y comunicación.\n- **Planificación de los procesos** para su ejecución en la CPU. En UNIX los procesos comparten el uso de la CPU por ello el núcleo debe velar porque la utilización de la CPU por parte de todos los procesos se realice de una forma justa.\n- **Asignación de la memoria principal**. La memoria principal de una computadora es un recurso finito y muy valioso. Si el sistema posee en un cierto momento poca memoria principal libre, el núcleo liberará memoria escribiendo uno o varios procesos temporalmente en memoria secundaria (en un área de memoria predefinida denominada dispositivo de intercambio). Si el núcleo escribe un proceso entero en el dispositivo de intercambio, se dice que el sistema de gestión de memoria sigue una política de intercambio. Mientras que si escribe páginas de memoria asociadas al proceso en al dispositivo de intercambio, se dice que el sistema de gestión de memoria sigue una política de demanda de páginas.\n- **Protección del espacio de direcciones** de un proceso en ejecución. El núcleo protege el espacio de direcciones de un proceso de intromisiones externas por parte de otros procesos. No obstante, bajo ciertas condiciones un proceso puede compartir porciones de su espacio de direcciones con otros procesos.\n- **Asignación de memoria secundaria** para almacenamiento y recuperación eficiente de los datos de usuario. El núcleo asigna memoria secundaria para los ficheros de usuario, reclama el espacio no utilizado, estructura el sistema de ficheros de una forma entendible y protege a los ficheros de usuario de accesos ilegales.\\n- Regulación del acceso de los procesos a los dispositivos periféricos tales como terminales, unidades de disco, dispositivos en red, etc.\n- **Administración de archivos y dispositivos**.\n- **Tratamiento de las interrupciones y excepciones**.\n\n>Control de la ejecución\nPlanificación de los proceso\nAsignación de la memoria principal\nAsignación de memoria secundaria\nProtección del espacio de direcciones\nAdministración de archivos y dispositivos\nTratamiento de las interrupciones y excepciones"
        }
    },
    {

        "course_id": 1,
        "points": 1,
        "chapter_id": null,
        "type": "document",
        "name": "Modos de ejecución",
        "properties":
        {"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
            "content":
                "## Modo usuario y modo núcleo\nEl núcleo reside permanentemente en memoria principal así como el proceso actualmente en ejecución también denominado proceso actual (o partes del mismo, por lo menos). Cuando se compila un programa, el compilador genera un conjunto de direcciones de memoria asociadas al programa que representan las direcciones de las variables y de las estructuras de datos, o las direcciones de instrucciones como por ejemplo funciones. El compilador genera las direcciones para una máquina virtual considerando que ningún otro programa será ejecutado simultáneamente en la máquina física.\nCuando un programa se ejecuta en la máquina, el núcleo le asigna espacio en memoria principal, pero las direcciones virtuales generadas por el compilador no necesitan ser idénticas a las direcciones físicas que ocupan en la máquina. El núcleo se coordina con el hardware de la máquina para traducir las direcciones virtuales a direcciones físicas. Esta traducción depende de las capacidades del hardware de la máquina y en consecuencia las partes del sistema UNIX que se ocupan de la misma son dependientes de la máquina.\n\n![space gif](https://media.giphy.com/media/1imXktPlcuj9N8rBKN/giphy.gif)\n\nCon el objetivo de poder implementar una protección eficiente del espacio de direcciones de memoria asociado al núcleo y de los espacios de direcciones asociados a cada proceso, la ejecución de los procesos en un sistema UNIX está dividida en dos modos de ejecución: un modo de mayor privilegio denominado modo núcleo o supervisor y otro modo de menor privilegio denominado modo usuario.\nUn proceso ejecutándose en modo usuario sólo puede acceder a unas partes de su propio espacio de direcciones (código, datos y pila). Sin embargo, no puede acceder a otras partes de su propio espacio de direcciones, como aquellas reservadas para estructuras de datos asociadas al proceso usadas por el núcleo.\nTampoco puede acceder al espacio de direcciones de otros procesos o del mismo núcleo. De esta forma se evita una posible corrupción de los mismos.\\nPor otra parte, un proceso ejecutándose en modo núcleo puede acceder a su propio espacio de direcciones al completo y al espacio de direcciones del núcleo, pero no puede acceder al espacio de direcciones de otros procesos. Debe quedar claro que cuando se dice que un proceso se está ejecutando en modo núcleo, en realidad el que se está ejecutando es el núcleo pero en el nombre del proceso. Por ejemplo, cuando un proceso en modo usuario realiza una llamada al sistema está pidiendo al núcleo que realice en su nombre determinadas operaciones con el hardware de la máquina.\n\n![space gif](https://media.giphy.com/media/l2Jeg0gmDDkN7BErK/giphy.gif)\n\nEntre los principales casos que producen que un proceso ejecutándose en modo usuario pase a ejecutarse en modo núcleo se encuentran: las llamadas al sistema, las interrupciones (hardware o software) y las excepciones.\n## Tipos de procesos\nUNIX mantiene una jerarquía de procesos. Cada proceso hereda el \\\"usuario\\\" y \\\"grupo\\\" de su progenitor y el SO controla quien es el padre de cada proceso para controlar sus permisos de acceso.\nLos procesos en el sistema UNIX pueden ser de tres tipos: procesos de usuario, procesos demonio y procesos del núcleo o del sistema.\nLos procesos de usuario son aquellos procesos asociados a un determinado usuario. Se ejecutan en modo usuario excepto cuando realizan llamadas al sistema para acceder a los recursos del sistema, que pasan a ser ejecutados en modo núcleo.\nLos procesos demonio normalmente no están asociados a ningún usuario (administrativamente el usuario al que pertenecen es root). Al igual que los proceso de usuario, son ejecutados en modo usuario excepto cuando realizan llamadas al sistema que pasan a ser ejecutados en modo núcleo. Los procesos demonio realizan tareas periódicas relacionadas con la administración del sistema, como por ejemplo: la administración y control de redes, la ejecución de actividades dependientes del tiempo, la administración de trabajos en las impresoras en línea, etc. Y se distinguen por ser hijos del proceso init y no estar asociados a ningún terminal.\\nLos procesos del núcleo no están asociados a ningún usuario (pertenecen a root). Se ejecutan exclusivamente en modo núcleo. Son similares a los procesos demonio en el sentido de que realizan tareas de administración del sistema, como por ejemplo, el intercambio de procesos (proceso intercambiador) o de páginas (proceso ladrón de páginas) a memoria secundaria. Su principal ventaja respecto a los procesos demonio es que poseen un mayor control sobre sus prioridades de planificación puesto que su código es parte del núcleo y de hecho viven dentro de la memoria del núcleo. Por ello pueden acceder directamente a los algoritmos y estructuras de datos del núcleo sin hacer uso de las llamadas al sistema, en consecuencia son extremadamente potentes. Sin embargo noson tan flexibles como los procesos demonio, ya que para modificarlos se debe de recompilar el núcleo.\n## Interrupciones y Excepciones\nEl sistema UNIX permite al reloj del sistema, a los periféricos de E/S o a los terminales interrumpir a la CPU mientras se está ejecutando un proceso. Estos dispositivos usan el mecanismo de interrupciones para notificar al núcleo que se ha completado una operación de E/S o que se ha producido un cambio en su estado. Así, las interrupciones hardware son eventos asíncronos que ocurren entre la ejecución de dos instrucciones de un proceso y pueden estar asociadas a eventos totalmente ajenos a la ejecución del proceso actualmente en ejecución.\n\n![Interrupcion gif](https://media.giphy.com/media/U1UzNo1ximdZnBTlKL/giphy.gif)\n\nLas interrupciones software o traps, se producen al ejecutar ciertas instrucciones especiales y son tratadas de forma síncrona. Son utilizadas, por ejemplo, en las llamadas al sistema, en los cambios de contexto, en tareas de baja prioridad de planificación asociadas con el reloj del sistema, etc.\nLas excepciones hacen referencia a la aparición de eventos síncronos inesperados, típicamente errores, causados por la ejecución de un proceso, como por ejemplo, el acceso a una dirección de memoria ilegal, el rebose de la pila de usuario, el intento de ejecución de instrucciones privilegiadas, la realización de una división por cero, etc. Las excepciones se producen durante el transcurso de la ejecución de una instrucción.\nTanto las interrupciones (hardware o software) como las excepciones son tratadas en modo núcleo por determinadas rutinas del núcleo, no por procesos del núcleo.\nPuesto que existen diferentes eventos que pueden causar una interrupción, puede suceder que llegue una petición de interrupción mientras otra interrupción está siendo atendida. Por lo tanto, es necesario asignar a cada tipo de interrupción un determinado nivel de prioridad de interrupción (npi) o nivel de ejecución del procesador. De tal forma que las interrupciones de mayor npi tenga preferencia sobre las de menor npi. Por ejemplo, una interrupción del reloj de la máquina debe tener preferencia sobre una interrupción de un dispositivo de red, puesto que esta última requerirá un mayor tiempo de uso de la CPU, varios tics de reloj, para ser atendida.\n\n![Interrupcion gif](https://media.giphy.com/media/sFK74luzYFhzG/giphy.gif)\n\nEl npi se almacena en un campo del registro de estado del procesador. Las computadoras típicamente poseen un conjunto de instrucciones privilegiadas paracomparar y configurar el npi a un determinado valor. Además el núcleo también dispone de rutinas, típicamente implementadas como macros por motivos de eficiencia, para explícitamente comprobar o configurar el npi.\nCuando el núcleo se encuentra realizando ciertas actividades críticas para el correcto funcionamiento del sistema no debe atender ciertos tipos de interrupciones para evitar la corrupción de determinadas estructuras de datos. Para ello, fija el npi a un determinado valor. Así las interrupciones del mismo nivel o de niveles inferiores quedan enmascaradas o bloqueadas, por lo que sólo se atenderán las interrupciones de los niveles superiores.\nEl número de niveles de prioridad de interrupción permitidos depende de cada distribución de UNIX. Usualmente, el menor npi es 01.\n\n![Niveles de prioridad de interrupción típicos](app/courseImages/modos_ejecucion.png \"Niveles de prioridad de interrupción típicos\")\n\nse muestra un ejemplo de un conjunto de niveles de prioridad de interrupción o niveles de ejecución del procesador. Si el núcleo con el npi al valor asociado a los discos (se dice que se han enmascarado las interrupciones de los discos), entonces se estarán bloqueando todas las interrupciones excepto las interrupciones del reloj y las interrupciones asociadas a los errores de la máquina.\nPor otro lado, si el núcleo con el npi al valor asociado a las interrupciones software (se dice que se han enmascarado las interrupciones software), entonces todas los demás tipos de interrupciones estarán permitidas. Finalmente si el núcleo con el npi=0 todas las interrupciones estarán permitidas.\nEn algunas distribuciones el criterio es justamente el contrario, es decir, 0 está asociado al máximo npi."
        }
    },
    {

        "course_id": 1,
        "points": 1,
        "chapter_id": null,
        "type": "document",
        "name": "Estructura del sistema operativo UNIX",
        "properties":
        {"card": {"back": null, "front": null}, "quiz": {"question": null, "responses": [], "correctAnswer": [0]}, "content": "## Nivel de usuario\nEn el nivel de usuario se encuentran los programas de usuario y los programas demonio. Estos programas interaccionan con el núcleo haciendo uso de las llamadas al sistema. Los programas pueden invocar a las llamadas al sistema de dos formas:\nMediante el uso de librerías de llamadas al sistema. Las llamadas al sistema se realizan de forma semejante a como se realizan las llamadas a cualquier función de un programa escrito en lenguaje C. Existen librerías de llamadas al sistema que trasladan estas llamadas a las funciones primitivas necesarias que permiten acceder al núcleo. Estas librerías se enlazan por defecto con el código de los programas en tiempo de compilación, formando así parte del fichero objeto asociado al programa.\nForma directa. Los programas escritos en lenguaje ensamblador pueden invocar a las llamadas al sistema de forma directa sin usar una librería de llamadas al sistema\nAl invocar un proceso a una llamada al sistema se ejecuta una instrucción especial que es una interrupción software o trap que provoca la conmutación hardware al modo supervisor.\n ## Nivel del núcleo\nEn este nivel se encuentran el subsistema de ficheros y el subsistema de control de procesos, que son los dos módulos más importantes del núcleo. El esquema de la AQUÍ VA UNA IMAGEN1-3 ofrece solamente una visión lógica útil del núcleo, en la práctica el comportamiento real del núcleo se desvía del modelo propuesto, puesto que algunos de los módulos interactúan con las operaciones internas de otros módulos.\nLa interfaz de llamadas al sistema representa la frontera entre los programas de usuario y el núcleo. Las llamadas al sistema pueden interactuar tanto con el subsistema de ficheros como con el subsistema de control de procesos. Asimismo el núcleo está en contacto con el hardware de la máquina a través de su módulo de control del hardware.\n ###  Subsistema de ficheros\nEl subsistema de ficheros se encarga de realizar todas las tareas del sistema asociadas a los ficheros: reserva espacio en memoria principal para las copias de los ficheros, administra el espacio libre del sistema de ficheros, controla el acceso a los ficheros, regula el intercambio de datos (lectura o escritura) entre los ficheros y los usuarios, etc.Los procesos interactúan con el subsistema de ficheros mediante una interfaz bien definido, que encapsula la visión que tiene el usuario del sistema de ficheros. Además esta interfaz especifica el comportamiento y la semántica de todas las llamadas al sistema pertinentes tales como: open (abre un fichero para la lectura o escritura), close (cierra un fichero), read (lee en un fichero), write (escribe en un fichero), stat (devuelve los atributos de un fichero), chown (cambia el propietario de un fichero), chmod (cambia los permisos de acceso al fichero), etc. La interfaz exporta al usuario un pequeño número de abstracciones tales como: ficheros, directorios, descriptores de ficheros y sistemas de ficheros.\nAsimismo dentro del subsistema de ficheros se encuentra la interfaz nodo-v/sfv que permite a UNIX soportar diferentes tipos de sistemas de ficheros tanto UNIX (s5fs, FFS, Ext4, ReiserFS, Btrfs, etc) como formatos de Windows, (FAT, NTFS). Esta interfaz será objeto de estudio en el Capítulo 8.\nEn UNIX hay diferentes tipos de ficheros: ordinarios (también denominados regulares o de datos), directorios, enlaces simbólicos, tuberías, ficheros de dispositivos (también denominados ficheros especiales), etc.\nLos ficheros ordinarios contienen bytes de datos organizados como un array lineal. Los directorios son ficheros que permiten dar una estructura jerárquica a los sistemas de ficheros de UNIX. Los enlaces simbólicos son ficheros que contienen el nombre de otro fichero. Las tuberías (sin nombre y ficheros FIFO (First In First Out)) son un mecanismo de comunicación que permite la transmisión de un flujo de datos no estructurados de tamaño fijo. Los ficheros de dispositivos permiten a los procesos comunicarse con los dispositivos periféricos (discos, CD-ROM, cintas, impresoras, terminales, redes, etc.)\nExisten dos tipos de ficheros de dispositivos: dispositivos modo bloque y dispositivos modo carácter, cada uno de ellos tiene asignado un tipo de fichero de dispositivo.\nEn los dispositivos modo bloque, el dispositivo contiene un array de bloques de tamaño fijo (generalmente un múltiplo de 512 bytes). La transferencia de datos entre el dispositivo y el núcleo, o viceversa, se realiza a través de un espacio en la memoria principal denominado caché de buffers de bloques que es gestionado por el núcleo. Esta caché está implementada por software y no debe confundirse con las memorias caché hardware que poseen muchas computadoras. El uso de esta caché permite regular el flujode datos lográndose así un incremento en la velocidad de transferencia de los datos. Ejemplos típicos de dispositivos modo bloque son los discos y las unidades de cinta.\nLos dispositivos modo carácter son aquellos dispositivos que no utilizan buffers de almacenamiento en memoria principal para regular el flujo de datos con el núcleo. En consecuencia las transferencias de datos se van a realizar a menor velocidad. Ejemplos típicos de dispositivos modo carácter son los terminales serie y las impresoras en línea. En los ficheros de dispositivos modo carácter la información no se organiza según una estructura concreta y es vista por el núcleo, o por el usuario, como una secuencia lineal de bytes.\nUn mismo dispositivo físico puede soportar los dos modos de acceso: bloque y carácter, de hecho esto suele ser habitual en el caso de los discos.\nLos módulos del núcleo que gestionan la comunicación con los dispositivos se denominan manejadores o drivers de dispositivos. Lo normal es que cada dispositivo tenga su manejador propio, aunque puede haber manejadores que controlen a toda una familia de dispositivos con características comunes (por ejemplo, el manejador que controla los terminales).\n ###  Subsistema de control de procesos\nEl subsistema de control de procesos se encarga, entre otras, de las siguientes tareas: sincronización de procesos, comunicación entre procesos, administración de la memoria principal y planificación de procesos.\nEl subsistema de ficheros y el subsistema de control de procesos interactúan cuando se carga un fichero en memoria principal para su ejecución. El subsistema de procesos es el encargado de cargar los ficheros ejecutables en la memoria principal antes de ejecutarlos.\nAlgunas de las llamadas del sistema para control de procesos son: fork (crea un nuevo proceso), exec (ejecuta un programa), exit (finaliza la ejecución de un proceso), wait (sincroniza la ejecución de un proceso con la terminación de uno de sus procesos hijos), signal (controla la respuesta de un proceso ante un determinado tipo de señal), etc.El subsistema de control de procesos está formado por tres módulos: módulo de administración de memoria, módulo de planificación y módulo de comunicación entre procesos.\nEl módulo de administración o gestión de memoria controla la asignación de memoria principal a los procesos. Si en algún momento el sistema no dispone de suficiente memoria principal, el núcleo transferirá algunos procesos de la memoria principal a la secundaria. A esta operación se le denomina intercambio (swapping) y con ella se intenta garantizar que todos los procesos tengan la oportunidad de ser ejecutados\nEl módulo de planificación (scheduler) asigna el uso de la CPU a los procesos. Un proceso (A) se ejecutará hasta que voluntariamente ceda el uso de la CPU (por ejemplo al tener que esperar por un recurso ocupado) o hasta que el núcleo lo expropie debido a que su tiempo de utilización del procesador o cuanto haya expirado. En ese momento, el planificador seleccionará para ejecutar al proceso de mayor prioridad de planificación que se encuentre listo para ser ejecutado. El proceso (A) volverá a ser ejecutado cuando sea el proceso de mayor prioridad de planificación listo para ejecución.\nExisten diferentes formas de comunicación entre procesos, desde los mecanismos asíncronos de señalización de eventos (señales) hasta la transmisión síncrona de mensajes entre procesos.\n ###  Módulo de control del hardware\nFinalmente, el módulo de control del hardware es el responsable del manejo de las interrupciones y de la comunicación con el hardware de la máquina.\n\n![image](../../../storage/courseImages/estructura_unix_t1.png)", "code_url": null, "scriptAfter": false, "scriptPrevious": false}    },
    {

        "course_id": 1,
        "points": 1,
        "chapter_id": null,
        "type": "document",
        "name": "La interfaz de usuario para el sistema de ficheros ",
        "properties":
        {"card": {"back": null, "front": null}, "quiz": {"question": null, "responses": [], "correctAnswer": [0]}, "content": "## Ficheros y directorios\nUn fichero es un contenedor permanente de datos. Un fichero permite tanto el acceso secuencial como el acceso aleatorio a sus datos. El núcleo suministra al usuario varias operaciones de control para nombrar, organizar y controlar el acceso a los ficheros. El núcleo no interpreta el contenido o la estructura de los ficheros, simplemente considera que un fichero es una colección de bytes. Además posibilita el acceso a los contenidos del fichero mediante flujos de bytes.", "code_url": null, "scriptAfter": false, "scriptPrevious": false}
    },
    {
        "course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "code",
        "name": "La interfaz de usuario para el sistema de ficheros 2",
        "properties": {
            "card": {
                "back": null,
                "front": null
            },
            "quiz": {
                "question": null,
                "responses": [],
                "correctAnswer": [
                    [
                        [
                            [
                                0
                            ]
                        ]
                    ]
                ]
            },
            "content": "Sea un archivo en c llamado ```ejemplo_4.c``` en su carpeta.\nSi el programa se compila con el nombre programa ```gcc ejemplo_4.c -o programa```, al ejecutarlo \n```\n$ ./programa\n```\ncreará un archivo de nombre ```fichero``` pasando como modo el valor 0777 lo que indica que los permisos serán “como máximo” de lectura, escritura y ejecución para el propietario, el grupo y otros.\n¿Qué permisos tendrá el fichero creado? Depende del usuario que lo ejecute.\nUn usuario normal suele tiene una máscara ```umask=0002``` que puede comprobar del siguiente modo:\n```\n$ umask\n0002\n```\nSupongamos que ese usuario ejecuta el programa, entonces los permisos del fichero creado son los siguientes:\n\n```\n$ ls -l fichero\n-rwxrwxr-x 1 sistemas sistemas 0 nov 29 19:09 fichero\n```\nEsto es, los permisos son ```0775 (~0002 & 0777 = 0775)```. Para verlo con mayor claridad es conveniente pasarlo a binario:\n```\nUmask = 000 000 010 \nModo = 111 111 111 \nModo efectivo = 111 111 101 \n```\nDe este modo, el 1 en el bit asociado a los permisos de escritura para otros usuarios de ```umask```, impide que establezcan permisos de escritura para el fichero recién creado. El usuario ```root```, por otra parte tiene un valor de umask más restrictivo: \n```\n$ umask\n0022\n```\nDe tal modo que si ejecuta él dicho programa no se establecen permisos de escritura ni para el grupo ni para otros usuarios: \n```\n$ ./programa\nls -l fichero\n-rwxr-xr-x 1 root root 0\n```",
            "code_url": "Ejemplo_1-4.c",
            "scriptAfter": "ls | grep -q fichero  && echo true || echo false",
            "scriptPrevious": "cp ../ejemplos/ejemplo_4.c ejemplo_4.c"
        }
    },
    {

        "course_id": 1,
        "points": 1,
        "chapter_id": null,
        "type": "document",
        "name": "La interfaz de usuario para el sistema de ficheros 3",
        "properties":
        {"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
            "content": "###  Lectura y escritura en un fichero\nLa llamada al sistema read permite leer en un fichero. Su sintaxis es:\n```\nnread=read(fd,buffer,nbytes);\n```\ndonde ```fd``` es el descriptor de fichero, ```buffer``` es el array de caracteres dónde se almacenarán los datos que se lean en el fichero y ```nbytes``` es el número de bytes que se desea leer. Si la llamada al sistema se ejecuta con éxito en nread se almacenan el número de bytes transferidos. En caso de error en nread se almacena el valor -1. Cuando se intenta leer más allá del final del fichero, read devuelve el valor 0.\nEl núcleo lee datos desde un fichero asociado con ```fd```, comenzando en la posición indicada por el puntero de lectura/escritura almacenado en el objeto de fichero abierto. Puede leer menos bytes que nbytes si alcanza el final del fichero o, en el caso de los ficheros FIFO o de los ficheros de dispositivos, si no hay suficientes datos disponibles. Bajo ninguna circunstancia el núcleo transmitirá más que ```nbytes``` bytes. Es responsabilidad del usuario asegurarse que ```buffer``` sea suficientemente grande para almacenar los ```nbytes``` bytes de datos. La llamada ```read``` también avanza el puntero de lectura/escritura en ```nread``` bytes para que la siguiente operación de lectura o de escritura comience donde la última operación ha terminado.\nLa llamada al sistema write permite escribir en un fichero. Su sintaxis es muy similar a la de read:\n```\nnwrite=write(fd,buffer,nbytes);\n```\ndonde ```fd``` es el descriptor de fichero, ```buffer``` es el array de caracteres donde se encuentran almacenados los datos que se van a escribir en el fichero y ```nbytes``` es el número de bytes que se desea escribir. Si la llamada al sistema se ejecuta con éxito en ```nwrite``` se almacenan el número de bytes escritos. En caso de error en ```nwrite``` se almacena el valor -1."
        }
    },
    {

        "course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "code",
        "name": "La interfaz de usuario para el sistema de ficheros 4",
        "properties":
        {"card": {"back": null, "front": null}, "quiz": {"question": null, "responses": [], "correctAnswer": [[[0]]]}, "content": "Hemos copiado un archivo en c llamado ```ejemplo_4.c``` en su carpeta.\nSi el programa se compila con el nombre programa ```gcc ejemplo_4.c -o programa```, al ejecutarlo \n```\n$ ./programa\n```\ncreará un archivo de nombre ```fichero``` pasando como modo el valor 0777 lo que indica que los permisos serán “como máximo” de lectura, escritura y ejecución para el propietario, el grupo y otros.\n¿Qué permisos tendrá el fichero creado? Depende del usuario que lo ejecute.\nUn usuario normal suele tiene una máscara ```umask=0002``` que puede comprobar del siguiente modo:\n```\n$ umask\n0002\n```\nSupongamos que ese usuario ejecuta el programa, entonces los permisos del fichero creado son los siguientes:\n\n```\n$ ls -l fichero\n-rwxrwxr-x 1 sistemas sistemas 0 nov 29 19:09 fichero\n```\nEsto es, los permisos son ```0775 (~0002 & 0777 = 0775)```. Para verlo con mayor claridad es conveniente pasarlo a binario:\n```\nUmask = 000 000 010 \nModo = 111 111 111 \nModo efectivo = 111 111 101 \n```\nDe este modo, el 1 en el bit asociado a los permisos de escritura para otros usuarios de ```umask```, impide que establezcan permisos de escritura para el fichero recién creado. El usuario ```root```, por otra parte tiene un valor de umask más restrictivo: \n```\n$ umask\n0022\n```\nDe tal modo que si ejecuta él dicho programa no se establecen permisos de escritura ni para el grupo ni para otros usuarios: \n```\n$ ./programa\nls -l fichero\n-rwxr-xr-x 1 root root 0\n```", "code_url": "ejemplo_4.c", "scriptAfter": "ls | grep -q fichero  && echo true || echo false", "scriptPrevious": "cp ../ejemplos_c/ejemplo_4.c ejemplo_4.c"}
    },
    {

        "course_id": 1,
        "points": 1,
        "chapter_id": null,
        "type": "document",
        "name": "La interfaz de usuario para el sistema de ficheros 5",
        "properties":
        {
            "content":
                "### Acceso aleatorio a un fichero\nUNIX permite realizar tanto accesos secuenciales como accesos aleatorios a un fichero. El patrón de acceso por defecto es secuencial. El núcleo mantiene un puntero de lectura/escritura al fichero, que es inicializado a cero cuando un proceso abre por primera vez un fichero. La llamada al sistema lseek permite realizar accesos aleatorios mediante la configuración del puntero de lectura/escritura a un valor especifico. Su sintaxis es:\n```sh\nresultado=lseek(fd,offset,origen);\n```\ndonde ```fd``` es el descriptor del fichero, ```offset``` es el número de bytes que se va desplazar el puntero y origen es la posición desde donde se va desplazar el puntero, que puede tomar los siguientes valores constantes definidos en el fichero de cabecera\n```<stdio.h>```:\n```SEEK_SET```El puntero avanza offset bytes con respecto al inicio del fichero. El valor de esta constante es 0.\n```SEEK_CUR``` El puntero avanza offset bytes con respecto a su posición actual. El valor de esta constante es 1.\n```SEEK_END``` El puntero avanza offset bytes con respecto al final del fichero. El valor de esta constante es 2.\nSi ```offset``` es un número positivo, los avances deben entenderse en su sentido natural; es decir, desde el inicio del fichero hacia el final del mismo. Sin embargo, también se puede conseguir que el puntero retroceda pasándole a ```lseek``` un desplazamiento negativo.\nSi la llamada se ejecuta con éxito en resultado se almacena la posición que ha tomado el puntero de lectura/escritura, medida en bytes, con respecto al inicio del fichero. En caso de error en ```resultado``` se almacena el valor -1."
        }
    },
    {

        "course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "code",
        "name": "La interfaz de usuario para el sistema de ficheros 6",
        "properties":
        {"card": {"back": null, "front": null}, "quiz": {"question": null, "responses": [], "correctAnswer": [[[[0]]]]}, "content": "UNIX permite realizar tanto accesos secuenciales como accesos aleatorios a un fichero. El patrón de acceso por defecto es secuencial. El núcleo mantiene un puntero de lectura/escritura al fichero, que es inicializado a cero cuando un proceso abre por primera vez un fichero. La llamada al sistema `lseek` permite realizar accesos aleatorios mediante la configuración del puntero de lectura/escritura a un valor especifico. Su sintaxis es:\n    \n```\nresultado=lseek(fd,offset,origen);\n```\ndonde `fd` es el descriptor del fichero, `offset` es el número de bytes que se va desplazar el puntero y origen es la posición desde donde se va desplazar el puntero, que puede tomar los siguientes valores constantes definidos en el fichero de cabecera `<stdio.h>:`\n**SEEK_SET**. El puntero avanza offset bytes con respecto al inicio del fichero. El valor de esta constante es 0.\n**SEEK_CUR.** El puntero avanza offset bytes con respecto a su posición actual. El valor de esta constante es 1.\n**SEEK_END**. El puntero avanza offset bytes con respecto al final del fichero. El valor de esta constante es 2.\nSi `offset` es un número positivo, los avances deben entenderse en su sentido natural; es decir, desde el inicio del fichero hacia el final del mismo. Sin embargo, también se puede conseguir que el puntero retroceda pasándole a `lseek` un desplazamiento negativo.\nSi la llamada se ejecuta con éxito en `resultado` se almacena la posición que ha tomado el puntero de lectura/escritura, medida en bytes, con respecto al inicio del fichero. En caso de error en `resultado` se almacena el valor -1.\n\nConsidérese el siguiente programa escrito en C que permite visualizar una determinada línea de un fichero supuesto que la longitud de las líneas de ese fichero es de 41 caracteres.\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <fcntl.h>\n#include <unistd.h>\n#define LL 41\nint main(int np, char* a[])\n   {\n   int b, id, h;\n   char alm[LL+1];\n   if\n(np==3)\n{\nb=atoi(a[2]);\nid=open(a[1],O_RDWR);\nif ( (id!=-1) && (lseek(id,(b-1)*LL,0)!=-1)\n              && (read(id,alm,LL)>0) )\n{\nprintf(\"\\n\");\nfor(h=0;h<LL;h=h+1) printf(\"%c\",alm[h]);\n printf(\"\\n\");\n}\nelse\n           printf(\"\\nError\\n\");\n} else\nexit(1);\n```\nSupóngase que el ejecutable que resulta de compilar este programa se llama exlseek y que es invocado desde la línea de órdenes del terminal de la siguiente forma:\n     \n```\n$ exlseek errores.dat 3\n```\n\nPuesto que la definición hecha de main permite pasar parámetros al ejecutable, en primer lugar [1] se comprueba que la invocación del programa se ha realizado con tres parámetros (recordar que el nombre del ejecutable se considera un parámetro más). En caso negativo se invoca [9] a la llamada al sistema `exit` para terminar el programa.\nEn caso positivo, en primer lugar [2] se ejecuta la función de librería `atoi` para convertir el número de línea 3 introducido como parámetro de main de tipo carácter a tipo entero. A continuación se invoca [3] a la llamada al sistema open para abrir con permisos de lectura y escritura el fichero errores.dat pasado como argumento de `main`. Acto seguido [4], se comprueba si la llamada `open` se ha ejecutado con éxito. Recuérdese que en dicho caso en la variable `id` se almacena el descriptor del fichero que es un número entero distinto de -1. También se invoca a la llamada al sistema `lseek` para posicionar el puntero de lectura/escritura al principio de la tercera línea del fichero. Asimismo se comprueba si durante la ejecución de `lseek` se ha producido algún error. Además se invoca a la llamada al sistema read para leer dicha línea del fichero y almacenarla en la variable alm. También se comprueba si dicha llamada ha logrado leer la línea pedida. Si alguna de las comprobaciones anteriores da un resultado negativo entonces [8] se imprime por pantalla el mensaje\n```\nError\n```\ny el programa finaliza.\nSi las tres comprobaciones realizadas en [4] son positivas se muestra por pantalla: un salto de línea [5], la línea pedida escribiéndola carácter a carácter a través de un bucle for [6] y otro salto de línea [7]. Luego en pantalla aparece\n     \n```\nMensaje C: Violación del segmento.......\n```\ny el programa finaliza.", "code_url": "ejemplo_4.c", "scriptAfter": null, "scriptPrevious": "cp ../ejemplos/exlseek.c exlseek.c"}    },
    {
        "course_id": 1,
        "points": 1,
        "chapter_id": null,
        "type": "document",
        "name": "Librería estándar de funciones de entrada/salida",
        "properties":
        {"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
            "content":
                "La librería estándar de funciones de entrada/salida, que forma parte de la definición del ANSI C, hace uso de las llamadas al sistema para presentar una interfaz de alto nivel que permite al programador trabajar con los ficheros desde un punto de vista más abstracto.\nPor otra parte, con esta librería cada acceso al disco se gestiona de una forma más eficiente, ya que las funciones manejan memorias intermedias para almacenar los datos y se espera hasta que estas memorias están llenas antes de transferirlas al disco o a la caché de buffers de bloques de disco.\nSe considera que un fichero es un flujo de bytes o flujo de datos (stream) cuya información de control se encuentra almacenada en una estructura predefinida de tipo ```FILE```. La definición de este tipo de estructura así como los prototipos de las funciones de entrada/salida se encuentran en el fichero de cabecera ```<stdio.h>```\nA esta librería pertenecen las funciones de entrada/salida (```getchar, putchar, scanf, printf, gets y puts```) descritas en el Capítulo 1. Otras funciones importantes pertenecientes a esta librería son: ```fopen, fread, fwrite, fclose, feof, fgets, fgetc, fputs, fputc, fscanf y fprintf.```\nAlgunas de las constantes más importantes definidas en esta librería son: ```SEEK_SET, SEEK_CUR, SEEK_END y EOF.``` Por su parte, la constante ```EOF``` cuyo valor es -1 se utiliza como valor de retorno de algunas funciones para señalar que se ha alcanzado el final de un fichero."
        }
    },
    {

        "course_id": 1,
        "points": 1,
        "chapter_id": null,
        "type": "document",
        "name": "Origen del término proceso demonio",
        "properties":
        {"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
            "content":
            "El término proceso demonio o demonio (daemon) fue acuñado por los programadores del proyecto MAC (Multiple Access Computer) del MIT. Ellos tomaron el nombre del demonio de Maxwell un ser imaginario de un famoso experimento pensado por el físico escocés J. C. Maxwell para probar posibles violaciones de la segunda ley de la termodinámica. El demonio de Maxwell trabajaba continuamente sin ser visto ordenando moléculas. Maxwell se inspiró en los demonios de la mitología griega, algunos de los cuales se encargaban de hacer aquellas tareas que los dioses no querían realizar.\n> Los sistemas UNIX heredaron esta terminología para designar a un tipo especial de proceso que se ejecuta de forma continua en segundo plano y que no puede ser controlado directamente por el usuario ya que no está asociado con una terminal o consola.\nAl igual que los proceso de usuario, son ejecutados en modo usuario excepto cuando realizan llamadas al sistema que pasan a ser ejecutados en modo núcleo. Los procesos demonio realizan tareas periódicas relacionadas con la administración del sistema, como por ejemplo:\n- la administración y control de redes,\n- la ejecución de actividades dependientes del tiempo,\n - la administración de trabajos en las impresoras en línea, etc.\n Un proceso demonio no hace uso de los dispositivos de entradas y salida estándar para comunicar errores o registrar su funcionamiento, sino que usa archivos del sistema en zonas especiales o se utilizan otros demonios especializados en dicho registro."
        }
    },
    {

        "course_id": 1,
        "points": 1,
        "chapter_id": null,
        "type": "document",
        "name": "Resumen: ¿Qué hemos aprendido?",
        "properties":
        {"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
            "content":
            "1. En primer lugar, se introducen los términos proceso y núcleo. Un proceso es una instancia de un programa en ejecución. El núcleo administra a los procesos y suministra varios servicios para ellos. El sistema operativo UNIX de forma general incluye tanto el núcleo como otros programas y utilidades.\n   El núcleo es el único programa indispensable sin el cual ningún otro podría ejecutarse, y define la interfaz de programación del sistema.\\nLas principales características que han dado éxito al sistema UNIX son: están escritas en C, interfaz de usuario sencilla, sistema de ficheros jerarquizado, formato consistente para los archivos, contiene un interfaz simple y consistente para los periféricos, es un sistema multiusuario y multiproceso, y oculta la arquitectura de la máquina al usuario.\n   Existen diferentes distribuciones de UNIX: System V, BSD, OFS/1, SunOS, Solaris. En el capítulo se describe brevemente la historia del sistema operativo UNIX.\n   2. En segundo lugar, se ha visto que la arquitectura del sistema operativo UNIX se puede dividir en cuatro niveles o etapas. Una primera etapa, o nivel más interno, consiste en el hardware. En el segundo nivel está el núcleo, que suministra los servicios que utilizan todos los programas de aplicación del sistema UNIX. En el tercer nivel están los programas estándar y los ejecutables generados por el usuario. En este nivel, un programa interactúa con el núcleo mediante las llamadas al sistema, que permite el intercambio de datos, y dan instrucciones al núcleo para que realice operaciones con el hardware. En el cuarto nivel están las aplicaciones que se sirven de otros programas ya creados ubicados en el nivel inferior.\n   3. Los principales servicios realizados por el núcleo son: control de la ejecución de los procesos, planificación de los procesos para su ejecución en la CPU, asignación de la memoria principal, protección del espacio de direcciones de un proceso en ejecución, asignación de memoria secundaria para almacenamiento y recuperación de los datos de usuario, regulación del acceso de los procesos a los dispositivos periféricos, administración de archivos y dispositivos, tratamiento de interrupciones y excepciones.\n   4. La ejecución de los procesos en un sistema UNIX está dividida en dos modos de ejecución: modo núcleo o supervisor, y modo usuario. Un proceso que se ejecuta en modo usuario puede acceder sólo a unas partes de su propio espacio de direcciones, pero no alespacio de direcciones de otros procesos, o del mismo núcleo. Un proceso que se ejecuta en modo núcleo puede acceder al completo a su espacio de direcciones y al del núcleo, pero no al de otros procesos.\n   Asimismo, los procesos en el sistema UNIX puede ser de tres tipos: procesos de usuario (se ejecutan en modo usuario salvo cuando realizan llamadas al sistema, que se ejecutan en modo núcleo), procesos demonio (no asociados a ningún usuario, se ejecutan en modo usuario y modo núcleo, realizan tareas periódicas relacionadas con la administración del sistema), y procesos del núcleo (no asociados a ningún usuario, se ejecutan exclusivamente en modo núcleo, pueden acceder directamente a los algoritmos y estructuras de datos del núcleo sin hacer llamadas al sistema).\n    Los periféricos de E/S, el reloj del sistema, y los terminales pueden interrumpir a la CPU mientras se ejecuta un proceso. El mecanismo de interrupciones notifica al núcleo que se ha completado una operación o se ha producido un cambio de estado. Las interrupciones hardware son eventos asíncronos que ocurren entre la ejecución de dos instrucciones de un proceso. Las interrupciones software o traps son síncronas y se producen al ejecutar ciertas instrucciones especiales. Las excepciones se producen durante el transcurso de ejecución de una instrucción, y son eventos síncronos inesperados, típicamente errores. Dado que puede darse una petición de interrupción, mientras otra está siendo atendida, es necesario asignar un nivel de prioridad de interrupción (npi) o nivel de ejecución del procesador. El npi se almacena en un campo del registro de estado del procesador.\n5. También, se estudia la estructura del sistema operativo UNIX, en la que se pueden distinguir tres niveles: nivel de usuario, nivel de núcleo, y nivel de hardware.\nEn el nivel usuario, se encuentran los programas de usuario y los programas demonio. Interaccionan con el núcleo usando las llamadas al sistema. Se puede realizar la invocación a las llamadas al sistema de dos formas: mediante el uso de librerías de llamadas al sistema (similar a cualquier llamada de una función C, las librerías de llamadas del sistema trasladas estas llamadas a las funciones primitivas necesarias que permiten acceder al núcleo), y de forma directa.\\nEn el nivel núcleo, se encuentra el subsistema de ficheros y el subsistema de control de procesos, que interactúan con los programas de usuario a través de la interfaz de llamadas al sistema.Asimismo, el nivel de núcleo se comunica con el nivel de hardware a través de su módulo de control del hardware.\nEl subsistema de ficheros realiza todas las tareas del sistema asociadas a los ficheros (administra el espacio en memoria principal y del sistema de ficheros, control el acceso a los ficheros, etc). La interfaz que enlaza procesos con el subsistema de ficheros especifica el comportamiento y la semántica de todas las llamadas al sistema pertinentes tales como open, close, read, write,stat, chown, chmod. La interfaz exporta al usuario un pequeño número de abstracciones tales como: ficheros (ordinarios, enlaces simbólicos, tuberías, ficheros de dispositivos), directorios, descriptores de ficheros, y sistemas de ficheros. Los ficheros de dispositivos permiten a los procesos comunicarse con los dispositivos periféricos. Existe los dispositivos modo bloque y modo carácter.\nEl subsistema de control de procesos se encarga de la sincronización, comunicación y planificación de procesos, y administración de la memoria principal. Es el encargado de cargar los ficheros ejecutables en la memoria principal. Algunas de las llamadas que emplea son: fork, exec, exit, wait, signal. Está formado por tres módulos: módulo de administración de memoria (controla la asignación de memoria principal a los procesos, mediante un proceso de intercambio o swapping, y transfiere algunos procesos de la memoria principal a la secundario cuando no se dispone de suficiente memoria principal), módulo de planificación (asigna el uso de la CPU a los procesos), y el módulo de comunicación (mecanismos asíncronos de señalización de eventos, transmisión síncrona de mensajes entre procesos).\nEl módulo de control de hardware es el responsable del manejo de las interrupciones y de la comunicación con el hardware.\n6. Por último, se estudia la interfaz de usuario para el sistema de ficheros. Un fichero es un contenedor permanente de datos, y el núcleo suministra al usuario varias operaciones de control para nombrar, organizar y controlar el acceso a los ficheros. Un directorio contiene información sobre el nombre de los ficheros y directorios. UNIX organiza los ficheros en un árbol de directorios, que comienza en el directorio raíz que se denota con “/”. La entrada de un fichero en un directorio constituye un enlace duro para el fichero, que puede tener más de un enlace, en el mismo o en diferentes directorios.\nAparte del nombre de un fichero, el sistema de ficheros mantiene un conjunto de atributos para cada fichero, almacenados en una estructura del disco conocida como nodoíndice (nodo-i). Estos atributos son: tipo de fichero, permisos e indicadores de modo, número de enlaces duros, tamaño del fichero, identificador del dispositivo, número de nodo- i, identificador de usuario real (uid) y del grupo real (gid), e información asociada al tiempo. Llamadas al sistema para conocer y manipular atributos de un sistema son: stat y fstat, link y unlink, utimes, chown, chmod.\\n\nAdemás, cada fichero en UNIX tiene asociada una máscara de 16 bits conocida como máscara de modo del fichero. Los bits 15-12 indican el tipo de fichero. El bit 11 es el bit _ISUID. Bit 10: _ISGID. Bit 9: _ISVTX, y los bits 8-0 son los bits de acceso al fichero, que indican el tipo de permiso de acceso (lectura, escritura, y ejecución). De estos 16, el propietario del fichero puede modificar únicamente los valores de los bits 11 a 0, que se agrupa en cuatro dígitos octales M3M2M1M0.\nEl núcleo, cuando un usuario invoca a la llamada al sistema open para abrir un fichero, creo en memoria principal una estructura de datos asociada al fichero abierto que se llama objeto de fichero abierto. Cada objeto de fichero abierto se almacena en una entrada en una estructura global de núcleo denominada tabla de ficheros. También, el núcleo asigna un descriptor de fichero, un número entero positivo que sirve de identificador del objeto de fichero abierto. Cada proceso posee su propia tabla de descriptores de procesos, que contiene todos los descriptores de procesos asociados a un determinado proceso.\nLos tres ficheros que ocupan las tres primeras entradas de la tabla de descriptores cuando se arranca un proceso en UNIX son: fichero estándar de entrada (stdin), fichero estándar de salida (stout), y fichero estándar de salida de mensajes de error (stdeer). El proceso pasa el descriptor de fichero a las llamadas al sistema asociadas con operaciones de E/S.\nEl proceso pasa el descriptor del fichero a las llamadas al sistema asociadas con operaciones de E/S. El núcleo usa el descriptor para localizar rápidamente el objeto de fichero abierto, de manera que el núcleo sólo realiza una vez, y no en cada operación de E/S con el fichero, tareas tales como la búsqueda de la ruta del acceso o el control de acceso al fichero, mejorando el rendimiento considerablemente.\nEn UNIX los ficheros son accedidos secuencialmente. Cuando un usuario abre el fichero, el núcleo inicializa el puntero de lectura/escritura a cero. Si dos procesos abren el mismo fichero, el núcleo genera un nuevo objeto de fichero abierto y un nuevo descriptorde fichero en cada invocación a open. \nPor otra parte, un proceso puede duplicar un descriptor.\nLas operaciones de E/S sobre un fichero son: apertura y cierre de un fichero (creat, open, close), lectura y escritura (read, write), y acceso aleatorio (lseek)."
        }
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"Proceso y núcleo son:",
            "responses":[
                "Un proceso es una instancia de un programa en ejecución. El núcleo administra a los procesos y suministra varios servicios para ellos, y define la interfaz de programación del sistema. El sistema operativo UNIX incluye tanto el núcleo como otros programas y utilidades.",
                "El núcleo es una instancia de un programa en ejecución. Un proceso administra al núcleo y le suministra varios, y define la interfaz de programación del sistema. El sistema operativo UNIX incluye tanto el núcleo como otros programas y utilidades.",
                "El núcleo está en el nivel más interno de la computadora. Un proceso está escrito en C y genera programas ejecutables por el usuario.",
                "Un proceso es el encargado de hacer las llamadas al sistema, el núcleo suministra servicios para los programas"
            ],
            "correctAnswer":0              } ,"code_url":null, "content":""}
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"Principales características del sistema UNIX.",
            "responses":[
                "Están escritas en C, sistema de ficheros jerarquizado, formato consistente para los archivos, es un sistema multiusuario y monoproceso, y oculta la arquitectura de la máquina al usuario.",
                "Están escritas en C, sistema de ficheros jerarquizado, formato consistente para los archivos, contiene un interfaz simple y consistente para los periféricos, es un sistema multiusuario y multiproceso, y oculta la arquitectura de la máquina al usuario.",
                "Están escritas en C++, sistema de ficheros en grafo, formato consistente para los archivos, contiene un interfaz simple y consistente para los periféricos, es un sistema multiusuario y multiproceso, y oculta la arquitectura de la máquina al usuario.",
                "Están escritas en C++, sistema de ficheros jerarquizado, formato consistente para los archivos, contiene un interfaz simple y consistente para los periféricos, es un sistema multiusuario y monpproceso, y oculta la arquitectura de la máquina al usuario."
            ],
            "correctAnswer":1              } ,"code_url":null, "content":""}
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"Niveles en los que se divide la arquitectura del sistema operativo UNIX.",
            "responses":[
                "Tiene tres niveles o etapas: hardware, núcleo y ejecutables, que interactúan con el núcleo mediante las llamadas al sistema.",
                "Tiene cuatro niveles: hardware, núcleo, programas sistema, que interactúan con el núcleo mediante las llamadas al sistema, y apps.",
                "Tiene tres niveles: hardware, núcleo y apps.",
                "Tiene cuatro niveles: hardware, núcleo, programas estándar y ejecutables, que interactúan con el núcleo mediante las llamadas al sistema, y aplicaciones."
            ],
            "correctAnswer":3              } ,"code_url":null, "content":""}
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"Principales servicios realizados por el núcleo.",
            "responses":[
                "Control de la ejecución de los procesos, planificación de los procesos para su ejecución en la CPU, asignación de la memoria principal, protección del espacio de direcciones de un proceso en ejecución, asignación de memoria secundaria para almacenamiento y recuperación de los datos de usuario, regulación del acceso de los procesos a los dispositivos periféricos, administración de archivos y dispositivos.",
                "Control de la ejecución de los procesos, planificación de los procesos para su ejecución en la CPU, asignación de la memoria principal, protección del espacio de direcciones de un proceso en ejecución, asignación de memoria secundaria para almacenamiento y recuperación de los datos de usuario, regulación del reloj del sistema, regulación del acceso de los procesos a los dispositivos periféricos, administración de archivos y dispositivos.",
                "Control de la ejecución de los procesos, planificación de los procesos para su ejecución en la CPU, asignación de la memoria principal, protección del espacio de direcciones de un proceso en ejecución, asignación de memoria secundaria para almacenamiento y recuperación de los datos de usuario, regulación del acceso de los procesos a los dispositivos periféricos, administración de alarmas, administración de archivos y dispositivos, tratamiento de interrupciones y excepciones.",
                "Control de la ejecución de los procesos, asignación de la memoria principal, protección del espacio de direcciones de un proceso en ejecución, planificación de los procesos para su ejecución en la CPU, asignación de memoria secundaria para almacenamiento y recuperación de los datos de usuario, regulación del acceso de los procesos a los dispositivos periféricos, administración de archivos y dispositivos, tratamiento de interrupciones y excepciones."
            ],
            "correctAnswer":3              } ,"code_url":null, "content":""}
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"¿Cuáles son los modos de ejecución de los procesos de un sistema UNIX?.",
            "responses":[
                "La ejecución de los procesos en un sistema UNIX está dividida en dos modos de ejecución: modo núcleo, y modo usuario.",
                "La ejecución de los procesos en un sistema UNIX está dividida en tres modos de ejecución: modo núcleo, supervisor, y modo usuario.",
                "La ejecución de los procesos en un sistema UNIX está dividida en tres modos de ejecución: modo núcleo, modo demonio y modo usuario.",
                "La ejecución de los procesos en un sistema UNIX está dividida en dos modos de ejecución: modo hardware y modo usuario."
            ],
            "correctAnswer":0             } ,"code_url":null, "content":""}
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"Tipos de procesos en el sistema UNIX.",
            "responses":[
                "Los procesos en el sistema UNIX puede ser de tres tipos: procesos de usuario, procesos demonio, y procesos del núcleo.",
                "Los procesos en el sistema UNIX puede ser de dos tipos: procesos de usuario y procesos del núcleo.",
                "Los procesos en el sistema UNIX puede ser de tres tipos: procesos de usuario, procesos de excepciones y procesos del sistema.",
                "Los procesos en el sistema UNIX puede ser de tres tipos: procesos de usuario, procesos demonio, y procesos de sistema."
            ],
            "correctAnswer":0              } ,"code_url":null, "content":""}
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"En qué consiste una interrupción, y tipos.",
            "responses":[
                "Mientras se ejecuta un proceso, diversos sistemas pueden interrumpir a la CPU. El mecanismo de interrupciones notifica al núcleo una operación completada o un cambio de estado. Existe dos tipos de interrupciones: hardware y software.",
                "Los terminales pueden interrumpir a la CPU. Consiste en un sistema de notificaciones. Existe dos tipos de interrupciones: traps y excepciones.",
                "El reloj del sistema, y los terminales pueden interrumpir a la CPU. Las interrupciones notifican al núcleo sobre una operación completada. Existe tres tipos de interrupciones: nucleo, software, y excepciones.",
                "Mientras se ejecuta un proceso, los periféricos de E/S, el reloj del sistema, y los terminales pueden interrumpir a la CPU. El mecanismo de interrupciones notifica al núcleo una operación completada o un cambio de estado. Existe tres tipos de interrupciones: hardware, software, y excepciones."
            ],
            "correctAnswer":3              } ,"code_url":null, "content":""}
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"Señala los niveles en la estructura del sistema UNIX.",
            "responses":[
                "Nivel de usuario, nivel de núcleo, y nivel de sistema. El nivel de usuario interacciona con el nivel de núcleo a través de las llamadas al nucleo. En el núcleo se encuentra el subsistema de ficheros y el subsistema de control de procesos.",
                "Nivel de usuario, nivel de núcleo, y nivel de hardware. El nivel de usuario interacciona con el nivel de núcleo a través de las llamadas al sistema, y su invocación se puede realizar mediante el uso de librerías y de forma directa. En el núcleo se encuentra el subsistema de ficheros y el subsistema de control de procesos. El nivel de núcleo se comunica con el nivel de hardware a través de su módulo de control del hardware.",
                "Nivel de kernel, nivel de núcleo, y nivel de usuario. El nivel de usuario interacciona con el nivel de núcleo a través de las llamadas al kernel, y su invocación se puede realizar mediante el uso de librerías y de forma directa. El nivel de núcleo se comunica con el nivel de hardware a través de su módulo de control del hardware.",
                "Nivel de usuario, nivel de núcleo, y nivel de hardware. El nivel de usuario interacciona con el nivel de núcleo a través de las llamadas al sistema, y su invocación se puede realizar mediante el uso de librerías. En el núcleo se encuentra el subsistema de ficheros y el subsistema de control de procesos. El nivel de núcleo se comunica con el nivel de hardware a través de su módulo de sistemas."
            ],
            "correctAnswer":2             } ,"code_url":null, "content":""}
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"Describe la interfaz de usuario para el sistema de ficheros.",
            "responses":[
                "Un fichero es un contenedor permanente de datos, y el núcleo suministra al usuario varias operaciones de control sobre estos ficheros. UNIX organiza los ficheros en un árbol de directorios. La entrada de un fichero en un directorio constituye un enlace duro para el fichero.",
                "Un fichero es una lista enlazada de datos donde el núcleo suministra al usuario las suficientes operaciones de control para controlarlos. UNIX organiza los ficheros en un árbol de directorios acíclico.",
                "Un fichero es una lista enlazada de datos accesible por el usuario y por el núcleo. UNIX organiza los ficheros en un árbol de directorios. Una entrada de fichero va asociada a una máscara de modo",
                "Un fichero es un contenedor permanente de datos accesible por el usuario y por el núcleo. UNIX organiza los ficheros en un árbol de directorios. Una entrada de fichero va asociada a una máscara de modo"
            ],
            "correctAnswer":0              } ,"code_url":null, "content":""}
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"Señala los tipos de atributos de ficheros, y dónde se almacenan.",
            "responses":[
                "Tipo de fichero, permisos e indicadores de modo, tamaño del fichero, identificador del dispositivo, identificador de usuario real (uid) y del grupo real (gid), e información asociada al tiempo para cada fichero. Los atributos se almacenan en el nodo índice (nodo-i)",
                "Tipo de fichero, número de enlaces duros, tamaño del fichero, identificador del dispositivo, permisos e indicadores de modo, número de nodo-i, identificador de usuario real (uid) y del grupo real (gid), e información asociada al tiempo para cada fichero. Los atributos se almacenan en el nodo índice (nodo-i)",
                "Tipo de fichero, permisos e indicadores de modo, número de enlaces activos, tamaño del fichero, identificador del dispositivo, número de nodo-i, número de nodo-c, identificador de usuario real (uid) y del grupo real (gid), e información asociada al tiempo para cada fichero. Los atributos se almacenan en el nodo índice (nodo-i)",
                "Tipo de fichero,  número de enlaces duros, tamaño del fichero, identificador del dispositivo, permisos e indicadores de modo e información asociada al tiempo para cada fichero. Los atributos se almacenan en el nodo índice (nodo-i)"
            ],
            "correctAnswer":1              } ,"code_url":null, "content":""}
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"¿Qué es la máscara de modo de fichero? ¿Qué indica cada bit o conjunto de bits?",
            "responses":[
                "La máscara de modo de fichero indica los permisos sobre el archivo con prioridad sobre otras estructuras. Cada bit indica un tipo de permiso",
                "La máscara de modo de fichero indica las modificaciones que se pueden realizar sobre el archivo. Cada bit indica qué tipo de usuario puede modificarlo",
                "La máscara de modo informa, por orden, de los permisos para el propietario, los miembros del grupo al que pertenece el propietario del fichero y otros usuarios.",
                "La máscara de modo informa de los listados de acceso del fichero, el grupo de permisos asociados y la capacidad de cada usuario"
            ],
            "correctAnswer":2              } ,"code_url":null, "content":""}
    },
    {"course_id": 1,
        "points": 10,
        "chapter_id": null,
        "type": "quiz",
        "name": "Autoevaluación. Comprueba lo que has aprendido",
        "properties": {"card": {"back": null, "front": null},"quiz": {
            "question":"Define objeto de fichero abierto, tabla de ficheros, y descriptores de ficheros. 1M) Señala las operaciones de E/S sobre un fichero",
            "responses":["Las operaciones de E/S sobre un fichero son: creación y cierre de un fichero, lectura y escritura, y acceso aleatorio.\n",
                "Las operaciones de E/S sobre un fichero son: apertura, compresión de un fichero y acceso aleatorio (lseek).\n",
                "Las operaciones de E/S sobre un fichero son: apertura y cierre de un fichero (creat, open, close), lectura y escritura (read, write).\n",
                "Las operaciones de E/S sobre un fichero son: apertura y cierre de un fichero (creat, open, close), lectura y escritura (read, write), y acceso aleatorio (lseek).\n"
            ],
            "correctAnswer":3} ,"code_url":null, "content":""}
    },
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "ADMINISTRACIÓN BÁSICA DEL SISTEMA OPERATIVO UNIX",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": ""
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Consideraciones iniciales ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": ""
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Comandos de UNIX más comunes ",
"properties":
{
"content": "## Manejo de directorios y ficheros"
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Cambiar el directorio de trabajo",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "Ejemplo_1-7"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "### Obtener información de un directorio o de un fichero",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "Ejemplo_1-8"     }
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Crear directorios nuevos",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "Ejemplo_1-9"     }
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Copiar ficheros",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_1-10"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Mover ficheros",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_1-11"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Borrar ficheros y directorios",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_1-12"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Acceder al contenido de los ficheros",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_1-13"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Comandos de UNIX más comunes ",
"properties":
{
"content": ""
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Gestión de usuarios ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,"content":""}
},
{
"course_id": 1,
"chapter_id": null,
"points": 0,
"type": "code",
"name": "## Cuentas de usuario",
"properties":
{

"content": "",
"code_url": "Ejemplo_1-14"     }
},
{
"course_id": 1,
"chapter_id": null,
"points": 0,
"type": "code",
"name": "## Creación y eliminación de una cuenta de usuario",
"properties":
{

"content": "",
"code_url": "Ejemplo_1-15"     }
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Gestión de usuarios ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Modificación de la información asociada a una cuenta de usuario\nEl superusuario puede modificar la información asociada a una cuenta de usuario. La forma más simple de hacer esto es cambiar los valores directamente en la línea apropiada del fichero /etc/passwd.\nPor otra parte si un usuario desea modificar la contraseña de acceso a su cuenta puede utilizar el comando passwd, que solicita la contraseña vieja y la contraseña nueva. Esta última la solicita dos veces para validarla.\nSi un usuario olvida su contraseña deberá pedirle al superusuario que le asigne una nueva contraseña."
}
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Grupos de usuarios",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "Ejemplo_1-15"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Configuración de los permisos de acceso a un fichero ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": ""
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Consideraciones generales sobre los intérpretes de comandos ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": ""
}
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Redirección de entrada/salida",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_1-17"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Encadenamiento de órdenes",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_1-18"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Asignación de alias a comandos",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_1-19"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Shell scripts",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_1-20"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Funcionamiento de un intérprete de comandos",
"properties":
{
"content": "Un intérprete de comandos es un fichero ejecutable. El proceso que se crea asociado a la ejecución de dicho fichero en primer lugar lee y ejecuta las órdenes establecidas en los diferentes ficheros de arranque del intérprete para configurar sus variables internas, a continuación muestra el marcador en pantalla y se queda a la espera de recibir órdenes del usuario. De forma general, las órdenes que se pueden ejecutar en un intérprete de comandos pueden ser de dos tipos:Órdenes internas (builtin commands). Son aquellas órdenes cuyo código de ejecución se encuentra incluido dentro del propio código del intérprete. Así la ejecución de una orden interna no supone la creación de un nuevo proceso. Ejemplos de órdenes internas son cd , pwd, print, printf, read y readline. En el manual de ayuda de UNIX en la entrada asociada al intérprete de comandos que se esté utilizando se puede encontrar información sobre todas sus órdenes internas. Para obtener información sobre un comando en concreto puede utilizarse la orden help comando.\nÓrdenes externas. Son aquellas órdenes que para poder ser ejecutadas por el intérprete requieren de la búsqueda y ejecución del fichero ejecutable asociado a cada orden. Típicamente son programas ejecutables o shell scripts incluidos en la distribución del sistema o creados por el usuario. La ejecución de una orden externa supone la creaciónde al menos un nuevo proceso con la llamada al sistema fork (ver sección 4.3) y la invocación del programa ejecutable con la llamada al sistema exec (ver sección 4.8.2). Ejemplos de órdenes externas son ls y mkdir.\nCuando se teclea una orden, el intérprete de comandos en primer lugar busca el nombre de la orden y comprueba si es una orden interna. En caso afirmativo la ejecuta. En caso contrario considera que es una orden externa por lo que debe buscar su programa ejecutable asociado. Si lo encuentra lo ejecuta. En el caso de que no se pueda encontrarlo mostrará un mensaje de aviso por la pantalla."
}
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Variables del intérprete de comandos y variables de entorno",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_1-21"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## La variable de entorno PATH",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},
"content": "",
"code_url": "Ejemplo_1-22"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Depuración en bash",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "Ejemplo_1-23"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Control de Tareas",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "ada proceso que es ejecutado por un usuario supone una tarea para el sistema. El control de tareas es una utilidad incluida en muchos intérpretes de comandos que permite controlar el estado de las diferentes tareas que se están ejecutando en el sistema.\nEn muchos casos, los usuarios sólo ejecutan una tarea cada vez, que es el último comando tecleado. Sin embargo, usando el control de tareas, se pueden ejecutar diferentes tareas al mismo tiempo, cambiando entre cada una de ellas conforme se necesite."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Visualización de los procesos en ejecución",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_2-8-1"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Primer plano y segundo plano",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_2-8-2"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Eliminación de procesos",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_2-8-3"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Otros comandos de UNIX ",
"properties":
{}
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Información del sistema",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "Ejemplo_2-9-1"     }
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Búsqueda de ficheros y texto",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_2-9-2"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Compresión de ficheros",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_2-9-3"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "## Instalación de software",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,           "content": "Si un determinado programa tiene una licencia de software libre, significa que de alguna manera es posible llegar a obtener el código fuente de ese programa.\nNormalmente el código fuente se encuentra comprimido en el formato .tar.gz. Una vez que se hayan descomprimido los archivos, se debe ejecutar la acción que corresponda según el lenguaje en el que esté desarrollada la aplicación.\nLa mayor parte del software libre está desarrollado en lenguaje C y pensado para ser compilada con el compilador gcc. El software que sigue los directrices de empaquetamiento de GNU, dispone de un comando configure que detecta una gran variedad de datos acerca del sistema utilizado (el procesador, el sistema operativo, el compilador C, las bibliotecas necesarias para compilar y todos los recursos necesarios para compilar el código fuente en cuestión). En el caso en que falte un determinado recurso (bibliotecas, programas, etc) avisará al usuario de ello.\nUna vez que todos los recursos han sido detectados correctamente, es necesario ejecutar el comando make, para que compile el código fuente. A continuación se debe ejecutar el comando make install que instala el programa en el sistema, dejándolo listo para usar.\nPara el caso de los programas que no usen los comandos configure y make será necesario leer la documentación que acompañe al código fuente para saber cómo realizar la compilación.\nSi bien todo programa que sea software libre da la posibilidad de ser compilado por el usuario, esto requiere mucho tiempo. Por ello muchas veces es preferible utilizar el código binario (programa ejecutable) que ya ha sido compilado por otras personas, para la plataforma que se esté utilizando.\nLa gran mayoría de los programas, se distribuyen también en forma binaria compilada por su creador. Normalmente este código binario se encontrará en formato .tar.gz, al igual que el código fuente. O incluso en archivos ejecutables que pueden instalarse directamente.\nPor lo general basta con descomprimir el archivo y luego agregar el directorio correspondiente a la variable PATH, o bien ejecutarlo directamente desde el directorio.\nTanto la instalación desde el código fuente como la instalación a partir del código binario permiten que un usuario instale una aplicación en su directorio de trabajo sin tener que pedirle permiso al administrador del sistema.\nCuando la instalación es realizada por el administrador del sistema, es recomendable colocar los programas en la ruta /usr/local o bien /opt (estas rutas pueden variar según la distribución de UNIX o Linux utilizada). De forma que todos los usuarios del sistema puedan acceder a estos programas.\nOtra forma bastante habitual de presentación de un software es en forma de paquete. Se denomina paquete al conjunto formado por el código binario de una aplicación, los scripts necesarios para configurar, instalar y desinstalar esta aplicación, los datos acerca de otros programas y bibliotecas que son necesarios para su correcto funcionamiento (dependencias) y algunos otros datos adicionales relacionados con la aplicación en cuestión.\nExisten varios formatos de paquetes en GNU/Linux, por ejemplo:\nPaquetes de la distribución Red Hat y derivados. Se identifican porque su nombre termina con la extensión .rpm. La herramienta para manejar estos paquetes se llama rpm. Para instalar un cierto paquete llamado paquete.rpm se debe ejecutar la orden rpm -i paquete.rpm.\nPaquetes de la distribución Debian. Se identifican porque su nombre termina con la extensión .deb. Existen dos herramientas para manejar estos paquetes: apt y dpkg. Para instalar con dpkg un cierto paquete llamado paquete.deb se debe ejecutar la orden dpkg -i paquete.deb.\nPaquetes de la distribución Slackware. Se identifican porque su nombre termina con la extensión .tgz. Las herramientas para manejar estos paquetes son dos: pkgtool para seleccionar los paquetes a instalar desde un menú amigable y installpkg para instalar los paquetes.\nLos paquetes de software pueden distribuirse de forma independiente o de forma agrupada en repositorios. Un repositorio es un almacén de software que puede accederse típicamente través de internet y que permite instalar paquetes de software de forma totalmente automática. Cada distribución de Unix cuenta con sus propios repositorios ygestores de paquetes. Si paquete se encuentra en un repositorio su instalación en el sistema será fácil y rápida usando el gestor de paquetes apropiado que se encargará de resolver las dependencias de cada paquete antes de instalarlo."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Trabajo en red",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "Ejemplo_2-9-5"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "Ejemplos adicionales de shell scripts",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "Ejemplo_2-10"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Ficheros de arranque de un intérprete de comandos",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": ""
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "La función de librería System",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},	"content": "",
"code_url": "Ejemplo_2-12"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Resumen: ¿Qué hemos aprendido?",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": ""
}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué es una consola del sistema?",
"responses":[                         "Por consola del sistema se entiende el monitor y teclado conectado directamente al sistema. UNIX proporciona acceso a consolas virtuales, lo que permitirá tener más de una sesión de trabajo activa.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué es un intérprete de comandos?",
"responses":[                         "Un intérprete de comandos (shell) es simplemente un programa de utilidad que permite al usuario comunicarse con el sistema. Básicamente lo que hace es leer las órdenes o comandos que teclea el usuario en la línea de órdenes, buscar los programas ejecutables asociados a las mismas y ejecutarlos.\nEl formato general de una orden o comando de UNIX es el siguiente\nnombre_orden -opciones parámetro1 parámetro2 ... parámetroN",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué orden se utiliza para crear un directorio?",
"responses":[                         "Para crear un nuevo directorio se usa la orden mkdir. Su sintaxis es: mkdir dir1 dir2 ...dirN\ndonde dir1, dir2, ..., dirN son los nombres de los directorios que se desean crear",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué orden se utiliza para mover un fichero?",
"responses":[                         "Para mover ficheros de un directorio a otro se puede usar la orden mv cuya sintaxis es: mv fichero1 fichero2 ... ficheroN destino\ndonde fichero1, fichero2,..., ficheroN son las rutas de acceso de los ficheros que se desean mover y destino es el directorio destino.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué comandos se pueden emplear para salir del sistema?",
"responses":[                         "Para salir del sistema UNIX de forma segura se recomienda usar el comando\nshutdown. En la invocación de este comando se puede especificar que tras salir del sistema la computadora se apague o se reinicie.\nSi se desea salir del sistema UNIX más rápidamente y apagar la computadora se pueden teclear los comandos halt o poweroff. Si se desea reiniciar la computadora se puede usar el comando reboot.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué información almacena el sistema sobre las cuentas de usuarios?",
"responses":[                         "El sistema almacena información sobre las cuentas de usuarios en el fichero /etc/passwd. Cada línea de este fichero contiene la siguiente información acerca de un único usuario:- Nombre de usuario (login). Es un identificador único dado a cada usuario del sistema. Este identificador pueden contener los siguientes caracteres: letras, dígitos, '_' y '.'. Además su longitud está limitada normalmente a 8 caracteres de longitud.\n- Identificador de usuario real (uid). Es un número único dado a cada usuario del sistema.\n- Identificador de grupo real (gid). Es un número único dado a cada grupo de usuarios del sistema.\n- Contraseña (password). Es una clave personal secreta que posee cada usuario para poder entrar en el sistema. Como medida de seguridad el sistema almacena encriptada esta clave. Es usual encontrar en este campo simplemente el carácter ‘x‘. Esto significa que la contraseña se encuentra almacenada dentro del archivo /etc/shadow que únicamente puede leer el superusuario. De esta forma obtener la contraseña de un usuario es mucho más difícil.\n- Nombre real o completo del usuario.\n- Directorio de trabajo inicial. Es el directorio desde donde inicialmente empezará a trabajar el usuario cuando acceda al sistema. Cada usuario debe tener su propio directorio inicial, normalmente como un subdirectorio del directorio /home.\n- Intérprete de comandos inicial. Es el intérprete de comandos con el que comenzará a trabajar el usuario cuando acceda al sistema.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cómo se obtiene la máscara de modo simbólica de un archivo?",
"responses":[                         "El comando ls -l muestra información detallada sobre los ficheros contenidos en el directorio de trabajo actual. En concreto al principio de la línea asociada a cada fichero muestra una cadena de caracteres con información sobre la máscara de modo del fichero. A dicha cadena se le denominará máscara de modo simbólica.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué utilidad tiene el comodín ‘*’ y en qué se diferencia del carácter ‘?’?",
"responses":[                         "El comodín ’*’ hace referencia a cualquier carácter o cadena de caracteres en el fichero. Por ejemplo, cuando se usa el carácter ’*’ en el nombre de un fichero, el intérprete de comandos lo sustituye por todas las combinaciones posibles provenientes de los ficheros en el directorio de trabajo.\nEl proceso de la sustitución de ’*’ en nombres de ficheros es llamado expansión de comodines y es efectuado por el intérprete de comandos.\nLa diferencia respecto al carácter ‘?’ es que el comodín ’*’ se puede substituir en la expansión por varios caracteres mientras que el carácter ‘?’ se sustituye por uno solo.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Se pueden asignar alias a los comandos?",
"responses":[                         "Sí, En ciertas ocasiones se suelen utilizar comandos que son difíciles de recordar o que son demasiado extensos. En UNIX existe la posibilidad de dar un nombre alternativo o alias a un comando con el fin de que cada vez que se quiera ejecutar, sólo se use el nombre alternativo. Obviamente se debe procurar que el alias que se utilice sea corto y fácil de recordar.\nPara definir un alias sólo se necesita usar el comando alias, su sintaxis es: alias nombre='definición'",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Explica qué es un shell script y sus principales ventajas e inconvenientes.",
"responses":[                         "Los shell scripts son ficheros de texto que contienen programas escritos en el lenguaje del intérprete de comandos. Para poder ejecutar un shell script es necesario que su fichero de texto asociado tenga activados, al menos, los permisos de lectura y ejecución.\nLa principal ventaja que presenta un shell script frente a un programa compilado es la portabilidad. Otra ventaja es la facilidad de lectura e interpretación.\nEl principal inconveniente que presenta un shell script respecto a un programa compilado es la lentitud de ejecución. Otro inconveniente es que el código resulta visible acualquier usuario que lo pueda ejecutar.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe el funcionamiento de un intérprete de comandos.",
"responses":[                         "Un intérprete de comandos es un fichero ejecutable. El proceso que se crea asociado a la ejecución de dicho fichero en primer lugar lee y ejecuta las órdenes establecidas en los diferentes ficheros de arranque del intérprete para configurar sus variables internas. A continuación muestra el marcador en pantalla y se queda a la espera de recibir órdenes del usuario. De forma general, las órdenes que se pueden ejecutar en un intérprete de comandos pueden ser de dos tipos: órdenes internas y externas. Las internas són las ordenes implementadas en el propio intérprete y las externas corresponden a la invocación de otros ficheros ejecutables.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué es una variable de intérprete de comandos?",
"responses":[                         "Cuando se ejecuta un intérprete de comandos se crean, con los valores iniciales establecidos en diferentes ficheros de arranque, un conjunto de variables denominadas variables del intérprete de comandos. Estas variables son locales al intérprete y pueden ser utilizadas por todas sus órdenes internas.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué es una variable de entorno?",
"responses":[                         "Se denominan variables de entorno a aquellas variables del intérprete de comandos\nque proceden del entorno del proceso asociado al intérprete. Por ejemplo la variable PATH.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe el funcionamiento de la variable PATH",
"responses":[                         "La variable PATH es una variable de entorno que especifica las rutas de acceso a los directorios donde el intérprete debe buscar el fichero ejecutable asociado a una determinada orden externa. Esta variable no es usada, sin embargo, en la localización de los ficheros ordinarios.\nAl entrar en el sistema, la variable PATH al igual que el resto de variables de entorno es inicializada con un valor por defecto que se encuentra definido en los ficheros de arranque del sistema o del intérprete.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué comando se emplea para la visualización de los procesos en ejecución?",
"responses":[                         "El comando ps muestra por pantalla la lista de procesos que el usuario está ejecutando actualmente. Si se invoca con la opción -aux, es decir, ps -aux, se mostrará además la utilización del procesador y de la memoria.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué comando se emplea para eliminar un proceso?",
"responses":[                         "Para eliminar un proceso, se utiliza el comando kill. Este comando toma como argumento el pid del proceso o el número de tarea que dicho proceso tiene asignado.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "ESTRUCTURAS DE DATOS DE CONTROL DE PROCESOS EN UNIX",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "- Descripción del espacio de direcciones virtuales asociado a un proceso.\n- Identificadores y las estructuras de datos del núcleo asociadas a un proceso.\n- Análisis de los diferentes elementos que constituyen el contexto de un proceso.\n- Tratamiento de las interrupciones por parte del núcleo.\n- Interfaz de las llamadas al sistema.\n- Conocimiento y descripción de los posibles estados de un proceso.\nCuando se compila un programa, el compilador suponiendo que dicho programa va a ser el único que se va a ejecutar en el sistema genera un espacio o conjunto de direcciones de memoria virtual asociadas a dicho programa. Este espacio es traducido por la máquina a un conjunto de direcciones de memoria principal. De esta forma, varias copias de un mismo programa pueden coexistir en memoria principal, todas ellas utilizarán las mismas direcciones virtuales, sin embargo tendrán asignadas diferentes direcciones físicas.\nUna región o segmento es un subconjunto o área de direcciones contiguas de memoria virtual. En cualquier programa se pueden distinguir al menos tres regiones: la región de código o texto, la región de datos y la región de pila.\nUn proceso es una instancia de un programa en ejecución. Consiste en un conjunto de bytes que la CPU interpreta como código (instrucciones máquina), datos o elementos de una pila. En un sistema UNIX los procesos parecen ejecutarse de forma simultánea, aunque, si se tiene una arquitectura monoprocesador, en un determinado instante de\ntiempo, realmente sólo uno de ellos estará ejecutándose en la CPU. Asimismo pueden existir simultáneamente en el sistema varias instancias de un mismo programa.\nDesde un punto de vista práctico, un proceso es una entidad que se crea con la llamada al sistema fork, el proceso que invoca a esta llamada se denomina proceso padre y el proceso que se crea como resultado de la llamada fork se denomina proceso hijo.\nLos procesos son unidades funcionalmente independientes ya que se debe tener en cuenta que un proceso no puede ejecutar instrucciones de otro proceso. Un proceso puede leer y escribir en sus regiones de datos y de pila, pero no puede leer ni escribir en las regiones de datos y de pila de otros procesos. Evidentemente ante esta situación se hace necesario implementar mecanismos de comunicación entre los procesos, materia que será objeto de estudio en el capítulo 7.\nPuesto que UNIX es un sistema multitarea y multiusuario, el núcleo asigna a cada proceso varios identificadores numéricos con el fin de llevar un control de los procesos que se están ejecutando en el sistema y saber a qué usuarios pertenecen. Asimismo, el núcleo mantiene diferentes estructuras de datos asociadas a los procesos, las cuales son fundamentales para la ejecución de los mismos.\nDe manera poco formal, pero muy gráfica, se puede afirmar que el contexto de un proceso A es una “fotografía” de los valores de ciertas posiciones de memoria asociados al proceso A y de los registros de la CPU. En determinadas circunstancias, el núcleo debe realizar un cambio de contexto, es decir, aplazar o finalizar la ejecución del proceso A y comenzar o continuar con la ejecución de otro proceso B. Asimismo, cuando se produce una interrupción, una llamada al sistema o un cambio de contexto el núcleo debe salvar el contexto del proceso (“tomar una fotografía”).\nEn este capítulo, se describe el espacio de direcciones virtuales, los identificadores y las estructuras de datos del núcleo asociadas a un proceso. Asimismo, se analizan los diferentes elementos que constituyen el contexto de un proceso. Además se estudia cómo se salva el contexto de un proceso y cómo se realiza un cambio de contexto. También se describe el tratamiento de las interrupciones por parte del núcleo y la interfaz de las llamadas al sistema. La parte final del capítulo se dedica a enumerar y describir los posibles estados de un proceso, haciéndose especial hincapié en el estado dormido.\nEn la explicación de este capítulo se va a tomar como referencia principalmente el núcleo de una distribución clásica como SVR3. Las variantes modernas de UNIX tales\ncomo SVR4, OSF/1, BSD4.4 y Solaris 2.x (y superiores) presentan ciertas diferencias con respecto a este modelo clásico."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Espacio de direcciones de memoria virtual asociado a un proceso ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Formato lógico de un archivo ejecutable\nAl compilar el código fuente de un programa se crea un archivo ejecutable que consta básicamente de cuatro partes (ver AQUÍ VA UNA IMAGEN3-1):\n- Cabecera primaria. Contiene la siguiente información:o El número mágico. Es un entero pequeño que permite al núcleo\nidentificar el tipo de archivo ejecutable.\no Elnúmerodeseccionesquehayenelarchivo.\no La dirección virtual de inicio, imprescindible para comenzar con la ejecución del proceso.\n- Cabeceras de las secciones. Describen cada una de las secciones del archivo. Entre otras informaciones contienen el tipo y el tamaño de la sección, además de la dirección virtual que se le debe asignar al comienzo de la región cuando el proceso se ejecute en el sistema.\n- Secciones. Contienen los “datos”, que son cargados inicialmente en el espacio de direcciones del proceso, típicamente, el código (también denominado texto), los datos inicializados (variables estáticas y externas del programa conocidas en el momento de la compilación) y los datos no inicializados (también denominado bss8).\n- Otras informaciones. Tales como la tabla de símbolos y otros “datos”. La tabla de símbolos es una tabla que se utiliza para almacenar los nombres definidos por el usuario en el programa fuente: variables, nombres de funciones, nombres de tipos, constantes, etc. Normalmente un compilador, debe comprobar, por ejemplo, que no se utiliza una variable sin haberla declarado previamente, o que no se declara una variable dos veces. Para ello, el compilador tiene que almacenar el nombre de la\n8 Bss es el acrónimo del término inglés block started by symbol cuya traducción al castellano es bloque inicializado con símbolos.variable (y posiblemente su tipo y algún otro dato) en la tabla de símbolos. Cuando se utiliza esta variable en una expresión, el compilador la busca en la tabla para comprobar que existe y además para obtener información acerca de ella: tipo, dirección de memoria, etc.\nLa información que se guarda en esta tabla depende del tipo de símbolo de que se trate. Lo habitual (excepto en compiladores muy sencillos) es implementar la tabla de símbolos utilizando una tabla de dispersión (hash) para optimizar el tiempo de búsqueda.\nCabecera Primaria\nCabecera Sección 1 Cabecera Sección 2\nCabecera Sección n\nSección 1 Sección 2\nSección n\nAQUÍ VA UNA IMAGEN3-1: Estructura de un archivo ejecutable\n ## Regiones de un proceso\nEl núcleo carga un fichero ejecutable en memoria principal durante la realización, por ejemplo, de una llamada al sistema exec. El proceso cargado tiene asignado por el compilador un espacio de direcciones de memoria virtual, también denominado espacio de direcciones de usuario. Este espacio se divide en varias regiones, cada una de las cuales delimita un área de direcciones contiguas de memoria virtual. El espacio de direcciones de memoria virtual de un proceso consiste al menos de tres regiones: la región de código (o\n Número mágico Número de secciones Dirección virtual de inicio\n Tipo de la sección T amaño de la sección Dirección virtual\n Tipo de la sección T amaño de la sección Dirección virtual\n  Tipo de la sección T amaño de la sección Dirección virtual\n “Datos”\n “Datos”\n  “Datos”\n Otras informaciones\ntexto), la región de datos y la región de pila. Adicionalmente, puede contener regiones de memoria compartida, que posibilitan la comunicación de un proceso con otros procesos.\nLas regiones de código y de datos se corresponden con las secciones de código y datos del fichero ejecutable. La región de datos inicializados o zona estática de la región de datos es de tamaño fijo. Por el contrario el tamaño de la región de datos no inicializados o zona dinámica de la región de datos puede variar durante la ejecución de un proceso.\nLa región de pila o pila de usuario se crea automáticamente y su tamaño es ajustado dinámicamente en tiempo de ejecución por el núcleo. La ejecución del código del programa irá marcando el crecimiento o decrecimiento de la pila, el núcleo asignará espacio para la pila conforme se vaya necesitando. La pila está constituida por marcos de pila lógicos. Un marco se añade a la pila cuando se llama a una función y se extrae cuando se vuelve de la misma. Existe un registro especial de la máquina denominado puntero de la pila donde se almacena la dirección, dependiendo de la arquitectura de la máquina, de la próxima entrada libre o a la última utilizada. Análogamente, la máquina indica la dirección de crecimiento de la pila, hacia las direcciones altas o bajas. Un marco de pila contiene usualmente la siguiente información: los parámetros de la función, sus variables locales y las direcciones almacenadas en el instante de la llamada a la función en diferentes registros especiales de la máquina, como por ejemplo, el contador del programa y el puntero de la pila. Salvar el contenido del contador del programa permite conocer la dirección de retorno donde debe continuar la ejecución una vez que se ha ejecutado la función. Mientras que salvar el contenido del registro de pila permite conocer la ubicación del marco de pila anterior o del siguiente libre.En la AQUÍ VA UNA IMAGEN3-2 se representa a modo de ejemplo un diagrama del espacio de direcciones de memoria virtual de un proceso. Se observa que el proceso posee tres regiones: código, datos y pila. La dirección virtual de inicio de la región (DIRV0) de código es DIRV0=0 K. Por su parte la región de datos comienza en DIRV0=64 K para su zona estática y DIRV0=128 K para su zona dinámica. Finalmente, la región de pila o pila de usuario comienza en DIRV0=256 K. AQUÍ VA UNA IMAGEN3-2: Diagrama del espacio de direcciones de memoria virtual de un proceso\nAdemás se observa la existencia de dos regiones de direcciones de memoria virtual libre (no asignada) la primera comienza en DIRV0=32 K y la segunda en DIRV0=224 K.\nAdemás de las regiones descritas, existe otra parte del espacio de direcciones virtuales de un proceso denominada espacio del núcleo que se utiliza para ubicar estructuras de datos relativas a dicho proceso que son utilizadas por el núcleo. Existen básicamente dos estructuras locales a un proceso que deben ser manipuladas por el núcleo y que se suelen implementar en el espacio de direcciones del proceso: el área de usuario o área U y la pila del núcleo. Conceptualmente ambas estructuras aunque locales a un proceso son propiedad del núcleo. Obviamente, estas estructuras sólo pueden ser accedidas en modo núcleo o supervisor.\n ## Operaciones con regiones implementadas por el núcleo\nEl núcleo dispone de una estructura local asociada a cada proceso denominada tabla de regiones por proceso, que mantiene información relevante sobre las regiones de código, datos, pila de usuario y memoria compartida (si existe) de un cierto proceso. Cada entrada de esta tabla contiene un puntero que apunta a una entrada de la tabla de regiones. Ésta es una estructura global del núcleo que contiene información sobre cada región. Las entradas de la tabla de regiones se organizan en dos listas: una lista enlazada de regiones libres y una lista enlazada de regiones activas. Simultáneamente una entrada sólo puede pertenecer a una de las dos listas.\nExisten varias llamadas al sistema (fork, exec, ...) que tienen que manipular durante su ejecución el espacio de direcciones virtuales de un proceso. El núcleo dispone de algoritmos bien definidos para la realización de diferentes operaciones con las regiones. Las principales operaciones con regiones implementadas por el núcleo son:\n- Bloquear y desbloquear una región. El núcleo debe bloquear una región para prevenir los posibles accesos de otros procesos mientras se encuentra trabajando con ella. Cuando termina de usarla la desbloquea. Estas operaciones son independientes de las operaciones de asignar y liberar una región.\n- Asignar una región. Consiste en eliminar la primera entrada disponible de la lista enlazada de regiones libres y situarla en la lista enlazada de regiones activas. El núcleo implementa esta operación con el algoritmo allocreg()9. Las llamadas al sistema que usan esta operación son: fork, exec y shmget.\n- Ligar una región al espacio de direcciones virtuales de un proceso. Consiste en asociar a una región (que previamente ha tenido que ser asignada) una entrada de la tabla de regiones por proceso. El núcleo implementa esta operación con el algoritmo attachreg(). Las llamadas al sistema que usan esta operación son: fork, exec y shmat.\n- Cambiar el tamaño de una región. Las únicas regiones cuyo tamaño pueden ser modificados son las regiones de datos y de pila. Las regiones de código y las regiones de memoria compartida no pueden crecer después de ser inicializadas. El núcleo implementa esta operación con el algoritmo growreg(). Existen dos llamadas al sistema brk y sbrk que usan esta operación, ambas trabajan con la región de datos. Además el núcleo también utiliza esta operación para implementar el crecimiento de la pila de usuario.\n- Cargar una región con el contenido de un fichero. El núcleo implementa esta operación con el algoritmo loadreg() que es usada por la llamada al sistema exec.\n9 Los nombres de los algoritmos del núcleo que aparecen en este capítulo son los de la distribución SVR3.-\nDesligar una región del espacio de direcciones de un proceso. El núcleo implementa esta operación con el algoritmo detachreg(). Las llamadas al sistema que usan esta operación son: exec, exit y shmdt.\nLiberar una región. Cuando una región ya no está unida a ningún proceso, el núcleo puede liberar la región y devolverla a la lista enlazada de regiones libres. El núcleo implementa esta operación con el algoritmo freereg().\nDuplicar una región. El núcleo implementa esta operación con el algoritmo dupreg(), que es usado por la llamada al sistema fork."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Identificadores numéricos asociados a un proceso ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Identificador del proceso\nPuesto que UNIX es un sistema multitarea, necesita identificar de forma precisa a cada proceso que se está ejecutando en el sistema. La forma de identificación utilizada es asignar a cada proceso un número entero positivo distinto denominado identificador del proceso o pid. Luego los posibles valores de un pid son\npid {0,1,2,3,..., pidmax \ndonde pidmax es el valor más grande que puede asignar el núcleo al pid de un proceso.\nCuando el sistema operativo arranca crea un proceso especial denominado proceso 0 al que asigna un pid=0. Poco después el proceso 0 genera un proceso hijo denominado proceso inicial cuyo pid=1, a continuación el proceso 0 se convierte en el proceso intercambiador (swapper). El proceso inicial es el responsable de arrancar al resto de procesos del sistema y en consecuencia es el proceso padre de todos ellos. Si el núcleo necesita asignar un pid a un nuevo proceso y ya ha asignado el valor pidmax entonces realiza una búsqueda de pid libres comenzando desde 0. Muchos procesos tienen un tiempo de ejecución muy corto, así que probablemente habrá muchos números pid sin utilizar.\nLa llamada al sistema getpid devuelve el pid del proceso que realiza esta llamada. Su sintaxis es:salida=getpid();\nSe observa que no requiere de ningún parámetro de entrada. Si la llamada al sistema se ejecuta con éxito salida tendrá asignado el valor del pid del proceso. En caso contrario contendrá el valor -1.\nAsimismo la llamada al sistema getppid devuelve el pid del proceso padre del proceso que realiza esta llamada. Su sintaxis es análoga a la de getpid."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Identificadores de usuario y de grupo",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "Ejemplo_3-4-2"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Estructuras de datos del núcleo asociadas a los procesos",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "l núcleo mantiene diferentes estructuras de datos asociadas a los procesos, las cuales son imprescindibles para la ejecución de los mismos. Algunas de estas estructuras como la pila del núcleo, el área U y la tabla de regiones por proceso son locales a cada proceso, es decir, cada proceso tiene asignada su propia estructura privada. Otras estructuras, como la tabla de procesos y la tabla de regiones son globales para todos los procesos, es decir, sólo existe en el núcleo una estructura para todos los procesos.\nPor otra parte, algunas de estas estructuras como la pila del núcleo y el área U se implementan en el espacio de direcciones virtuales de cada proceso. Mientras que otras como la tabla de procesos, la tabla de regiones por proceso y la tabla de regiones se implementan en el espacio de direcciones virtuales del núcleo. Todas estas estructuras tienen en común que son propiedad del núcleo y por tanto solo pueden ser accedidas en modo núcleo.\nOtras estructuras de datos del núcleo asociadas a los procesos son las tablas de páginas y la tabla de descriptores de ficheros. Las tablas de páginas permiten traducir las direcciones de memoria virtual a direcciones de memoria física, (se estudiarán en el Capítulo 0). Por su parte, la tabla de descriptores de ficheros identifica a los ficheros abiertos por un proceso."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Pila del núcleo",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "Ejemplo_3-5-1"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Estructuras de datos del núcleo asociadas a los procesos 2",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Tabla de procesos\nLa tabla de procesos es una estructura global del núcleo donde se almacena información de control relevante sobre cada proceso existente en el sistema. Cada entrada de la tabla de procesos contiene distintos campos con información sobre un determinado proceso, como por ejemplo:\n- El identificador del proceso (pid).\n- Los identificadores de usuario (uid, euid) y de grupo (gid, egid) del proceso.\n- Punteros que permiten al núcleo localizar la tabla de regiones por proceso y el área U del proceso.\n- El estado del proceso. Un proceso durante su tiempo de vida puede pasar por diferentes estados (se estudian en la sección 3.9), cada uno de los cuales posee ciertas características que determinan el comportamiento del proceso.\n- Punteros para enlazar a los procesos en diferentes listas, las cuales permiten al núcleo controlar a los procesos, como por ejemplo, la lista de procesos planificados para ejecución, la lista de procesos dormidos, etc.\n- Canal o dirección de dormir asociada al evento por el que el proceso ha entrado en el estado dormido.- Información asociada a la prioridad de planificación del proceso que es consultada por el algoritmo de planificación del núcleo para determinar qué proceso debe pasar a utilizar el procesador.\n- Información asociada al tratamiento de las señales como por ejemplo, las máscaras de las señales que son ignoradas, bloqueadas, notificadas y tratadas.\n- Información genealógica, que describe la relación de este proceso con otros procesos, como por ejemplo, el pid de su proceso padre, un puntero al primer hijo creado, un puntero al último hijo creado, etc.\n- El tiempo de ejecución del proceso y el tiempo de utilización de los recursos de la máquina. Estas informaciones son usadas por el núcleo, entre otras cosas, para el cálculo del valor de la prioridad de planificación del proceso.\n ## Área U\nEl área de usuario o área U es una estructura local asociada a cada proceso que contiene información de control relevante sobre el mismo que el núcleo necesita consultar únicamente cuando ejecuta dicho proceso. Entre la información contenida en los campos del área U se encuentra:\n- Un puntero a la entrada de la tabla de procesos asociada a dicho proceso.\n- Los identificadores de usuario (uid, euid) y de grupo (gid, egid) del proceso. No debe extrañar la aparición de esta información tanto en el área U como en la entrada de la tabla de procesos asociada al proceso. Sin entrar en detalles más precisos, comentar únicamente que los identificadores de usuario y de grupo almacenados en el área U pueden, en determinadas circunstancias, diferir de los almacenados en la tabla de procesos.\n- Los argumentos de entrada, los valores de retorno y el identificador del error (si se produjese) de la llamada al sistema en ejecución.\n- Las direcciones de los manipuladores de las señales y otras informaciones relacionadas.\n- Información acerca de las regiones de código, datos y pila obtenida de la cabecera del programa.\n- La tabla de descriptores de ficheros que mantiene información sobre los ficheros abiertos por el proceso.\n- El directorio de trabajo actual y el directorio raíz actual.\n- El terminal de acceso asociada con el proceso, si existe alguno.\n- Estadísticas de uso de la CPU.\nEl área U de un proceso se puede considerar en ciertos aspectos como una extensión de la entrada asignada a dicho proceso en la tabla de procesos. Sin embargo, mientras que la información contenida en la tabla de procesos debe ser estar siempre accesible para el núcleo, el área U contiene información que necesita únicamente estar accesible para el núcleo cuando se está ejecutando el proceso.\nComo se justificará en la sección 7.9, el núcleo puede acceder directamente a los campos del área U del proceso que se está ejecutando pero no al área U de otros procesos. Internamente, el núcleo referencia a una variable denominada u para acceder al área U del proceso (A) que actualmente se está ejecutando. Cuando se ejecuta otro proceso (B), el núcleo reorganiza su espacio de direcciones virtuales de forma que la variable u referencie al área U del nuevo proceso B. Esta implementación permite al núcleo identificar fácilmente al proceso actual siguiendo el campo puntero del área U que apunta a la correspondiente entrada de la tabla de procesos.\n ## Tabla de regiones por proceso\nLa tabla de regiones por proceso es un estructura local a cada proceso que contiene una entrada por cada región (código, datos y pila de usuario) asociada al proceso. Si existen regiones de memoria compartida cada una de ellas también tendrá asignada una entrada.\nCada entrada de la tabla de regiones por proceso apunta a una entrada en la tabla de regiones y contiene la dirección virtual de comienzo de una región. Este nivel extra de direccionamiento (desde la tabla de regiones por proceso a la tabla de regiones) permite que procesos independientes puedan compartir regiones. Además cada entrada contieneel tipo de acceso permitido al proceso sobre dicha región: sólo lectura, lectura y escritura, o lectura y ejecución.\nLa tabla de regiones por proceso de un proceso puede implementarse dentro de la entrada de la tabla de procesos asociada a dicho proceso, o puede implementarse dentro del área U de dicho proceso. También puede implementarse en un área de memoria independiente.\n ## Tabla de regiones\nLa tabla de regiones es una estructura global del núcleo que contiene una entrada por cada región asignada por el núcleo. Cada entrada de esta tabla contiene la información necesaria para describir una región, como por ejemplo:\nUn puntero al nodo-i del fichero cuyo contenido fue cargado dentro de la región.\nEl tipo de región (código, datos, pila de usuario o memoria compartida).\nEl tamaño de la región.\nLa localización de la región en memoria principal, típicamente un puntero a una tabla de páginas.\nEl estado de la región, que puede ser una combinación de: bloqueada, bajo demanda, en proceso de ser cargada en memoria y válida (cargada en memoria).\nEl contador de referencias, que indica el número de procesos que están referenciando a una región.\nLas entradas de la tabla de regiones se organizan en dos listas: una lista enlazada de regiones libres y una lista enlazada de regiones activas. Simultáneamente una entrada sólo puede pertenecer a una de las dos listasEn la AQUÍ VA UNA IMAGEN3-4 se representa un posible diagrama que relaciona a las estructuras de datos del núcleo asociadas a los procesos: pila del núcleo, área U, tabla de procesos, tabla de regiones por proceso y tabla de regiones. En concreto se han considerado dos procesos: el proceso A y el proceso B.\nEn este diagrama se observa claramente el carácter local y global de las diferentes estructuras. Así el proceso A y el proceso B poseen cada uno de ellos su propia pila del núcleo, área U y tabla de regiones por proceso. Mientras que la tabla de procesos y la tabla de regiones son comunes para todos los procesos.\nAsimismo, en este diagrama se observa claramente la relación existente entre estas estructuras. Por ejemplo, el área U del proceso A apunta a la entrada asociada a dicho proceso en la tabla de procesos. A su vez dicha entrada posee un puntero tanto al área U como a la tabla de regiones por proceso asociadas al proceso A. Esta tabla posee tres entradas asociadas cada una de ellas a las regiones de código, datos y pila de usuario del proceso A. Cada una de las entradas de la tabla de regiones por proceso contiene un puntero a una entrada de la tabla de regiones. Relaciones análogas se aprecian para el proceso B.\nAQUÍ VA UNA IMAGEN3-4: Estructura de datos del núcleo asociadas a los procesos A y B\nAdemás, se observa en la tabla de regiones que el proceso A y el proceso B tienen una región común. Por lo tanto, el contador de referencias de esta región contendrá el valor 2, mientras que el resto tendrá el valor 1."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Contexto de un proceso ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,           "content": "## Definición\nDe forma general, el contexto de un proceso en un cierto instante de tiempo se puede definir como la información relativa al proceso que el núcleo debe conocer para poder iniciar o continuar su ejecución. Cuando se ejecuta un proceso se dice que el sistema se ejecutaen el contexto de dicho proceso. Por lo que cuando el núcleo decide pasar a ejecutar otro proceso debe cambiar de contexto, de forma que el sistema pasará a ejecutarse en el contexto del nuevo proceso.\nEl contexto de un proceso en un cierto instante de tiempo está formado por su espacio de direcciones virtuales, los contenidos de los registros hardware de la máquina y las estructuras de datos del núcleo asociadas a dicho proceso. Formalmente, el contexto de un proceso se puede considerar como la unión del contexto a nivel de usuario, contexto de registros y contexto a nivel del sistema.\nEl contexto a nivel de usuario de un proceso está formado por su código, datos, pila de usuario y memoria compartida que ocupan el espacio de direcciones virtuales del proceso.\nEl contexto de registros de un proceso está formado por el contenido de los siguientes registros de la máquina:\n- El contador del programa que indica la dirección de la siguiente instrucción que debe ejecutar la CPU. Esta dirección es una dirección virtual del espacio de memoria del núcleo o del usuario.\n- El registro de estado del procesador que indica el estado del hardware de la máquina en relación al proceso en ejecución. Contiene diferentes campos para almacenar la siguiente información: el modo de ejecución, el nivel de prioridad de interrupción, el indicador de rebose, el indicador de arrastre, etc.\n- El puntero de la pila donde se almacena la dirección virtual, dependiendo de la arquitectura de la máquina, de la próxima entrada libre o de la última utilizada en la pila de usuario (ejecución en modo usuario) o en la pila del núcleo (ejecución en modo núcleo). Análogamente, la máquina indica la dirección de crecimiento de la pila, hacia las direcciones altas o bajas.\n- Los registros de propósito general, que contienen datos generados por el proceso durante su ejecución. Para simplificar la discusión, se van a considerar sólo dos registros, el registro 0 y el registro 1.\nEl contexto a nivel del sistema de un proceso está formado por: la entrada de la tabla de procesos asociada a dicho proceso, su área U, su pila del núcleo, su tabla de regiones\npor proceso, las entradas de la tabla de regiones apuntadas por las entradas de su tabla de regiones por proceso y las tablas de páginas asociadas a dichas entradas de la tabla de regiones.\n ## Parte estática y parte dinámica del contexto de un proceso\nDurante el tiempo de vida de un proceso pueden producirse distintos sucesos, como por ejemplo: llamadas al sistema, interrupciones, cambios de contexto... Al atenderse a estos sucesos algunos elementos del contexto del proceso van a cambiar su contenido. Se hace necesario por tanto almacenar el contenido de estos elementos para que una vez atendido el suceso, y si no existe otro suceso pendiente, continuar con la ejecución en modo usuario del proceso.\nPor tanto, en el contexto de un proceso se distinguen una parte dinámica, cuyo contenido es necesario salvar ante la aparición de ciertos sucesos, y una parte estática, cuyo contenido no es necesario salvar. La parte dinámica de un proceso está formada por el contexto a nivel de registros y su pila del núcleo. Los restantes elementos del contexto de un proceso constituyen su parte estática.\n    CONTEXTO DE UN PROCESO\nContexto a nivel de usuario\nContexto\nde registros (*)\nContexto a nivel del sistema\n- Código\n- Datos\n- Pila de usuario\n- Memoria compartida\n- Contador del programa\n- Registro de estado del procesador\n- Puntero de la pila\n- Registros de propósito general (registro 0 y registro 1)\n- Entrada asociada al proceso de la tabla de procesos. - Área U\n- Pila del núcleo (*)\n- Tabla de regiones por proceso\n- Entradas de la tabla de regiones apuntadas por las entradas de la tabla de regiones por proceso\n- Tablas de páginas apuntadas por estas entradas de la tabla de regiones\n- Pila de capas de contexto (*)\n Nota: Los elementos marcados con (*) constituyen la parte dinámica del contexto\nAQUÍ VA UNA IMAGEN3-5 : Contexto de un procesoA la parte dinámica del contexto de un proceso que ha sido salvada se le denomina capa de contexto. Así durante el tiempo de vida de un proceso dependiendo de la secuencia de sucesos que se produzcan pueden existir varias capas de contexto. La manipulación que el núcleo realiza de las capas de contexto puede visualizarse como una pila, denominada pila de capas de contexto.\nEl Sistema Operativo mantiene una región por cada proceso denominada área de usuario o Área U, este área es de acceso privado del núcleo y contiene información administrativa para gestionar el proceso y es accesible cuando el proceso se encuentra en ejecución.\nEl área U contiene el bloque de control de proceso PCB, el puntero al proceso, los UIDs del proceso, información de las llamadas al sistema (argumentos, resultados y mensajes de error), manejadores de error y sus informaciones asociadas, información de la cabecera del programa (tamaño, texto, datos, tamaño de la pila, etc...), descriptores de ficheros abiertos, información acerca de los terminales asociados al proceso, estadísticas del proceso así como la pila del núcleo asociada al proceso. Puesto que el área U contiene partes estáticas y dinámicas en la AQUÍ VA UNA IMAGEN3-5 se muestran dichas partes por separado. Además la pila de capas de contexto se almacenan en el área U.\nLa pila de capas de contexto también se considera como un elemento de la parte dinámica del contexto de un proceso, en concreto, del contexto a nivel del sistema. En el AQUÍ VA UNA IMAGEN3-5 se resume la información que forma parte del contexto de un proceso.\nEl núcleo almacena en la entrada de la tabla de procesos asociada al proceso en ejecución la información necesaria para localizar la capa de contexto superior de la pila de capas de contexto asociada al proceso. De esta forma el núcleo conoce dónde debe almacenar una nueva capa de contexto o dónde debe buscar la última capa de contexto almacenada.\nEl núcleo añade una capa de contexto en la pila de capas de contexto de un proceso en los siguientes casos:\n- Cuando se produce una interrupción.\n- Cuando el proceso realiza una llamada al sistema.\n- Cuando se produce un cambio de contexto.\nAsimismo, el núcleo extrae una capa de contexto de la pila de capas de contexto de un proceso cuando:\n- El núcleo vuelve de manipular una interrupción.\n- El proceso vuelve al modo usuario después de que el núcleo completa la ejecución\nde una llamada al sistema.\n- Se produce un cambio de contexto.\nSe observa por tanto, que la realización de un cambio de contexto (se estaba ejecutando un proceso A y se pasa a ejecutar otro proceso B) provoca tanto la acción de añadir una capa de contexto (en la pila de capas de contexto del proceso A) como la de extraer una capa de contexto (en la pila de capas de contexto del proceso B).\nEl número de capas de contexto de la parte dinámica está limitado por el número de niveles de interrupción que soporte la máquina. Por ejemplo, supóngase que una máquina soporta seis niveles de interrupción (ver AQUÍ VA UNA IMAGEN1-2). En este caso, la pila de capas de contexto de un proceso podrá contener como máximo ocho capas de contexto: una para cada nivel de interrupción, una para las llamadas al sistema y otra más para mantener el nivel de usuario. Estas ocho capas son suficientes para mantener a todas las interrupciones aunque las interrupciones ocurran en la peor secuencia posible, ya que una interrupción dada estará bloqueada mientras el núcleo manipula interrupciones de ese nivel o superior.\nEn el siguiente ejemplo se va a usar la siguiente notación:\nRE: contexto a nivel de registros del proceso A.\nPN: pila del núcleo asociada al proceso A.\nREti: contenido de RE en un cierto instante de tiempo ti.\nPNti: contenido (marcos de pila) de PN en un cierto instante de tiempo ti. PCC: pila de capas de contexto asociada al proceso A.\nSupóngase que un proceso A se está ejecutando en modo usuario y que se produce la siguiente secuencia de sucesos:\nEn el instante de tiempo t0 el proceso A invoca a una llamada al sistema, por lo que se cambia de modo usuario a modo núcleo y se comienza atender la llamada al sistema. En este caso se añade una capa de contexto en su PCC que estaba inicialmente vacía al estar el proceso ejecutándose en modo usuario. A dicha capa de contexto se la va a denotar como capa 0 y su contenido será únicamente REt0 ya \nque en modo usuario su PN está vacía. Esta capa contiene la información necesaria para poder continuar con la ejecución del proceso A en modo usuario una vez se haya atendido la llamada al sistema.\nEn el instante de tiempo t1 mientras se está ejecutando la llamada al sistema llega una interrupción del disco duro que por su nivel de prioridad debe ser atendida. Por ello se detiene la ejecución de la llamada al sistema y se comienza a ejecutar la rutina de servicio o manipulador de la interrupción del disco duro. En este caso se añade una capa de contexto en su PCC. A dicha capa de contexto se la va a denotar como capa 1 y su contenido será REt1 y PNt1. Esta capa contiene la información necesaria para poder continuar con la ejecución de la llamada al sistema una vez sea atendida la interrupción del disco duro.\nEn el instante de tiempo t2 mientras se está ejecutando la rutina de servicio del disco duro llega una interrupción del reloj que por su nivel de prioridad debe ser atendida. Por ello se detiene la ejecución de rutina de servicio del disco duro y se comienza a ejecutar la rutina de servicio del reloj. En este caso se añade una capa de contexto en su PCC. A dicha capa de contexto se le va a denotar como capa 2 y su contenido será REt2 y PNt2. Esta capa contiene la información necesaria para poder continuar con la ejecución de la rutina de servicio del disco duro una vez sea atendida la interrupción del reloj.\nEn el instante de tiempo t3 finaliza la ejecución de la rutina de servicio del reloj y se continúa con la ejecución de la rutina de servicio del disco duro. Para poder continuar atendiendo la interrupción del disco duro desde el mismo punto donde lo dejó el núcleo extrae la capa 2 de la PCC e inicializa RE y PN con los valores REt2 y PNt2, respectivamente.\nEn el instante de tiempo t4 finaliza la ejecución de la rutina de servicio del disco duro y se continúa con la ejecución de la llamada al sistema. Para poder continuar ejecutando la llamada al sistema desde el mismo punto donde lo dejó el núcleo extrae la capa 1 de la PCC e inicializa RE y PN con los valores REt1 y PNt1, respectivamente.\nEn el instante de tiempo t5 finaliza la ejecución de la llamada al sistema, por lo que se cambia a modo usuario y se continua con la ejecución del proceso A. Para poder continuar ejecutando el código del proceso en modo usuario extrae la capa 0 de la PCC e inicializa RE con el valor REt0 recuérdese que en modo usuario la pila del núcleo del proceso A está vacía.\nEn la AQUÍ VA UNA IMAGEN3-6 se representa un diagrama con la configuración de la PCC del proceso A durante los distintos sucesos considerados.\nEjecución en modo usuario del proceso A\nEjecución llamada al sistema\nEjecución rutina de servicio del disco duro\nEjecución rutina de servicio del reloj\nEjecución rutina de servicio del disco duro\nEjecución llamada al sistema\nEjecución en modo usuario del proceso A\nREt0\nREt1 PNt1\nREt0\nREt2 PNt2\nREt1 PNt1 REt1 PNt1\nREt0 REt0 REt0\nCapa 2 Capa 1 Capa 0\nu.t.\nt0 t1 t2 t3 t4 t5\nAQUÍ VA UNA IMAGEN3-6: Configuración de la pila de capas de contexto del proceso A durante los distintos sucesos considerados\n ## Salvar y restaurar el contexto de un proceso\nSe entiende por salvar el contexto de un proceso a la acción del núcleo de añadir una capa de contexto en la pila de capas de contexto asociada a dicho proceso. Por lo tanto, cuando se produce un cierto suceso, como una interrupción, una llamada al sistema o un cambio de contexto, no se salva todo el contexto del proceso propiamente dicho, sino solamente la parte dinámica del mismo que puede ser modificada durante la ejecución de otro proceso, en concreto, el contexto de registros y la pila del núcleo.\nAsimismo se entiende por restaurar el contexto de un proceso a la acción del núcleo de extraer la capa superior de la pila de capas de contexto asociada a dicho proceso e inicializar el contexto de registros y la pila del núcleo con los valores que se habían salvado en dicha capa. Por lo tanto, se deberá restaurar el contexto de un proceso cuando se termina de atender una interrupción, cuando se vuelve a modo usuario tras finalizar una llamada al sistema o cuando se realiza un cambio de contexto.\nLas operaciones asociadas a salvar o restaurar el contexto de un proceso se suelen implementar por hardware o microcódigo, ya que se obtiene una mayor velocidad en su realización. En consecuencia, la implementación de estas acciones es fuertemente dependiente de la máquina.\nEn ciertas circunstancias, el núcleo debe realizar una vuelta abortiva, es decir, abortar su secuencia de ejecución actual, restaurar una capa de contexto salvada con anterioridad en el área U del proceso, y reiniciar su ejecución dentro del contexto restaurado. El núcleo usa el algoritmo setjmp() para salvar una capa de contexto en el área U del proceso. Asimismo, usa el algoritmo longjmp()para extraer dicha capa salvada en el área U e inicializar el contexto de registros y la pila del núcleo con los valores que se habían salvado en dicha capa. Los algoritmos del núcleo setjmp() y longjmp() no deben ser confundidos con las funciones de librería que tienen el mismo nombre. No obstante, su utilidad es muy parecida.\n ## Cambio de contexto\nSe define el cambio de contexto como el conjunto de tareas que debe realizar el núcleo para aplazar o finalizar la ejecución del proceso (A) actualmente en ejecución, y comenzar o continuar con la ejecución de otro proceso (B).Cuando se ejecuta un proceso se dice que el sistema se ejecuta en el contexto de dicho proceso. Por lo que cuando el núcleo realiza un cambio de contexto, pasará de ejecutarse en el contexto del proceso A, a ejecutarse en el contexto del proceso B.\nEntre las principales circunstancias que motivan la realización de un cambio de contexto se encuentran:\n- La entrada de un proceso en el estado dormido. Como se verá en la sección 4.8 uno de los posibles estados en que se puede encontrar un proceso es en el estado dormido. Un proceso entra en dicho estado cuando por ejemplo tiene que esperar por una operación de E/S con el disco duro. La realización de un cambio de contexto en esta circunstancia está plenamente justificada ya que puede transcurrir una cierta cantidad de tiempo hasta que el proceso despierte, con lo que mientras tanto se pueden ejecutar otros procesos.\n- La finalización de la ejecución de una llamada al sistema exit. Esta llamada al sistema provoca la terminación del proceso en cuyo contexto se está ejecutando el núcleo. Por lo tanto, puesto que el proceso actual ha sido finalizado el núcleo debe hacer un cambio de contexto para continuar o iniciar la ejecución de otro proceso.\n- La vuelta al modo usuario tras ejecutarse una llamada al sistema y la existencia de un proceso esperando para ser ejecutado con mayor prioridad de planificación que el actual. En este caso se produce un cambio de contexto porque si hay otro proceso con mayor prioridad de planificación, sería injusto mantenerle esperando.\n- La vuelta al modo usuario tras atenderse una interrupción y la existencia de un proceso esperando para ser ejecutado con mayor prioridad de planificación que el actual. La justificación del cambio de contexto en esta circunstancia es análoga al caso anterior.\n- La finalización del tiempo de uso del procesador de un proceso ejecutándose en modo usuario. En esta circunstancia, de acuerdo con el tipo de algoritmo de planificación utilizado en UNIX, se planifica otro proceso para ser ejecutado en modo usuario y por tanto es necesario realizar un cambio de contexto.\nEl algoritmo del núcleo que implementa un cambio de contexto es de los más difíciles de entender del sistema operativo. Desde un punto de vista introductorio basta con conocer\nque las principales tareas que realiza el algoritmo del núcleo para implementar un cambio de contexto son:\n- Decidir si hay que hacer un cambio de contexto, de acuerdo con las circunstancias que lo motivan expuestas anteriormente, y si puede realizarse en el instante actual.\n- Salvar el contexto del proceso actual (A).\n- Usar el algoritmo de planificación de procesos para elegir el próximo proceso (B) cuya\nejecución se va a iniciar o se va a continuar.\n- Restaurar el contexto del proceso (B) que ha sido elegido para ser ejecutado.\nAntes de hacer un cambio de contexto, el núcleo debe asegurarse de que el estado de sus estructuras de datos sea consistente, es decir, que se hayan hecho todas las actualizaciones correctamente, que las colas estén enlazadas apropiadamente, que se han colocado los bloqueos adecuados para evitar la intrusión de otros procesos, que no se ha quedado bloqueada innecesariamente ninguna estructura de datos, etc."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Tratamiento de las interrupciones",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "Las interrupciones (hardware o software) son atendidas en modo núcleo dentro del contexto del proceso que se encuentra actualmente en ejecución, aunque dicha interrupción no tenga nada que ver con la ejecución de dicho proceso.\nEn la siguiente descripción del tratamiento de las interrupciones se van a utilizar, por simplificar, las siguientes abreviaturas:\n- npi, es el nivel de prioridad de interrupción actual almacenado en el registro de estado del procesador.\n- npii, es el nivel de prioridad de interrupción asociado a un determinado tipo de interrupción.\nCuando se produce una interrupción, ésta es tratada por el núcleo si npii>npi, en dicho caso el núcleo invoca al algoritmo inthand() para el tratamiento de las interrupciones. Este algoritmo realiza principalmente las siguientes acciones:\nSalvar el contexto del proceso actual.Elevar el nivel de prioridad de interrupción. Es decir, se hace npi=npii. Por tanto, las interrupciones que lleguen con un nivel de prioridad de interrupción igual o menor que npi quedan bloqueadas o enmascaradas temporalmente. De esta forma se logra preservar la integridad de las estructuras de datos del núcleo.\nObtener el vector de interrupción. Normalmente, las interrupciones aparte del npii pasan al núcleo alguna información que le permite identificar el tipo de interrupción de que se trata. En un sistema con interrupciones vectorizadas, cada dispositivo suministra al núcleo un número único denominado número del vector de interrupción que se utiliza como un índice en una tabla, denominada tabla de vectores de interrupción. Cada entrada de esta tabla es un vector de interrupción, que contiene, entre otras informaciones, un puntero al manejador o rutina de servicio de la interrupción apropiada.\nInvocar al manipulador o rutina de servicio de la interrupción.\nRestaurar el contexto del proceso, una vez que se ha concluido la rutina de servicio\nde la interrupción.\nEn consecuencia cuando finaliza inthand() el nivel del npi es restaurado al valor que tenía antes de atenderse la interrupción.\nLas peticiones de interrupción que pudieran haber quedado bloqueadas o enmascaradas durante la ejecución de inthand() son almacenadas en un registro especial de peticiones de interrupción. Estas interrupciones serán atendidas cuando el npi disminuya suficientemente.\nAlgunas máquinas disponen de una pila especial denominada pila de interrupciones que es utilizada por todos los manejadores de interrupciones. En las máquinas que no disponen de un pila de interrupciones los manejadores utilizan la pila del núcleo asociada al proceso.\nPor otra parte, el tratamiento de la interrupción provoca un pequeño impacto en el proceso en cuyo contexto es atendida, ya que el tiempo utilizado para atender la interrupción es cargado al cuanto del proceso. Asimismo, es importante resaltar que el contexto del proceso no está protegido de forma explícita de ser accedido por los manipuladores de interrupciones. Un manipulador incorrectamente escrito potencialmente puede corromper cualquier parte del espacio de direcciones del proceso."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "Interfaz de las llamadas al sistema",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},	"content": "",
"code_url": "Ejemplo_3-8"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Estados de un proceso ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,           "content": "## Consideraciones generales\nEl tiempo de vida de un proceso en un sistema UNIX puede ser conceptualmente dividido en un conjunto de estados que describen el comportamiento del proceso. Los nueve estados en que se puede encontrar un proceso en un sistema UNIX (SVR2 o SVR3) son:\n- Ejecutándose en modo usuario.\n- Ejecutándose en modo núcleo o supervisor.\n- Preparado en memoria principal para ser ejecutado. El proceso no está ejecutándose, pero está cargado en memoria principal listo para ser ejecutado tan pronto lo planifique el núcleo.\n- Dormido o bloqueado en memoria principal. El proceso se encuentra esperando en memoria principal a que se produzca un determinado evento, como por ejemplo, la finalización de una operación de E/S.\n- Preparado en memoria secundaria para ser ejecutado. El proceso está listo para ser ejecutado pero se encuentra en memoria secundaria.\n- Dormido o bloqueado en memoria secundaria. El proceso está esperando en memoria secundaria a que se produzca un determinado evento.\n- Creado. El proceso se ha creado recientemente y está en un estado de transición. El proceso existe, pero no se encuentra preparado para ser ejecutado ni tampoco está dormido. Este estado es el inicial para todos los procesos excepto para el proceso con pid=0.\n- Zombi. Este es el estado final de un proceso al que se llega mediante la ejecución explícita o implícita de la llamada al sistema exit.\nEn la AQUÍ VA UNA IMAGEN3-10 se representa el diagrama de transición de estados de los procesos en un sistema UNIX (SVR2 o SVR3). En dicho diagrama los nodos representan a los posibles estados de un proceso. Asimismo las líneas de conexión representan las posibles transiciones entre los estados. Estas líneas de conexión se encuentran rotuladas con el evento que provoca que un proceso pase de un estado a otro. Una transición entre dos estados es legal si existe una línea de conexión en el sentido adecuado que los una. AQUÍ VA UNA IMAGEN3-10: Diagrama de transiciones de estado en un sistema UNIX (SVR2 o SVR3)\nSe van a analizar a continuación las posibles transiciones de estado, partiendo del nacimiento de un proceso. Cuando un nuevo proceso A se crea, mediante una llamada al sistema fork realizada por otro proceso B, el primer estado en el que entra A es el estado creado. Desde aquí puede pasar, dependiendo de si existe suficiente espacio en memoria principal, a dos estados distintos: preparado para ejecución en memoria principal o preparado para ejecución en memoria secundaria.\nSi el proceso se encuentra en el estado preparado para ejecución en memoria principal entonces el planificador de procesos puede escogerlo para ser ejecutado, por lo que pasará al estado ejecución en modo núcleo. Cuando el proceso finalice la ejecución de su parte de la llamada al sistema fork entonces pasará al estado ejecución en modo usuario, donde comenzarán a ejecutarse las instrucciones de la región de código del proceso.\nCuando el proceso agota su cuanto, el reloj del sistema mandará una interrupción al procesador. El tratamiento de las interrupciones se realiza en modo núcleo, en conclusión, el proceso debe pasar de nuevo al estado ejecutándose en modo núcleo. Cuando el manipulador de la interrupción de reloj finaliza, el planificador expropiará de la CPU al\nproceso A y planificará otro proceso C para ser ejecutado. De esta forma, el proceso A pasa de nuevo al estado preparado para ejecución en memoria principal donde permanecerá hasta que el planificador vuelva a seleccionar al proceso A.\nSi el proceso A invoca durante su ejecución en modo usuario a una llamada al sistema, entonces pasa al estado ejecución en modo núcleo. Supóngase que la llamada al sistema necesita realizar una operación de E/S con el disco, entonces el núcleo debe esperar a que se complete la operación, en consecuencia el proceso A pasa al estado dormido en memoria principal. Cuando se completa la operación de E/S, el hardware interrumpe a la CPU y el manipulador de la interrupción despertará al proceso, lo que provocará que pase al estado preparado para ejecución en memoria principal.\nSupóngase que en el sistema se están ejecutando muchos procesos y que no existe suficiente espacio en memoria. En esta situación el intercambiador elige para ser intercambiados a memoria secundaria a algunos procesos (entre ellos el proceso A) que se encuentran en el estado preparado para ejecución en memoria principal. Estos procesos pasarán al estado preparado para ejecución en memoria secundaria.\nEn un momento dado, el intercambiador elige al proceso más apropiado para intercambiarlo de vuelta a la memoria principal, supóngase que se trata del proceso A. Éste pasa al estado listo para ejecución en memoria. A continuación, el planificador en algún instante elegirá el proceso para ejecutarse y entonces pasará al estado ejecución en modo supervisor donde continuará con la ejecución de la llamada al sistema. Cuando finalice la llamada al sistema pasará de nuevo al estado ejecución en modo usuario.\nCuando el proceso se complete, invocará explícitamente o implícitamente a la llamada al sistema exit, en consecuencia pasará al estado ejecución en modo supervisor. Cuando se complete esta llamada al sistema pasará finalmente al estado zombi.\nUn proceso tiene control sobre algunas transiciones de estado. En primer lugar, un proceso puede crear otro proceso. Sin embargo, es el núcleo quien decide en qué momento se realizará la transición desde el estado creado al estado preparado para ejecución en memoria principal o al estado preparado para ejecución en memoria secundaria.\nEn segundo lugar, un proceso puede invocar a una llamada al sistema lo que provocará que pase del estado ejecución en modo usuario al estado ejecución en modo núcleo. Sin embargo, el proceso no tiene control de cuándo volverá de este estado, incluso algunos eventos pueden producir que nunca retorne y pase al estado zombi.En tercer lugar, un proceso puede finalizar realizando una invocación explícita de la llamada al sistema exit, pero por otra parte eventos externos también pueden hacer que se produzca la terminación del proceso.\nEl resto de las transiciones de estado sigue un modelo rígido codificado en el núcleo. Por lo tanto, el cambio de estado de un proceso ante la aparición de ciertos eventos se realiza de acuerdo a unas reglas predefinidas.\n ## Estados adicionales\nEn el UNIX BSD4 se definieron algunos estados adicionales que no son soportados en SVR2 ni SVR3, pero sí en SVR4. Como por ejemplo, el estado parado o suspendido (en memoria principal o secundaria) y el estado dormido y parado (en memoria principal o secundaria). En el estado parado, la ejecución del proceso es detenida por la acción de una señal pero posteriormente puede retomarse. En el apartado 4.4.1.b se detalla el funcionamiento de dichas señales y su relación con los estados adicionales.\n ## El estado dormido\nEl estado dormido en memoria principal es uno de los posibles estados de un proceso, por su importancia requiere de una atención especial. Un proceso siempre pasa al estado dormido en memoria principal desde el estado ejecución en modo supervisor. Principalmente, un proceso pasa al estado dormido cuando se produce alguna de los siguientes circunstancias:\n- Durante la ejecución de una llamada al sistema el núcleo requiere usar un recurso que se encuentra ocupado, o debe esperar a que termine una transferencia de E/S.\n- Se produce un fallo de página como resultado de acceder a una dirección virtual que no está cargada en memoria principal.\nUn proceso permanecerá en el estado dormido hasta que tenga lugar el evento por el que se encuentra esperando. Cuando dicho evento ocurra, el proceso será despertado y pasará al estado preparado para ejecución en memoria (principal o secundaria).\nVarios procesos pueden estar a la espera de un mismo evento, además cada recurso puede producir eventos de diferente naturaleza. Para gestionar esto el núcleo clasifica los eventos en canales o direcciones de dormir. Un canal es una dirección virtual del núcleo\nasociada a un determinado recurso. Distintos eventos pueden estar asociados a un mismo canal.\nDe este modo cuando un proceso pasa al estado dormido en espera de un determinado evento el núcleo lo añade a una lista de procesos dormidos. Además almacena la dirección de dormir en el campo correspondiente de la entrada asociada al proceso en la tabla de procesos.\nCuando se produce un evento asociado a dicha dirección de dormir el núcleo pasa a estado preparado a todos los procesos que estaban a la espera de un evento en dicho canal.En la AQUÍ VA UNA IMAGEN3-11 se observa cómo la lista de procesos dormidos contiene 8 procesos. Los procesos están en el estado dormido esperando por que se produzcan los siguientes eventos:\n1) Finalización de una operación de E/S (proceso C).\n2) Desbloqueo del buffer (procesos A, E, F y H).\n3) Desbloqueo de un nodo-i (procesos B y G).\n4) Entrada en el terminal (proceso D).\nSe observa cómo existen tres canales o direcciones de dormir, las direcciones del buffer, del nodo- i y del terminal, respectivamente. Los eventos finalización de una operación de E/S y desbloqueo del buffer tienen asociados la dirección del buffer. El evento desbloqueo de un nodo-i tiene asociada la dirección del nodo-i. Finalmente, el evento entrada en el terminal tiene asociada la dirección del terminal.\n LISTA DE PROCESOS DORMIDOS EVENTOS QUE DEBEN PRODUCIRSE CANALES\nDirección del buffer\nDirección del nodo-i\nDirección del terminal\n  Proceso A Proceso B Proceso C Proceso D Proceso E Proceso F Proceso G Proceso H\nFinalización de una operación de E/S\n      Desbloqueo del buffer\n    Desbloqueo de un nodo-i\n   Entrada en un terminal\nAQUÍ VA UNA IMAGEN3-11: Lista de procesos dormidos, eventos que deben producirse y canales asociados\nEsta implementación del estado dormido presenta dos anomalías. En primer lugar, cuando un evento tiene lugar, el núcleo despierta a todos los procesos de la lista de procesos dormidos que se encuentran esperando por la ocurrencia de dicho evento, y lospasa al estado preparado para ejecución en memoria (principal o secundaria). Puesto que sólo uno de ellos puede ser planificado para ser ejecutado y usar el recurso por el que espera, el resto de los procesos tendrá que volver al estado dormido después de una breve visita al estado ejecución en modo supervisor, lo que genera cambios de contextos y procesamientos innecesarios. Obviamente, la implementación sería más eficiente si solamente se despertara a aquel proceso dormido que tiene una mayor probabilidad de ser planificado para ser ejecutado, es decir, su prioridad de planificación es mayor.\nLa segunda anomalía es que distintos eventos pueden estar asociados a un mismo canal o dirección de dormir. La implementación sería más eficiente si cada evento tuviese asociado su propio canal. Curiosamente, en la práctica el rendimiento del sistema no se ve muy perturbado por la existencia de esta anomalía puesto que es raro que se asocien muchos eventos a un mismo canal. Además, un proceso ejecutándose normalmente libera los recursos bloqueados antes de que otro proceso sea planificado para ejecución.En el esquema de la AQUÍ VA UNA IMAGEN3-11 se tiene un ejemplo de la segunda anomalía comentada. Puesto que tanto el evento finalización de una operación de E/S como el evento desbloqueo del buffer tienen asociados la misma dirección de dormir (la dirección del buffer) cuando la operación de E/S con el buffer se completa, el núcleo despierta tanto al proceso C como a los procesos A, E, F y H. Puesto que el proceso C esperando por la terminación de una operación de E/S mantiene el buffer bloqueado, los procesos A, E, F y H que esperan por el desbloqueo del buffer para poder utilizarlo volverán al estado dormido, si el buffer sigue bloqueado, cuando vayan a ejecutarse. En consecuencia A, E, F y H han sido despertados inútilmente. Obviamente el sistema sería más eficiente si los procesos fuesen despertados cuando se estuviese seguro de que el buffer no está bloqueado.\nUn ejemplo de la primera anomalía se da cuando el núcleo despierta a los procesos A, E, F y H al estar el buffer disponible (se supone que el proceso C ya completó su operación de E/S y ha desbloqueado el buffer). Los cuatro procesos compiten por el mismo recurso, solamente uno de ellos será planificado para ser ejecutado el resto volverá al estado dormido. Obviamente el sistema sería más eficiente si solo se despertase al proceso con una mayor prioridad de planificación.\nAntes de comentar otra característica importante del estado dormido conviene recordar lo que se entiende por señal. Una señal es un mecanismo de comunicación que utiliza el núcleo para informar a un proceso de la ocurrencia de algún evento asíncrono. La posibilidad de poder interrumpir a un proceso en el estado dormido, es decir, de poder despertarlo cuando llega una señal para él, permite distinguir entre dos tipos de estado dormido:\nEstado dormido no interrumpible por señales. En este estado el proceso no puede ser interrumpido (no puede ser despertado) cuando llegue una señal para él. Si bien conviene matizar que existen algunas señales que no pueden ser ignoradas. Un proceso entra en este estado si se encuentra esperando por un evento que no tardará mucho en producirse, como por ejemplo que se complete una operación de E/S con el disco o que se libere un recurso (nodo-i o buffer) bloqueado.\nEstado dormido interrumpible por señales. En este estado el proceso puede ser interrumpido (puede ser despertado) cuando llegue una señal para él. Un proceso entra en este estado si se encuentra esperando por un evento que puede tardar en producirse, como por ejemplo que el usuario pulse alguna tecla del teclado.\n  Prioridad\n   Valor\n   Descripción\n PSWP O PSWP + 1 1 PSWP + 1/2/4 1/2/4\nPINOD 10 PRIBIO 20 PRIBIO+1 21 PZERO 25 TTIPRI 28 TTOPRI 29 PWAIT 30 PLOCK 35 PSLEP 40\nPrioridad en la que duerme el proceso intercambiador Prioridad en la que duerme el ladrón de páginas Prioridades en las que duermen otras actividades de administración de memoria\nEvento : Desbloqueo de un nodo-i\nEvento: Finalización de una operación de E/S en disco Evento: Desbloqueo del buffer\nPrioridad umbral\nEvento: Entrada en un terminal\nEvento: Salida en un terminal\nEvento: T erminación de un proceso hijo\nEvento: Bloqueo de un recurso\nEvento: Recepción de una señal\n   Tabla 3-1: Prioridades para dormir en el UNIX BSD4.3\nComo se estudiará en el capítulo 5, el parámetro que usa el núcleo para determinar si un proceso entra en el estado dormido interrumpible o no interrumpible es el valor de la prioridad de planificación de un proceso en modo núcleo. El núcleo asigna una determinada prioridad de planificación en modo núcleo en función del evento por el que el proceso se encuentra esperando. A dicha prioridad se le suele denominar prioridad para dormir. Además define un valor límite o umbral de tal forma que si la prioridad para dormir de un proceso es mayor que dicho valor umbral el proceso entrará en el estado dormido no interrumpible. En caso contrario, el proceso entrará en el estado dormido interrumpible. En la Tabla 3-1 se muestra, a modo de ejemplo, las prioridades para dormir utilizadas en la distribución BSD4.3. En ella las prioridades más altas corresponden a los valores numéricos más bajos."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Resumen: ¿Qué hemos aprendido?",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": ". Cuando se compila un programa, el compilador genera un espacio o conjunto de direcciones de memoria virtual asociadas a dicho programa. La máquina traduce este espacio en un conjunto de direcciones de memoria principal. Varias copias de un mismo programa pueden coexistir en memoria principal, que utilizarán las mismas direcciones virtuales, pero con diferentes direcciones físicas asignadas.\nUn proceso es una instancia de un programa en ejecución. Al compilar el código fuente de un programa se crea un archivo ejecutable que consta básicamente de cuatro partes: cabecera primaria (número mágico, número de secciones, dirección virtual de inicio), cabecera de las secciones, secciones, y otras informaciones.\nEl núcleo carga un fichero ejecutable en memoria principal durante, por ejemplo, la llamada al sistema exec. El proceso cargado tiene asignado por el compilador un espacio de direcciones de memoria virtual (o espacio de direcciones de usuario). Este espacio se divide en varias regiones. El espacio de direcciones de memoria virtual de un proceso consiste al menos de tres regiones: la región de código (o texto), la región de datos y la región de pila. Adicionalmente, puede contener regiones de memoria compartida, que posibilitan la comunicación de un proceso con otros procesos.\nLas principales operaciones con regiones implementadas por el núcleo son: bloquear y desbloquear una región, asignar una región, ligar una región al espacio de direcciones virtuales de un proceso, cambiar el tamaño de una región, cargar una región con el contenido de un fichero, desligar una región del espacio de direcciones de un proceso, liberar una región y duplicar una región.\n2. Dado que UNIX es multitarea, necesita identificar cada proceso. La forma de identificación consiste en un número entero positivo distinto denominado identificador del proceso o pid\nCuando el sistema operativo arranca crea un proceso especial denominado proceso 0 al que asigna un pid=0. Poco después el proceso 0 genera un proceso hijo denominado proceso inicial cuyo pid=1 y se convierte en el proceso intercambiador (swapper). La llamada al sistema getpid devuelve el pid del proceso que realiza esta llamada.\nDado que UNIX es multiusuario, el núcleo asocia a cada proceso dos identificadores enteros positivos de usuario (identificador de usuario real (uid) y el identificador de usuario\nefectivo (euid)) y dos identificadores enteros positivos de grupo (identificador del grupo real (gid) y el identificador del grupo efectivo (egid)).\nEl núcleo mantiene diferentes estructuras de datos asociadas a los procesos. Algunas de estas estructuras como la pila del núcleo, el área U y la tabla de regiones por proceso son locales a cada proceso (cada proceso tiene asignada su propia estructura privada). Otras estructuras, como la tabla de procesos y la tabla de regiones son globales para todos los procesos, es decir, sólo existe en el núcleo una estructura para todos los procesos. La tabla de regiones por proceso contiene información relevante sobre las regiones de código, datos, pila de usuario y memoria compartida (si existe) de un cierto proceso. Cada entrada de esta tabla contiene un puntero que apunta a una entrada de la tabla de regiones, con información sobre cada región. Las entradas de la tabla de regiones se organizan en dos listas: una lista enlazada de regiones libres y una lista enlazada de regiones activas. Otras estructuras son las tablas de páginas y la tabla de descriptores de ficheros.\n3. El contexto de un proceso en un cierto instante de tiempo se puede definir como la información relativa al proceso que el núcleo debe conocer para poder iniciar o continuar su ejecución.\nEl contexto de un proceso en un cierto instante de tiempo está formado por su espacio de direcciones virtuales, los contenidos de los registros hardware de la máquina y las estructuras de datos del núcleo asociadas a dicho proceso. Formalmente, el contexto de un proceso se puede considerar como la unión del contexto a nivel de usuario, contexto de registros y contexto a nivel del sistema.\nDurante el tiempo de vida de un proceso pueden producirse distintos sucesos: llamadas al sistema, interrupciones, cambios de contexto... En el contexto de un proceso se distinguen una parte dinámica (capa de contexto), cuyo contenido es necesario salvar ante la aparición de ciertos sucesos, y una parte estática, cuyo contenido no es necesario salvar. La parte dinámica de un proceso está formada por el contexto a nivel de registros y su pila del núcleo. La manipulación que el núcleo realiza de las capas de contexto se puede visualizar como una pila de capas de contexto, local a cada proceso.\nSe entiende por salvar el contexto de un proceso a la acción del núcleo de añadir una capa de contexto en la pila de capas de contexto asociada a dicho proceso; y restaurar el contexto de un proceso es la acción del núcleo de extraer la capa superior de la pila decapas de contexto asociada a dicho proceso e inicializar el contexto de registros y la pila del núcleo con los valores que se habían salvado en dicha capa. Se define el cambio de contexto como el conjunto de tareas que debe realizar el núcleo para aplazar o finalizar la ejecución del proceso (A) actualmente en ejecución, y comenzar o continuar con la ejecución de otro proceso (B).\n4. Las interrupciones (hardware o software) son atendidas en modo núcleo dentro del contexto del proceso que se encuentra actualmente en ejecución.\nCuando se produce una interrupción, el núcleo invoca al algoritmo inthand(), que realiza principalmente las siguientes acciones: Salvar el contexto del proceso actual; elevar el nivel de prioridad de interrupción, obtener el vector de interrupción, invocar al manipulador, restaurar el contexto del proceso.\n5. Las llamadas al sistema son el mecanismo que los procesos de usuario utilizan para solicitar al núcleo el uso de los recursos del sistema. Un proceso invoca a una llamada al sistema como si se tratase de una función de librería cualquiera, que entre otras, ejecutan una instrucción que provoca una interrupción software especial denominada trap del sistema operativo. El tratamiento del trap por parte del núcleo provoca el cambio de modo de ejecución a modo núcleo, salvar el contexto del proceso actual y la invocación del algoritmo del núcleo que trata las llamadas al sistema, típicamente denominado syscall().\n6. El tiempo de vida de un proceso en un sistema UNIX puede ser conceptualmente dividido en un conjunto de estados que describen el comportamiento del proceso. Los ocho estados en que se puede encontrar un proceso en un sistema UNIX (SVR2 o SVR3) son: ejecutándose en modo usuario, ejecutándose en modo núcleo (o supervisor), preparado en memoria principal para ser ejecutado, dormido o bloqueado en memoria principal, preparado en memoria secundaria para ser ejecutado, dormido o bloqueado en memoria secundaria, creado y zombi."
}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué es un proceso?",
"responses":[                         "Un proceso es una instancia de un programa en ejecución.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cuál es la información que contiene la cabecera primaria?",
"responses":[                         "- El número mágico. Es un entero pequeño que permite al núcleo identificar el tipo de archivo ejecutable.\n- El número de secciones que hay en el archivo.\n- La dirección virtual de inicio, imprescindible para comenzar con la ejecución del\nproceso.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cuál es la información que contiene las cabeceras de las secciones?",
"responses":[                         "Las Cabeceras de las secciones describen cada una de las secciones del archivo. Entre otras informaciones contienen el tipo y el tamaño de la sección, además de la dirección virtual que se le debe asignar a la región cuando el proceso se ejecute en el sistema.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué contienen las secciones?",
"responses":[                         "Contienen los “datos”, que son cargados inicialmente en el espacio de direcciones del proceso, típicamente, el código (también denominado texto), los datos inicializados (variables estáticas y externas del programa conocidas en el momento de la compilación) y los datos no inicializados (también denominado bss ).\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué regiones principales se pueden distinguir en un proceso?",
"responses":[                         "El espacio de direcciones de memoria virtual de un proceso consiste al menos de tres regiones: la región de código (o texto), la región de datos y la región de pila.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Enumera las principales operaciones con regiones implementadas por el núcleo.",
"responses":[                         "Las principales operaciones con regiones implementadas por el núcleo son: bloquear y desbloquear una región, asignar una región, ligar una región al espacio de direcciones virtuales de un proceso, cambiar el tamaño de una región, cargar una región con el contenido de un fichero, desligar una región del espacio de direcciones de un proceso, liberar una región y duplicar una región.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe en qué consiste Ligar una región al espacio de direcciones virtuales de un\n                    proceso.",
"responses":[                         "Ligar una región al espacio de direcciones virtuales de un proceso consiste en asociar a una región (que previamente ha tenido que ser asignada) una entrada de la tabla de regiones por proceso. El núcleo implementa esta operación con el algoritmo attachreg(). Las llamadas al sistema que usan esta operación son: fork, exec y shmat.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe cómo se cambia el tamaño de una región.",
"responses":[                         "Las únicas regiones cuyo tamaño pueden ser modificados son las regiones de datos y de pila. Las regiones de código y las regiones de memoria compartida no pueden crecer después de ser inicializadas. El núcleo implementa esta operación con el algoritmo growreg(). Existen dos llamadas al sistema brk y sbrk que usan esta operación, ambas trabajan con la región de datos. Además el núcleo también utiliza esta operación para implementar el crecimiento de la pila de usuario.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué llamada al sistema devuelve el identificador del proceso que realiza esta\n                    llamada?",
"responses":[                         "La llamada al sistema getpid devuelve el pid del proceso que realiza esta llamada.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe los identificadores de usuario y de grupo",
"responses":[                         "El uid identifica al usuario que es responsable de la ejecución del proceso y el gid identifica al grupo al cual pertenece dicho usuario. El euid se utiliza, principalmente, para determinar el propietario de los ficheros recién creados, para permitir el acceso a losficheros de otros usuarios y para comprobar los permisos para enviar señales a otros procesos. El uso del egid es similar al del euid pero desde el punto de vista del grupo.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Señala las principales estructuras de datos del núcleo, y describe sus diferencias.",
"responses":[                         "El núcleo mantiene diferentes estructuras de datos asociadas a los procesos, las cuales son imprescindibles para la ejecución de los mismos. Algunas de estas estructuras como la pila del núcleo, el área U y la tabla de regiones por proceso son locales a cada proceso, es decir, cada proceso tiene asignada su propia estructura privada. Otras estructuras, como la tabla de procesos y la tabla de regiones son globales para todos los procesos, es decir, sólo existe en el núcleo una estructura para todos los procesos.\nPor otra parte, algunas de estas estructuras como la pila del núcleo y el área U se implementan en el espacio de direcciones virtuales de cada proceso. Mientras que otras como la tabla de procesos, la tabla de regiones por proceso y la tabla de regiones se implementan en el espacio de direcciones virtuales del núcleo. Todas estas estructuras tienen en común que son propiedad del núcleo y por tanto solo pueden ser accedidas en modo núcleo\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe pila de usuario y pila de núcleo",
"responses":[                         "La existencia en UNIX de dos modos distintos de ejecución, modo usuario y modo núcleo, hace necesario la existencia de una pila independiente para cada modo y para cada proceso: la pila de usuario y la pila del núcleo. La pila de usuario contiene los marcos de pila de las funciones que se ejecutan en modo usuario. De forma análoga, la pila del núcleo contiene los marcos de pila de las funciones que se ejecutan en modo núcleo. Por tanto, estas dos pilas crecerán de forma autónoma. De hecho la pila del núcleo está vacía cuando el proceso se ejecuta en modo usuario.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe qué es la tabla de procesos",
"responses":[                         "La tabla de procesos es una estructura global del núcleo donde se almacena información de control relevante sobre cada proceso existente en el sistema. Cada entrada de la tabla de procesos contiene distintos campos con información sobre un determinado proceso.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe qué es el área U",
"responses":[                         "El área de usuario o área U es una estructura local asociada a cada proceso que contiene información de control relevante sobre el mismo que el núcleo necesita consultar únicamente cuando ejecuta dicho proceso.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe la tabla de regiones por proceso",
"responses":[                         "La tabla de regiones por proceso es un estructura local a cada proceso que contiene una entrada por cada región (código, datos y pila de usuario). Si existen regiones de memoria compartida cada una de ellas también tendrá asignada una entrada.\nCada entrada de la tabla de regiones por proceso apunta a una entrada en la tabla de regiones y contiene la dirección virtual de comienzo de una región. Este nivel extra de direccionamiento (desde la tabla de regiones por proceso a la tabla de regiones) permite que procesos independientes puedan compartir regiones. Además cada entrada contiene el tipo de acceso permitido al proceso sobre dicha región: sólo lectura, lectura y escritura, o lectura y ejecución.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe la tabla de regiones, y la información que contiene.",
"responses":[                         "La tabla de regiones es una estructura global del núcleo que contiene una entrada por cada región asignada por el núcleo. Cada entrada de esta tabla contiene la información necesaria para describir una región, como por ejemplo.\n- Un puntero al nodo-i del fichero cuyo contenido fue cargado dentro de la región.\n- El tipo de región (código, datos, pila de usuario o memoria compartida).\n- El tamaño de la región.\n- La localización de la región en memoria principal, típicamente un puntero a una tabla de páginas.\n- El estado de la región, que puede ser una combinación de: bloqueada, bajo demanda, en proceso de ser cargada en memoria y válida (cargada en memoria).- El contador de referencias, que indica el número de procesos que están referenciando a una región.\nLas entradas de la tabla de regiones se organizan en dos listas: una lista enlazada de regiones libres y una lista enlazada de regiones activas. Simultáneamente una entrada sólo puede pertenecer a una de las dos listas",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué forma el contexto a nivel de usuario?",
"responses":[                         "El contexto a nivel de usuario de un proceso está formado por su código, datos, pila de usuario y memoria compartida que ocupan el espacio de direcciones virtuales del proceso.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué contenido tiene el contexto a nivel de registros?",
"responses":[                         "El contexto de registros de un proceso está formado por el contenido de los siguientes registros de la máquina:\n- El contador del programa que indica la dirección de la siguiente instrucción que debe ejecutar la CPU. Esta dirección es una dirección virtual del espacio de memoria del núcleo o del usuario.\n- El registro de estado del procesador que indica el estado del hardware de la máquina en relación al proceso en ejecución. Contiene diferentes campos para almacenar la siguiente información: el modo de ejecución, el nivel de prioridad de interrupción npi, el indicador de rebose, el indicador de arrastre, etc.\n- El puntero de la pila donde se almacena la dirección virtual, dependiendo de la arquitectura de la máquina, de la próxima entrada libre o de la última utilizada en la pila de usuario (ejecución en modo usuario) o en la pila del núcleo (ejecución en modo núcleo). Análogamente, la máquina indica la dirección de crecimiento de la pila, hacia las direcciones altas o bajas.\n- Los registros de propósito general, que contienen datos generados por el proceso durante su ejecución.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué contenido tiene el contexto a nivel de sistema?",
"responses":[                         "El contexto a nivel del sistema de un proceso está formado por: la entrada de la tabla de procesos asociada a dicho proceso, su área U, su pila del núcleo, su tabla de regiones por proceso, las entradas de la tabla de regiones apuntadas por las entradas de su tabla de regiones por proceso y las tablas de páginas asociadas a dichas entradas de la tabla de regiones.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿En qué casos el núcleo añade una capa de contexto en la pila de capas de\n                    contexto de un proceso?",
"responses":[                         "El núcleo añade una capa de contexto en la pila de capas de contexto de un proceso en los siguientes casos:\n- Cuando se produce una interrupción.\n- Cuando el proceso realiza una llamada al sistema.\n- Cuando se produce un cambio de contexto.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿En qué casos el núcleo extrae una capa de contexto en la pila de capas de contexto de un proceso?",
"responses":[                         "EEl núcleo extrae una capa de contexto de la pila de capas de contexto de un proceso cuando:\n- El núcleo vuelve de manipular una interrupción.\n- El proceso vuelve al modo usuario después de que el núcleo completa la ejecución\nde una llamada al sistema.\n- Se produce un cambio de contexto.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cuáles son las principales circunstancias que provocan la realización de un cambio de contexto?",
"responses":[                         "- La entrada de un proceso en el estado dormido- La finalización de la ejecución de una llamada al sistema exit.\n- La vuelta al modo usuario tras ejecutarse una llamada al sistema y la existencia de un proceso esperando para ser ejecutado con mayor prioridad de planificación que el actual.\n- La vuelta al modo usuario tras atenderse una interrupción y la existencia de un proceso esperando para ser ejecutado con mayor prioridad de planificación que el actual\n- La finalización del tiempo de uso del procesador de un proceso ejecutándose en modo usuario.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué acciones realiza el algoritmo inthand()?",
"responses":[                         "Cuando se produce una interrupción, el núcleo invoca al algoritmo inthand(), que realiza principalmente las siguientes acciones: Salvar el contexto del proceso actual; elevar el nivel de prioridad de interrupción, obtener el vector de interrupción, invocar al manipulador, restaurar el contexto del proceso.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cuáles son las principales causas que provocan que un proceso pase al estado\n                    dormido?.",
"responses":[                         "El estado dormido en memoria principal es uno de los posibles estados de un proceso, por su importancia requiere de una atención especial. Un proceso siempre pasa al estado dormido en memoria principal desde el estado ejecución en modo supervisor. Principalmente, un proceso pasa al estado dormido cuando se produce alguna de los siguientes circunstancias:\n- Durante la ejecución de una llamada al sistema el núcleo requiere usar un recurso que se encuentra ocupado, o debe esperar a que termine una transferencia de E/S.\n- Se produce un fallo de página como resultado de acceder a una dirección virtual que no está cargada en memoria principal.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "ALGORITMOS DE CONTROL DE PROCESOS EN UNIX",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "- Cómo se produce la creación de procesos mediante la función fork.\n- Qué son las señales.\n- Descripción de los algoritmos dormir (sleep()) y despertar (wakeup()) a un proceso.\n- Descripción de la terminación de procesos mediante la función exit.\n- Descripción del algoritmo esperar la terminación de un proceso (wait), que permite sincronizar la ejecución de un proceso con la terminación de algunos de sus procesos hijos.\n- Invocación de otros programas.\n- Funciones de librería.\n- Funcionamiento del algoritmo exec().\n- Qué es una hebra y para qué sirve.\nEste capítulo está dedicado al estudio del uso y la implementación de las llamadas al sistema y los algoritmos del núcleo que permiten controlar a un proceso. En la explicación de las llamadas al sistema que se tratan en este capítulo se va a tomar como referencia principalmente el núcleo de una distribución clásica como SVR3. En primer lugar se describe la llamada al sistema fork que permite crear un nuevo proceso (hijo) a partir de otro proceso (padre). En segundo lugar, se describen las señales, que permiten informar a los procesos de eventos asíncronos. Su estudio en profundidad es imprescindible parapoder comprender los algoritmos sleep() y wakeup() que el núcleo utiliza dentro de la ejecución de las llamadas al sistema para pasar a un proceso al estado dormido (interrumpible o no interrumpible por señales) y para despertarlo, respectivamente. Ambos algoritmos también son explicados en este capítulo.\nA continuación se describen la llamada al sistema exit, que permite terminar la ejecución de un proceso y la llamada al sistema wait, que permite sincronizar la ejecución de un proceso con la terminación de alguno de sus procesos hijos. El núcleo sincroniza la ejecución de exit y wait mediante el uso de señales.\nAdemás, se presenta la llamada al sistema exec que permite a un proceso invocar a un “nuevo” programa ejecutable. Finalmente se incluye un apartado dedicado a las hebras que son unidades computacionales utilizadas en las distribuciones modernas de UNIX."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "Creación de procesos",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},	"content": "",
"code_url": "Ejemplo_4-3"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Señales",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content":""
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Llamada al sistema kill",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},
"content": "## Llamadas al sistema para el manejo de señales",
"code_url": "Ejemplo_4-4-3-1"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Llamada al sistema raise",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "###  \nLa llamada al sistema raise permite a un proceso enviarse una señal a sí mismo.\nSu sintaxis es:resultado = raise(señal);\nSe observa que raise tiene únicamente un parámetro de entrada señal, que es una constante entera que identifica a la señal. Asimismo, raise devuelve un único parámetro de salida resultado que vale 0 si la llamada al sistema se ejecuta con éxito. En caso contrario, vale -1."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Llamada al sistema signal",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_4-4-3-3"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Llamada al sistema pause",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "Ejemplo_4-4-3-4"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Llamadas al sistema para emnascarar señales",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,           "content": "  \n ###  .\nLa llamada al sistema sigsetmask fija la máscara actual de señales, es decir, permite especificar qué señales van a estar bloqueadas. Obviamente, aquellas señales que no pueden ser ignoradas ni capturadas, tampoco van a poder ser bloqueadas. Su sintaxis es:resultado=sigsetmask(máscara);\nSe observa que tiene un único parámetro de entrada máscara que es un entero largo asociado a la máscara de señales. Se considera que la señal número j está bloqueada si el j-ésimo bit de máscara está a 1. Este bit puede ser fijado con la macro sigmask(j).\nAsimismo se observa que posee un único parámetro de salida resultado que es la máscara de señales que se tenía especificada antes de ejecutar esta llamada al sistema. En caso de error resultado vale -1.\nPor otra parte, la llamada al sistema sigblock permite añadir nuevas señales bloqueadas a la máscara actual de señales. Su sintaxis:resultado=sigblock(máscara2);Tema 4: Algoritmos de control de procesos en UNIX 199\nSe observa que tiene un único parámetro de entrada máscara2 que es un entero largo que se utilizará como operando junto con la máscara actual de señales máscara para realizar una operación lógica de tipo OR a nivel de bits:máscara = máscara | máscara 2;\nSe considera que la señal número j está bloqueada si el j-ésimo bit de máscara2\nestá a 1. Este bit puede ser fijado con la macro sigmask(j).\nAsimismo se observa que sigblock posee un único parámetro de salida resultado que es la máscara de señales que se tenía especificada antes de ejecutar esta llamada al sistema. En caso de error resultado vale -1.\nLa principal diferencia entre sigsetmask y sigblock es que la primera fija la máscara de señales de forma absoluta y la segunda, de forma relativa.\nOtra llamada al sistema para el manejo de la máscara de señales es sigprocmask (SVR4).\nEn general estas llamadas al sistema han quedado obsoletas (aunque todavía pueden usarse en muchas versiones de UNIX) y han sido reemplazadas por sus equivalentes POSIX tal como muestra el siguiente ejemplo:#include <stdio.h> #include <signal.h> #include <stdlib.h> #include <unistd.h>\n     int main(void) {[1] sigset_t nueva, vieja;\n[2] sigemptyset(&nueva);\n[3] sigaddset(&nueva, SIGINT);\n[4] sigprocmask(SIG_BLOCK, &nueva, &vieja);\n[5] raise(SIGINT);\n[6] sleep(2);\n[7] sigprocmask(SIG_SETMASK, &vieja, NULL);[8] printf(\"FINAL\n\"); }Considérese el siguiente programa escrito en lenguaje C:En la sentencia [1] se declara las variables nueva y vieja de tipo sigset_t. En la sentencia [2] se invoca a sigemptyset para crear una máscara vacía. Seguidamente se añade a la máscara nueva [3] la señal SIGINT. Por último se aplica a dicha máscara la acción SIG_BLOCK [4]. En la variable vieja se almacena la máscara de señales original que se tenía especificada antes de invocar a esta llamada al sistema.\nEn la sentencia [5] se invoca a raise para enviar al mismo proceso que la invoca la señal SIGINT. Puesto que está bloqueada no tiene efecto inmediatamente, pero tampoco se pierde sino que queda en una cola de espera.\n[6] hace que se espere dos segundos, transcurridos los cuales se restaura la máscara original [7] con la acción SIG_SETMASK. Al volver de la llamada al sistema se atiende la señal que estaba pendiente y cuyo efecto es la acción por defecto es terminar el proceso. Por este motivo la sentencia [8] no llega a ejecutarse."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Dormir y despertar a un proceso ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": " ## Algoritmo sleep()\nEl núcleo usa el algoritmo sleep() para pasar a un proceso A al estado dormido. Este algoritmo requiere como parámetros de entrada la prioridad para dormir y la dirección de dormir o canal asociada al evento por el que estará esperando el proceso.\nLa primera acción que realiza sleep() es salvar el nivel de prioridad de interrupción (npi) actual, típicamente en el registro de estado del procesador. A continuación eleva el npi para bloquear todas las interrupciones.\nPosteriormente en los campos correspondientes de la entrada de la tabla de procesos asociada al proceso A marca el estado del proceso a dormido en memoria principal, salva el valor de la prioridad para dormir y de la dirección de dormir. Asimismo coloca al proceso en una lista de procesos dormidos.\nA continuación compara la prioridad para dormir con un cierto valor umbral para averiguar si el proceso puede ser interrumpido por señales. Si la prioridad para dormir es mayor que dicho valor umbral entonces el proceso no puede ser interrumpido por señales.Tema 4: Algoritmos de control de procesos en UNIX 201\nEn caso contrario, el proceso sí puede ser interrumpido por señales. Se distinguen por tanto dos casos:\n- Caso 1: El proceso no puede ser interrumpido por señales. En este caso el núcleo realiza un cambio de contexto, en consecuencia otro proceso B pasará a ser ejecutado. De esta forma la ejecución del algoritmo sleep() es momentáneamente detenida. Más tarde, cuando el proceso A sea despertado y planificado para ejecución, continuará su ejecución en modo núcleo en la siguiente instrucción del algoritmo sleep(), que consiste en restaurar el valor del npi al valor que tenía antes de comenzar a ejecutar el algoritmo. A continuación, el algoritmo finaliza.\n- Caso 2: El proceso puede ser interrumpido por señales. En este caso el núcleo invoca al algoritmo issig() para comprobar la existencia de señales pendientes. Se pueden dar dos casos:o Caso 2.1: Existen señales pendientes. Entonces el núcleo borra al proceso A de la lista de procesos dormidos, restaura el valor del npi (al valor que tenía antes de comenzar a ejecutar el algoritmo) e invoca al algoritmo psig() para tratar la señal.\no Caso 2.2: No existen señales pendientes. Entonces el núcleo realiza un cambio de contexto, en consecuencia otro proceso D pasará a ser ejecutado. De esta forma la ejecución del algoritmo sleep() es momentáneamente detenida. Más tarde, cuando el proceso A sea despertado (bien porque se produjo el evento por el que estaba esperando o porque es interrumpido por una señal) y planificado para ejecución, el núcleo invocará nuevamente al algoritmo issig() para comprobar la existencia de señales pendientes que han podido ser notificadas durante el tiempo que pasó dormido. Existen dos posibilidades:\n- Si no existen señales pendientes, entonces el núcleo restaura el npi al valor que tenía antes de comenzar a ejecutar sleep() y finaliza el algoritmo. Existen señales pendientes, entonces el núcleo restaura el npi al valor que tenía antes de comenzar a ejecutar el algoritmo sleep() e invoca a psig() para tratar la señal.\nEn la AQUÍ VA UNA IMAGEN4-3 se resumen las principales acciones que realiza el núcleo durante la ejecución del algoritmo sleep(). De la descripción realizada del algoritmo sleep() se deducen las siguientes conclusiones:\nAl contrario de lo que podría pensarse, el algoritmo sleep() no requiere ejecutarse hasta el final para lograr su objetivo de pasar a un proceso al estado dormido. Un proceso entra formalmente en el estado dormido cuando dentro del algoritmo se ejecuta el paso del cambio de contexto, momento en el que se suspende la ejecución del algoritmo. En conclusión en el caso 2.1, debido a la existencia de señales pendientes, el proceso nunca llega a entrar formalmente en el estado dormido.\nLa pila de capas de contexto de un proceso dormido contiene dos capas de contexto, la capa 1 que contiene la información necesaria para poder continuar con la ejecución del algoritmo sleep() y la capa 0 que contiene la información necesaria para poder retomar la ejecución del proceso en modo usuario.Tema 4: Algoritmos de control de procesos en UNIX 203\n AQUÍ VA UNA IMAGEN4-3: Principales acciones realizadas por el núcleo durante la ejecución del algoritmo\nsleep()\nEn este algoritmo se dan dos de las tres situaciones (ver sección \n##) en los cuales el núcleo invoca al algoritmo issig() para comprobar la existencia de señales pendientes:\n- Justo antes de entrar en el estado dormido interrumpible (caso 2).- Inmediatamente después de despertar porque se produjo el evento por el que estaba esperando o porque es interrumpido por una señal (caso 2.2).\nSi se genera una señal para A mientras éste se encuentra en el estado dormido no interrumpible, la señal será marcada como pendiente, pero el proceso no se dará cuenta de la existencia de esta señal hasta que no vuelva al estado ejecución en modo usuario o entre en el estado dormido interrumpible.\n ## Algoritmowakeup()\nEl núcleo usa el algoritmo wakeup() para despertar a un proceso que se encuentra en el estado dormido a la espera de la aparición de un determinado evento. Típicamente la invocación de wakeup() se realiza dentro de algún otro algoritmo del núcleo como los asociados a las llamadas al sistema o las rutinas de manipulación de interrupciones. Por ejemplo, si el núcleo usa el algoritmo iput() para liberar a un nodo-i que estaba bloqueado deberá invocar dentro del mismo a wakeup() para despertar a aquellos procesos que estaban esperando por la liberación de dicho nodo-i. Asimismo durante la ejecución de la rutina de tratamiento de una interrupción del disco duro, el núcleo deberá invocar al algoritmo wakeup() para despertar a aquellos procesos que estaban esperando que se completará una operación de E/S con el disco.\nEl núcleo también llama al algoritmo wakeup() cuando genera una señal para un proceso en estado dormido interrumpible, siempre y cuando el proceso no ignore ni tenga bloqueado dicho tipo de señales. Pero, en este caso, el núcleo sólo despierta al proceso receptor de la señal.\nEl algoritmo wakeup() requiere como parámetro de entrada la dirección de dormir o canal asociada a dicho evento. La primera acción que realiza wakeup() es salvar el nivel de prioridad de interrupción (npi) actual. A continuación eleva el npi para bloquear todas las interrupciones.\nPosteriormente, busca en la lista de procesos dormidos a aquellos procesos que están a la espera de la aparición del evento asociado a la dirección de dormir. Para cada uno de estos procesos realiza las siguientes acciones: elimina al proceso de la lista de procesos dormidos, marca en el campo estado de su entrada asociada en la tabla de procesos el estado de preparado para ejecución en memoria principal (o en memoria secundaria), coloca al proceso en una lista de procesos elegibles para ser planificados yTema 4: Algoritmos de control de procesos en UNIX 205\nborra el contenido del campo dirección de dormir o canal de su entrada asociada en la tabla de procesos.\n  Salvar el npi inicial y elevar el npi actual para bloquear las interrupciones\n  NO\nInicio\n¿Existe algún proceso asociado a la dirección de dormir en la lista de\nprocesos dormidos?\nSI\n    Restaurar el valor de npi al valor que tenía al principio del algoritmo\n  Fin\nAQUÍ VA UNA IMAGEN4-4: Principales acciones realizadas por el núcleo durante la ejecución del algoritmo\nwakeup()\nAdemás, si el proceso A que ha sido despertado no estaba cargado en memoria principal, el núcleo despierta al proceso intercambiador para intercambiar al proceso A hacia la memoria principal desde memoria secundaria (supuesto que la política de gestión de memoria es de intercambio).\nEn caso contrario (el proceso A estaba cargado en memoria principal) si el proceso despertado A es más elegible para ser ejecutado que el proceso actualmente en ejecución D, entonces el núcleo activa un indicador denominado runrun en la entrada de la tabla de procesos asociada con A para que esta circunstancia sea tenida en cuenta por el algoritmo de planificación cuando el proceso vaya a retornar al modo usuario.\nNO\n¿Está el proceso en memoria principal?\nSI\nEliminar al proceso de la lista de\nprocesos dormidos\nMarcar en la tabla de procesos que el estado del proceso es\npreparado para ejecución\n Despertar al proceso intercambiador\nCuando ya no quedan más procesos en la lista de procesos dormidos a la espera de la aparición del evento asociado a la dirección de dormir el núcleo restaura el npi al valor que tenía antes de comenzar a ejecutar wakeup() y el algoritmo finaliza.\nEn la AQUÍ VA UNA IMAGEN4-4 se resumen las principales acciones que realiza el núcleo durante la ejecución del algoritmo wakeup(). Debe quedar claro que el algoritmo wakeup() no hace que un proceso sea inmediatamente planificado; sólo hace que el proceso sea elegible para ser planificado."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Terminación de procesos",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "En un sistema UNIX un proceso finaliza cuando se ejecuta la llamada al sistema exit. Cuando un proceso B invoca a esta llamada el núcleo lo pasa al estado zombi y elimina todo su contexto excepto su entrada en la tabla de procesos. La sintaxis de esta llamada al sistema e:exit(condición);\nSe observa que posee un único parámetro de entrada condición que es número entero que será devuelto al proceso padre del proceso B. Al parámetro condición se le suele denominar código de retorno para el proceso padre. El proceso padre puede examinar, si lo desea, el valor de condición para identificar la causa por la que finalizó el proceso B de acuerdo a unos criterios que haya previamente establecido el usuario. Así por ejemplo, se podría establecer como criterio que si condición=0 el proceso finalizó normalmente, mientras que si condición=1 el proceso finalizó porque se produjo algún error durante su ejecución. También es posible no fijar ningún criterio por lo que el valor de condición no tendrá ningún significado en especial.\nAsimismo se observa que exit es de las pocas llamadas al sistema que no genera parámetros de salida. Esto es lógico, ya que el proceso B que la había invocado deja de existir después de haber ejecutado exit.\nUn proceso puede invocar a la llamada al sistema exit explícitamente como una sentencia de su código. Asimismo los programas escritos en C llaman a exit implícitamente cuando un programa finaliza su función main. En ambos casos el núcleo ejecuta el algoritmo exit().Tema 4: Algoritmos de control de procesos en UNIX 207\nAlternativamente, el núcleo puede invocar al algoritmo exit() internamente, como por ejemplo para terminar a un proceso durante el tratamiento de una señal no capturada. En ese caso el código de retorno para el proceso padre es el número de dicha señal.\nEl algoritmo exit() requiere como parámetro de entrada el código de retorno para el proceso padre. La primera acción que realiza el núcleo durante la ejecución del algoritmo exit es deshabilitar el tratamiento de las señales para el proceso, puesto que como el proceso va a finalizar ya no tiene sentido tratar una señal.\nA continuación, el núcleo recorre la tabla de descriptores de ficheros asociada al proceso para ir cerrando todos los ficheros abiertos por el proceso. Además libera el nodo- i del directorio de trabajo actual y el nodo-i del directorio raíz (si éste se hubiese cambiado).\nDespués el núcleo libera la memoria principal usada por el proceso, utilizando los algoritmos detachreg() y freereg() sobre las regiones asociadas al proceso. Asimismo en la entrada de la tabla de procesos asociada al proceso B cambia el estado del proceso a zombi y salva el código de retorno para el proceso padre y otras informaciones de tipo estadístico (tiempo de ejecución en modo usuario, tiempo de ejecución en modo núcleo, etc.). También se escribe en un fichero de contabilidad global la información estadística sobre la ejecución del proceso, como por ejemplo: el uid, el uso de la CPU, el uso de la memoria, el uso de los recursos de E/S, etc. Estos datos podrán ser leídos con posterioridad por otros programas de monitorización del sistema.\nPor otra parte, el núcleo desconecta al proceso B del árbol de procesos y hace que el proceso inicial (pid=1) adopte a los procesos hijos de B (si los tuviera), para ello conAQUÍ VA UNA IMAGENadecuadamente el campo información genealógica de la entrada asociada a cada proceso hijo en la tabla de procesos. En consecuencia, el proceso inicial se convierte en el padre efectivo de todos los hijos vivos que el proceso B haya creado, que se convierten en procesos demonio.\nSi existen procesos hijos del proceso B en estado zombi, entonces el núcleo envía una señal SIGCHLD al proceso inicial, para que éste borre los contenidos de sus entradas de la tabla de procesos.\nEl núcleo también envía una señal SIGCHLD al proceso padre del proceso B. Esta señal es ignorada por defecto y sólo tendrá efecto si el padre deseaba conocer la muerte de su hijo. Inicio\n Deshabilitar el tratamiento de señales\n Cerrar todos los ficheros abiertos por el proceso\n Liberar recursos (nodos-i, memoria, etc) ocupados por el proceso B\n Marcar el estado del proceso B a zombi en su entrada de\nla tabla de procesos\n  Hacer que el proceso inicial adopte a los procesos hijos del proceso B, si existen.\n NO\nSalvar datos estadísticos y el código de retorno en su entrada de la tabla de procesos\n¿Existen hijos de B SI en estado zombi?\n  Enviar una señal SIGCHLD al proceso padre de B\nEnviar una señal SIGCHLD al proceso inicial\npara que borre sus entradas de la tabla de procesos\n  Hacer un cambio de contexto\nAQUÍ VA UNA IMAGEN4-5: Principales acciones realizadas por el núcleo durante la ejecución del algoritmo\nexit()\nEn un escenario típico, el proceso padre se encuentra ejecutando una llamada al sistema wait a la espera de que un proceso hijo termine para proseguir su ejecución, tal y como se describirá en la siguiente sección.\nFinalmente el núcleo hace un cambio de contexto, con lo que se pasa a ejecutar otro proceso que haya sido previamente planificado. En la AQUÍ VA UNA IMAGEN4-5 se resumen las principales acciones que realiza el núcleo durante la ejecución del algoritmo exit."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Esperar la terminación de un proceso",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "Un proceso A puede sincronizar su ejecución con la terminación de un proceso hijo ejecutando la llamada al sistema wait. La sintaxis de esta llamada es:resultado = wait(direc);\nSe observa que posee un único parámetro de entrada direc que es la dirección de una variable entera dónde se almacenará el código de retorno para el proceso padre generado por el algoritmo exit() al terminar un proceso hijo.\nAsimismo se observa que wait posee un único parámetro de salida resultado que contiene, si la llamada al sistema se ha ejecutado con éxito, el pid del proceso hijo que ha terminado. En caso contrario, contiene el valor -1.\nEl algoritmo del núcleo o rutina del núcleo asociado a esta llamada al sistema es wait(), que requiere como parámetro de entrada la dirección de la variable dónde se va almacenar el código de retorno para el proceso padre.\nLa primera acción que realiza el núcleo durante la ejecución del algoritmo wait() es comprobar que el proceso A posee algún proceso hijo. Si no tiene ningún hijo el algoritmo finaliza y devuelve un error.\nEn caso contrario, si A posee algún proceso hijo se entra en un bucle, dentro del cual el núcleo comprueba la existencia de procesos hijos de A en estado zombi. Si existe alguno, el núcleo escoge al primero que encuentra (supóngase que es el proceso B) y extrae de la entrada asociada a B en la tabla de procesos, su pid y su código de retorno para el proceso padre. A continuación, el núcleo añade, en el campo apropiado del área U del proceso A, el tiempo que el proceso hijo B se ejecutó en modo usuario y en modo núcleo. Finalmente, el núcleo borra los contenidos de la entrada de la tabla de procesos asociada al proceso hijo B, dicha entrada estará ahora disponible para nuevos procesos. El algoritmo finaliza devolviendo al proceso padre el pid del proceso hijo y el código de retorno.Por el contrario, si no existe ningún proceso hijo de A en estado zombi, el núcleo invoca al algoritmo sleep() para pasar al proceso al estado dormido interrumpible en espera de la llegada de alguna señal.\n  NO\nInicio\n¿El proceso A tiene algún hijo?\nSI\nNO ¿Existe algún hijo de SI A en estado zombi?\n         Invocar al algoritmo\nsleep\npara pasar a A\nal estado dormido interrumpible\nCuando A sea despertado y planificado para ser ejecutado\nFin\nBusca un hijo en estado zombi\n(supongase que encuentra a B)\n Borra los contenidos de la entrada asociada a B en la tabla de procesos\n  Devolver un error\nDevolver el pid del hijo y el código de retorno para A\n  AQUÍ VA UNA IMAGEN4-6: Principales acciones realizadas por el núcleo durante la ejecución del algoritmo\nwait()\nComo se ha descrito en la sección anterior, una de las acciones que realiza el núcleo cuando ejecuta el algoritmo exit() para finalizar un cierto proceso (supóngase que es el proceso B) es generar una señal SIGCHLD para el proceso padre de B (supóngase que es el proceso A). A continuación invoca al algoritmo wakeup() para despertar al proceso A.\nCuando el proceso A sea planificado para ejecución, éste continuará su ejecución dentro del algoritmo sleep(). Por lo tanto, de acuerdo con lo explicado en la sección \n## se invocará al algoritmo issig() para comprobar la existencia de señales pendientes. Al menos existirá una señal pendiente, la señal SIGCHLD enviada al terminar el proceso hijo"
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "Esperar la terminación de un proceso - code",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_4-7"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Invocación de otros programas ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Funciones de librería\nLa llamada al sistema exec sirve para invocar desde un proceso a otro programa ejecutable (programa compilado o shell script). Básicamente exec carga las regiones de código, datos y pila del nuevo programa en el contexto de usuario del proceso que invoca a exec. Por lo tanto, una vez concluida esta llamada al sistema, ya no se podrá acceder a las regiones de código, datos y pila del proceso invocador, ya que han sido sustituidas por las del programa invocado.Tema 4: Algoritmos de control de procesos en UNIX 213\nExiste toda una familia de funciones de librería asociadas a esta llamada al sistema: execl, execv, execle, execve, execlp y execvp. La sintaxis de esta familia de funciones es la siguiente:\nresultado=execl(ruta, arg0, arg1,..., argN, NULL); resultado=execv(ruta, argv);\nresultado=execle(ruta, arg0, arg1,..., argN, NULL, envp); resultado=execve(ruta, argv, envp); resultado=execlp(fichero, arg0, arg1,..., argN, NULL); resultado=execvp(fichero, argv);\nTodas las funciones comienzan por el prefijo exec, el significado de las otras letras es el siguiente: “l” indica que los argumentos se pasan como una lista, “v” que los argumentos se pasan en un vector, “e” que se pasan las variables de entorno y “p” que se utiliza el path para buscar el ejecutable.\nEn todas estas funciones, ruta es la ruta del fichero ejecutable que es invocado. Fichero es el nombre de un fichero ejecutable, la ruta del fichero se construye buscando el fichero en los directorios indicados en la variable de entorno PATH.\nArg0, arg1,...,argN son punteros a cadenas de caracteres y constituyen la lista de argumentos o parámetros que se le pasa al nuevo programa. Por convenio, al menos arg0 está presente siempre y apunta a una cadena idéntica a ruta o al último componente de ruta. Para indicar el final de los argumentos siempre a continuación del último argumento argN se pasa un puntero nulo NULL.\nEnvp es un array de punteros a cadenas de caracteres terminado en un puntero nulo que constituyen el entorno en el que se va ejecutar el nuevo programa. Cuando un programa es invocado con una llamada al sistema exec, el sistema pone a su disposición un array de cadenas de caracteres conocido como entorno. A cada cadena se le conoce como variable de entorno (ver sección \n##). Por convenio, cada una de estas cadenas tiene la forma:\nVARIABLE_ENTORNO=VALOR_VARIABLEPara obtener el valor de una variable de entorno determinada o para declarar nuevas variables, se pueden usar las funciones getenv y putenv cuyos prototipos se encuentran en el fichero de cabecera <stdlib.h>.\nPara los programas que se ejecutan mediante una llamada a execl, execv, execlp o execvp, el entorno se encuentra accesible únicamente a través de la variable global environ declarada en la librería C. Para los programas que se invocan con las llamadas execle y execve, el entorno es accesible también a través del parámetro envp. El entorno de un proceso es heredado por todos sus procesos hijos.\nSi el programa que es invocado es un programa compilado, es decir, tiene un número mágico en su cabecera primaria que lo identifica como directamente ejecutable, entonces recibe los parámetros arg0, arg1,...,argN o argv y envp a través de la función principal main. Para pasar envp a main, ésta se debe declarar con tres argumentos formales, en vez de con los dos argumentos tradicionales (ver sección 1\n## para más detalles:\n   main(int argc, char *argv[], char *envp[]);\nSi el fichero invocado no dispone de un número mágico que lo identifica como un programa compilado directamente ejecutable entonces es considerado como un shell script y se le pasa al intérprete de comandos /bin/sh para que lo ejecute.\nSi la llamada al sistema exec devuelve el control al programa desde que se invoca, es porque no se ha ejecutado correctamente, entonces en resultado se almacenará el valor -1 y en la variable errno estará el código del error producido."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## El algoritmo exec()",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_4-8-2"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Hebras",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Motivación\nMuchos programas deben realizar varias tareas, en gran medida independientes, que no tienen necesidad de ser ejecutadas secuencialmente. Por ejemplo, un servidor con una base de datos puede recibir y atender numerosas peticiones de clientes. Puesto que las peticiones no tienen por qué ser servidas en un orden particular, pueden ser tratadas como unidades de ejecución independientes, las cuales en principio podrían ejecutarse en paralelo. Obviamente, la aplicación se comportaría mejor si el sistema dispusiera de mecanismos para la ejecución en paralelo de las subtareas.\nEn los sistemas UNIX tradicionales, un programa como el comentado utiliza múltiples procesos. La mayoría de las aplicaciones de un servidor tienen un proceso receptor de escucha que espera por las peticiones de los clientes. Cuando una petición llega, el proceso receptor crea un nuevo proceso con la llamada al sistema fork para servir la petición. Puesto que el servicio de una petición a menudo requiere operaciones de E/S que pueden bloquear el proceso, esta aproximación de múltiples procesos posee algunos beneficios de concurrencia incluso en sistemas con un único procesador.\nConsidérese ahora el caso de una aplicación de tipo científico que calcula los valores de varios elementos de un array, siendo cada elemento independiente de los demás. Se podría crear un proceso diferente para cada elemento del array y conseguir paralelismo encaminando cada proceso hacia diferentes computadoras, o quizás hacia los diferentes CPUs de un sistema multiprocesador. Si un proceso se bloquea debido a que debe esperarTema 4: Algoritmos de control de procesos en UNIX 219\npor una operación de E/S o por el servicio de un fallo de página, otro proceso podría progresar mientras tanto.\nEl uso de múltiples procesos para implementar una aplicación tiene algunas desventajas obvias. Crear todos estos procesos añade una sobrecarga (overhead) no despreciable al sistema, ya que fork suele ser usualmente una llamada al sistema bastante costosa en el uso de recursos. Además, puesto que cada proceso tiene su propio espacio de direcciones, se deben usar mecanismos de intercomunicación entre procesos como el paso de mensajes o memoria compartida. Asimismo, se requiere un trabajo adicional para: encaminar los procesos hacia diferentes máquinas o procesadores, pasar información entre los procesos, esperar a su finalización y reunir todos los resultados. Finalmente, los sistemas UNIX no tienen entornos de trabajo apropiados para compartir ciertos recursos.\nCon estos ejemplos se han ilustrado las deficiencias de la abstracción de proceso y la necesidad de disponer de mejores servicios para el procesamiento paralelo, que pueden resumirse de la siguiente forma:\nMuchas aplicaciones son inherentemente paralelas por naturaleza y requieren un modelo de programación que soporte el paralelismo. Los sistemas UNIX tradicionales fuerzan a tales aplicaciones a ejecutar secuencialmente sus tareas independientes o a idear raros e ineficientes mecanismos para realizar las operaciones múltiples.\nLos procesos tradicionales no pueden aprovecharse de las arquitecturas de multiprocesador, puesto que un proceso sólo puede usar un único procesador a la vez. Una aplicación debe crear varios procesos separados e encaminarlos hacia los procesadores disponibles. Estos procesos deben encontrar la forma de compartir la memoria y los recursos, además de sincronizar sus tareas unos con otros.\nLas distribuciones de UNIX modernas resuelven las limitaciones que aparecen con el modelo de proceso proporcionando el modelo de hebra (thread). La abstracción hebra representa a una unidad computacional que es parte de un trabajo de procesamiento de una aplicación. Estas unidades interaccionan entre si muy poco, por lo que son prácticamente independientes.\nDe forma general un proceso se puede considerar como una entidad compuesta que puede ser dividida en dos componentes: un conjunto de hebras y una colección de recursos. La hebra es un objeto dinámico que representa un punto de control en el procesoy que ejecuta una secuencia de instrucciones. Los recursos (espacio de direcciones, ficheros abiertos, credenciales de usuario, cuotas,...) son compartidos por todas las hebras de un proceso. Además cada hebra tiene sus objetos privados, tales como un contador de programa, una pila y un contador de registro. Un proceso UNIX tradicional tiene una única hebra de control. Los sistemas multihebras como son SVR4 y Solaris extienden este concepto permitiendo más de una hebra de control en cada proceso.\nEn función de sus propiedades y usos se distinguen tres tipos diferentes de hebras:\n- Hebras del núcleo: son objetos primitivos no visibles para las aplicaciones.\n- Procesos ligeros: son hebras visibles al usuario que son reconocidas por el núcleo y que están basadas en hebras del núcleo.\n- Hebras de usuario: Son objetos de alto nivel no visibles para el núcleo. Pueden utilizar procesos ligeros, si éstos son soportados por el núcleo, o pueden ser implementadas en un proceso UNIX tradicional sin un apoyo especial por parte del núcleo.\n ## Hebras del núcleo\nUna hebra del núcleo no necesita ser asociada con un proceso de usuario. Es creada y destruida internamente por el núcleo cuando la necesita. Se utiliza para ejecutar una función específica como por ejemplo, una operación de E/S o el tratamiento de una interrupción. Comparte el código del núcleo y sus estructuras de datos globales. Además posee su propia pila del núcleo. Puede ser planificada independientemente y utiliza los mecanismos de sincronización estándar del núcleo, tales como sleep() y wakeup().\nLas hebras del núcleo resultan económicas de crear y usar, ya que los únicos recursos que consumen son la pila del núcleo y un área para salvar el contexto a nivel de registros cuando no se están ejecutando. También necesitan de alguna estructura de datos para mantener información sobre planificación y sincronización. Asimismo, el cambio de contexto entre hebras del núcleo se realiza rápidamente.\nLas hebras del núcleo no son un concepto nuevo. Los procesos del sistema tales como el ladrón de páginas en los núcleos de UNIX tradicionales son funcionalmente equivalentes a las hebras del núcleo."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Procesos ligeros",
"properties":
{
"type": "code",
"content": "",
"code_url": "Ejemplo_4-9-3"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Resumen: ¿Qué hemos aprendido?",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": ". En un sistema UNIX la única forma que tiene un usuario de crear un nuevo proceso es invocando a la llamada al sistema fork.\nAl proceso que invoca a fork se le denomina proceso padre, y el proceso hijo es el nuevo proceso que se crea. En la primera parte de este capítulo se describe las principales acciones que realiza el núcleo durante la ejecución de la rutina asociada a la llamada al sistema fork, mediante la ejecución del algoritmo syscall(). Estas acciones comprender la comprobación de la existencia de recursos suficientes (memoria), y de que no existen demasiados procesos ejecutándose. Si la comprobación es positiva, el núcleoasigna al nuevo proceso hijo una entrada en la tabla de procesos y un pid, y crea el contexto del proceso hijo a partir de una copia del contexto del proceso padre. A continuación, el núcleo cambia el estado del proceso hijo al estado preparado para ejecutarse en memoria principal. Cuando el proceso hijo sea planificado para ser ejecutado, su contexto será restaurado, es decir, el núcleo extraerá la capa 1 de la pila de capas de contexto. Finalmente, la ejecución finaliza en el contexto del hijo devolviendo a syscall() el valor 0.\n2. Las señales proporcionan un mecanismo para notificar a los procesos los eventos que se producen en el sistema. Los eventos se identifican mediante números enteros. Algunos de estos eventos son notificaciones asíncronas, son errores síncronos o excepciones. También se pueden utilizar como un mecanismo de comunicación y sincronización entre procesos.\nEn el mecanismo de señalización se distinguen dos fases principalmente: generación y tratamiento. Una señal es generada cuando ocurre un evento (causado por el propio proceso receptor, otro proceso, interrupciones o acciones externas) que debe ser notificado a un proceso. La señal es recibida o tratada, cuando el proceso para el cual fue enviada la señal reconoce su llegada y toma las acciones apropiadas. Cada señal tiene asignada una acción por defecto, que realizará el núcleo si el proceso no ha especificado una, y son: abortar, finalizar, suspender, continuar el proceso e ignorar la señal. En el caso de especificar una acción alternativa, esta puede ser ignorar la señal o invocar a una función definida por el usuario (manejador de la señal). El proceso receptor se da cuenta de la existencia de la señal cuando el núcleo (en el nombre del proceso) invoca al algoritmo issig() para comprobar la existencia de señales pendientes.\nEn esta parte del capítulo se describen varias llamadas al sistema para el manejo de señales, como son: kill, raise, signal, pause, sigsetmask, sigblock.\n3. Para pasar un proceso al estado dormido, el núcleo usa el algoritmo sleep (). Este algoritmo requiere como parámetros de entrada la prioridad para dormir y la dirección de dormir o canal asociada al evento por el que estará esperando el proceso.\nLas acciones que realiza sleep() se pueden resumir en las siguientes: elevar el npi para bloquear las interrupciones, marcar en la tabla de procesos que el estado es dormido;\nguardar en la tabla de procesos la dirección de dormir y la prioridad para dormir, y colocar al proceso en la lista de procesos dormidos. A continuación compara la prioridad para dormir con un cierto umbral, para comprobar si puede ser interrumpido. En caso afirmativo, se distinguen el caso en que el proceso puede o no ser interrumpido por señales. Si puede ser interrumpido, el núcleo invoca al algoritmo issig() para comprobar la existencia de señales pendientes, en cuyo caso el núcleo borra el proceso de la lista de procesos dormidos, restaura el valor del npi e invoca al algoritmo psig(). En caso contrario, el núcleo realiza un cambio de contexto, y la ejecución es momentáneamente detenida. Cuando el proceso se ha despertado, se invoca de nuevo al algoritmo issig().\nPara despertar a un proceso que se encuentra en el estado dormido a la espera de la aparición de un determinado evento, el núcleo usa el algoritmo wakeup(). La invocación de este algoritmo se realiza dentro de algún otro algoritmo, como los asociados a las llamadas al sistema, o a las rutinas de manipulación de interrupciones, o cuando genera una señal para un proceso. Las acciones que realiza el núcleo son las siguientes: elevar el npi para bloquear las interrupciones, buscar en la lista de procesos dormidos a aquellos procesos que están a la espera de la aparición del evento asociado a la dirección de dormir, que implica eliminar al proceso de la lista, y a continuación marcar en el campo estado de su estado de la tabla de procesos el estado de preparado para su ejecución. Si el proceso despertado no estaba cargado en memoria principal, el núcleo despierta al proceso intercambiador. En caso contrario, si el proceso es más elegible para ser ejecutado, el núcleo activa un indicador denominado runrun. Cuando ya no quedan más procesos en la lista, el núcleo restaura el npi y el algoritmo finaliza.\n4. Un proceso finaliza cuando se ejecuta la llamada al sistema exit. El algoritmo exit() requiere como parámetro de entrada el código de retorno para el proceso padre. Las acciones que realiza el núcleo durante la ejecución de este algoritmo son resumidamente: deshabilitar el tratamiento de las señales; cerrar todos los ficheros abiertos por el proceso, liberar recursos (nodos-i, memoria), marcar el estado del proceso a zombi en su entrada de la tabla de procesos, salvar datos estadísticos y el código de retorno en su entrada de la tabla de procesos, y hacer que el proceso inicial adopte a los procesos hijos del proceso si existen. Si la respuesta afirmativa, se envía una señal SIGCHLD al proceso inicial para que borre sus entradas de la tabla de procesos. Finalmente, el núcleo hace un cambio de contexto.\n5. Finalmente, el algoritmo esperar la terminación de un proceso (wait) permite sincronizar la ejecución de un proceso con la terminación de algunos de sus procesos hijos.Las principales acciones que realiza es: comprobar que el proceso posee algún hijo; en cuyo caso el núcleo comprueba si alguno está en estado zombi. Si existe alguno, busca un hijo en este estado zombi, borra los contenidos de la entrada asociado en la tabla de procesos, y devuelve el pid del hijo y el código de retorno. Si no existe ningún proceso hijo en estado zombi, el núcleo invoca al algoritmo sleep().\nLa llamada al sistema exec sirve para invocar desde un proceso a otro programa ejecutable (programa compilado o shell script). Básicamente exec carga las regiones de código, datos y pila del nuevo programa en el contexto de usuario del proceso que invoca a exec. Una vez concluida esta llamada al sistema, ya no se podrá acceder a las regiones de código, datos y pila del proceso invocador. Existe toda una familia de funciones de librería asociadas a esta llamada al sistema: execl, execv, execle, execve, execlp y execvp.\nAl tratar la llamada al sistema exec desde alguna de sus funciones de librería, el núcleo invoca a la rutina o algoritmo exec(). Las acciones que se realizan son: localizar el nodo-i del fichero, comprobar que el usuario tiene permiso para ejecutarlo y de que se trata de un fichero ejecutable, salvar en un área del núcleo los parámetros de entrada de la función de biblioteca asociada a exec, desligar del proceso sus regiones de código, datos y pila de usuario, configurar un nuevo contexto de usuario, copiar en la pila los parámetros de entrada de la función exit, y configurar el contexto de registros salvado en la capa 0 de la pila de capas de contexto para poder comenzar la ejecución del fichero ejecutable.\n6. Con el modelo de proceso, existen deficiencias tales como la necesidad de disponer de mejores servicios para el procesamiento paralelo. Las distribuciones de UNIX modernas resuelven las limitaciones que aparecen con el modelo de proceso proporcionando el modelo de hebra (thread). La abstracción hebra representa a una unidad computacional que es parte de un trabajo de procesamiento de una aplicación. De forma general un proceso se puede considerar como una entidad compuesta que puede ser dividida en dos componentes: un conjunto de hebras y una colección de recursos. La hebra es un objeto dinámico que representa un punto de control en el proceso y que ejecuta una secuencia de instrucciones. Los recursos (espacio de direcciones, ficheros abiertos, credenciales de usuario, cuotas,...) son compartidos por todas las hebras de un proceso.Tema 4: Algoritmos de control de procesos en UNIX 231\nEn función de sus propiedades y usos se distinguen tres tipos diferentes de hebras: hebras del núcleo, procesos ligeros y hebras de usuario.Tema 4: Algoritmos de control de procesos en UNIX 233"
}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué realiza la llamada al sistema fork?",
"responses":[                         "Es la única forma que tiene un usuario de crear un nuevo proceso, cuando se invoca\nfork se crea una copia del proceso que lo invoca llamado proceso hijo.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué dos comprobaciones realiza el núcleo al ejecutar la rutina de la llamada al\n                    sistema fork?",
"responses":[                         "La primera acción que realiza el núcleo al ejecutar la rutina de la llamada al sistema fork es comprobar la existencia de recursos suficientes en el sistema para poder crear al nuevo proceso. En un sistema con gestión de memoria mediante intercambio, debe existir suficiente espacio en memoria principal o en memoria secundaria para poder almacenar al nuevo proceso. En un sistema con gestión de memoria por demanda de páginas, el núcleo tiene que poder asignar memoria para alojar nuevas tablas de páginas.\nAdemás el núcleo también comprueba que no existen demasiados procesos ejecutándose.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe el proceso de creación de la parte dinámica de un proceso hijo.",
"responses":[                         "Una vez finalizada la creación de la parte estática del contexto del proceso hijo, el núcleo procede a crear la parte dinámica. En primer lugar asigna memoria para la pila de capas de contexto del proceso hijo y añade en ella una copia de la capa 0 de la pila de capas de contexto del proceso padre. Después, si la pila del núcleo se implementa en un área de memoria independiente entonces asigna espacio para ella. En el caso de que se implemente dentro del área U, entonces el núcleo automáticamente crea la pila del núcleo al crear el área U. En ambos casos el contenido de la pila del núcleo asociado al padre y de la pila del núcleo asociado al hijo es idéntico.\nA continuación, añade otra capa de contexto (capa 1) en la pila de capas de contexto del proceso hijo y conAQUÍ VA UNA IMAGENel valor del contexto de registros salvado en ella para que el proceso hijo pueda comenzar a ejecutarse cuando sea planificado.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué dos fases se distinguen principalmente en el mecanismo de señalización?",
"responses":[                         "En el mecanismo de señalización se distinguen dos fases principalmente: generación y tratamiento. Una señal es generada cuando ocurre un evento que debe ser notificado a un proceso. La señal es recibida o tratada, cuando el proceso para el cual fue enviada la señal reconoce su llegada y toma las acciones apropiadas.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe las principales fuentes de generación de señales.",
"responses":[                         "- Excepciones: cuando durante la ejecución de un proceso se produce una excepción (por ejemplo, un intento de ejecutar una instrucción ilegal), el núcleo se lo notifica al proceso mediante el envío de una señal.\n- Otros procesos: un proceso puede enviar una señal a otro proceso, o a un conjunto de procesos, mediante el uso de las llamadas al sistema kill o sigsend. También un proceso puede enviarse una señal asimismo usando la llamada al sistema raise.\n- Interrupciones del terminal: la pulsación simultánea por parte de un usuario de teclas, como [control+c] o [control+], produce el envío de señales a los procesos que se encuentran ejecutándose en el primer plano de un terminal.\n- Control de tareas: los intérpretes de comandos generan señales para manipular tanto a los procesos que se encuentran ejecutándose en primer plano como a los que se encuentran ejecutándose en segundo plano. Cuando un proceso termina o es suspendido, el núcleo se lo notifica a su padre mediante el envío de una señal.\n- Cuotas: cuando un proceso excede su tiempo de uso de la CPU o el tamaño máximo de un fichero, el núcleo envía una señal a dicho proceso.\n- Notificaciones: un proceso puede requerir la notificación de ciertos eventos, como por ejemplo que un dispositivo se encuentra listo para realizar una operación de E/S. El núcleo informa al proceso de este evento enviándole una señal.\n- Alarmas: un proceso puede configurar una alarma para que se active transcurrido un cierto tiempo. Cuando éste expira, el núcleo se lo notifica enviándole una señal.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cuándo se dice que una señal es capturada?",
"responses":[                         "Cuando la acción que se realiza al tratar una señal es ejecutar un manejador definido por el usuario para dicha señal.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿En qué casos el núcleo llama al algoritmo issig()?",
"responses":[                         "El núcleo llama a issig() únicamente en los siguientes casos:\n- Antes de volver al estado ejecución en modo usuario desde el estado ejecución en\nmodo supervisor después de atender una llamada al sistema o una interrupción.\n- Justo antes de entrar en el estado dormido interrumpible.\n- Inmediatamente después de despertar del estado dormido interrumpible.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe los dos parámetros de entrada de la llamada al sistema signal.",
"responses":[                         "La llamada al sistema signal permite especificar el tratamiento de una determinada señal recibida por un proceso. Su sintaxis es:\nresultado = signal(señal, acción)\nSe observa que tiene dos parámetros de entrada, el primero de ellos señal. Es una constante entera que identifica a la señal para la cual el proceso está especificando la acción. También se puede introducir directamente el número asociado a la señal. El parámetro acción. Este parámetro especifica la acción que se debe realizar cuando se trate la señal, puede tomar los siguientes valores:\n- SIG_DFL. Constante entera que indica que la acción a realizar es la acción por defecto asociada a dicha señal\n- SIG_IGN. Constante entera que indica que la señal se debe ignorar.\n- Dirección del manejador de la señal definido por el usuario.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué acciones realiza el núcleo cuando ejecuta sleep(), y encuentra que existen señales pendientes para el proceso y que el proceso puede ser interrumpido?",
"responses":[                         "El núcleo usa el algoritmo sleep() para pasar a un proceso A al estado dormido, después de colocar el proceso A en la cola de procesos dormidos compara la prioridad para dormir con un cierto valor umbral para averiguar si el proceso puede ser interrumpido por señales. Si la prioridad para dormir es menor que el umbral entonces el proceso puedeser interrumpido por señales. En este caso el núcleo invoca al algoritmo issig() para comprobar la existencia de señales pendientes. Si encuentra alguna entonces el núcleo borra al proceso A de la lista de procesos dormidos, restaura el valor del npi (al valor que tenía antes de comenzar a ejecutar el algoritmo) e invoca al algoritmo psig() para tratar la señal.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe el algoritmo que se emplea para sincronizar la ejecución de un proceso con la terminación de un proceso hijo.",
"responses":[                         "Un proceso A puede sincronizar su ejecución con la terminación de un proceso hijo ejecutando la llamada al sistema wait. La sintaxis de esta llamada es:\nresultado = wait(direc);\nSe observa que posee un único parámetro de entrada direc que es la dirección de una variable entera donde se almacenará el código de retorno para el proceso padre generado por el algoritmo exit() al terminar un proceso hijo.\nAsimismo se observa que wait posee un único parámetro de salida resultado que contiene, si la llamada al sistema se ha ejecutado con éxito, el pid del proceso hijo que ha terminado. En caso contrario, contiene el valor -1.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe qué es una hebra del núcleo.",
"responses":[                         "Una hebra del núcleo no necesita ser asociada con un proceso de usuario. Es creada y destruida internamente por el núcleo cuando la necesita. Se utiliza para ejecutar una función especifica como por ejemplo, una operación de E/S o el tratamiento de una interrupción. Comparte el código del núcleo y sus estructuras de datos globales. Además posee su propia pila del núcleo. Puede ser planificada independientemente y utiliza los mecanismos de sincronización estándar del núcleo, tales como sleep()y wakeup().10.5 Respuestas del TEMA 5\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "PLANIFICACIÓN DE PROCESOS EN UNIX ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "- Cómo se tratan las interrupciones del reloj.\n- Planificación tradicional en UNIX, tareas basadas en consideraciones temporales, tales como callouts y alarmas, así como el estudio de algunas llamadas al sistema asociadas con el tiempo.\n- Análisis en detalle del Planificador del SVR4.\n- Análisis del Planificador del Solaris 2.x.\nLa CPU es un recurso de la computadora por cuyo uso compiten los procesos. El sistema operativo debe decidir cómo reparte este recurso entre todos los procesos. El planificador es el componente del sistema operativo que determina qué proceso debe ejecutarse en cada instante. UNIX es esencialmente un sistema de tiempo compartido, lo que significa que permite a varios procesos ejecutarse concurrentemente. En un sistema con un único procesador, la concurrencia no es más que una ilusión, puesto que en realidad solamente se puede estar ejecutando un único proceso en un instante de tiempo dado. El planificador cede el uso de la CPU a cada proceso durante un breve periodo de tiempo antes de planificar para ejecución a otro proceso. A este periodo se le denomina cuanto.\nNaturalmente, conforme la carga del sistema va aumentando cada proceso recibirá menos cuantos de ejecución, y por tanto se ejecutará más lentamente que si el sistema tuviese poca carga. El planificador debe asegurarse de que todos los procesos progresan en su ejecución.\nEn un sistema típico se ejecutarán distintas aplicaciones de forma concurrente. Estas aplicaciones pueden ser clasificadas de acuerdo a sus requerimientos y expectativas de planificación en los siguientes tipos:\n- Aplicaciones interactivas. Se trata de aplicaciones que interaccionan constantemente con sus usuarios. Ejemplo de estas aplicaciones son los intérpretes de comandos, los editores, los programas con interfaces gráficos de usuario, etc. Estas aplicaciones se encuentran a la espera de una entrada del usuario desde el terminal, bien mediante la pulsación de una tecla o mediante el movimiento del ratón. Cuando la entrada es recibida, ésta debe ser procesada rápidamente ya que en caso contrario el usuario encontrará que el sistema es insensible a sus acciones.\n- Aplicaciones batch. Se trata de actividades planificadas por el usuario que típicamente se suelen realizar en segundo plano. Ejemplos de estas actividades son los compiladores, programas de cálculo científico, etc. Para este tipo de actividades, una medida de la eficiencia del planificador es la diferencia entre el tiempo que tarda en completarse estas tareas en presencia de otro tipo de actividades y el tiempo que tardan en completarse cuando son el único tipo de tareas presentes en el sistema.\n- Aplicaciones en tiempo real. Se trata de actividades que son a menudo muy sensibles al tiempo de respuesta del sistema. Aunque existen muchos tipos de aplicaciones enTema 5: Planificación de procesos en UNIX 237\ntiempo real (control de sistemas físicos, adquisición de datos, procesamiento de video, etc), cada una con sus propios requerimientos, todas ellas comparten características comunes. En general este tipo de aplicaciones necesitan un comportamiento de planificación predecible con unos límites garantizados para el tiempo de respuesta.\nEn un sistema que presente un buen comportamiento, todas las aplicaciones independientemente de su tipo deben seguir progresando. Ninguna aplicación debería ser capaz de impedir que otras progresen, excepto si el usuario lo permite explícitamente. Además, el sistema debería siempre ser capaz de recibir y procesar entradas de los usuarios interactivos, ya que en caso contrario el usuario no tendría forma de controlar el sistema.\nUna descripción adecuada del planificador de cualquier sistema operativo, entre ellos UNIX, debe centrarse en dos aspectos: la política de planificación y la implementación.\nLa política de planificación, es el conjunto de reglas que utiliza el planificador para decidir qué proceso debe ser planificado para ser ejecutado en un cierto instante y cuándo debe planificar a otro proceso. La política de planificación elegida debe intentar cumplir, entre otros, los siguientes objetivos:\n- Dar una respuesta rápida a las aplicaciones interactivas.\n- Conseguir una productividad alta de los trabajos batch.\n- Garantizar unos límites para el tiempo de respuesta de las aplicaciones en tiempo real.\n- Evitar el abandono de procesos, es decir, que los procesos pasen mucho tiempo sin recibir el uso de la CPU.\n- Asegurar que las funciones del núcleo tales como, paginación, tratamiento de interrupciones y administración de procesos puedan ser ejecutadas apropiadamente cuando se necesita.\nEstos objetivos a menudo entran en conflicto y el planificador debe buscar el mejor equilibrio entre todos ellos.La implementación del planificador hace referencia a las estructuras de datos y los algoritmos utilizados para implementar la política de planificación. La implementación del planificador debe ser eficiente y producir una sobrecarga mínima en el sistema.\nEn este capítulo en primer lugar se describe el tratamiento de las interrupciones del reloj y las tareas basadas en consideraciones temporales, tales como los callouts y las alarmas. Asimismo se estudian algunas llamadas al sistema asociadas con el tiempo. En segundo lugar, se describe y analiza el planificador implementado en las distribuciones SVR3 y BSD4.3. El capítulo finaliza con un par de apartados dedicados a comentar las principales características de los planificadores implementados en las distribuciones SVR4 y Solaris 2.x, respectivamente."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Tratamiento de las interrupciones del reloj ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "# Consideraciones generales\nCada máquina UNIX tiene un reloj hardware que interrumpe al sistema a intervalos fijos de tiempo. Muchas máquinas requieren cuando se produce una interrupción del reloj que éste sea preparado, mediante instrucciones software, para que vuelva a interrumpir al procesador transcurrido el intervalo de tiempo adecuado. Estas instrucciones son fuertemente dependientes del hardware. Por el contrario, en otras máquinas el reloj se rearma de forma automática.\nAl periodo de tiempo entre dos interrupciones del reloj se le denomina tic de la CPU, tic del reloj, o simplemente tic. La mayoría de las computadoras soportan una variedad de intervalos de tics. UNIX típicamente conAQUÍ VA UNA IMAGENel tic de la CPU a 10 milisegundos12.\nSe denomina frecuencia del reloj al número de tics por segundo. Por ejemplo, para un tic de 10 milisegundos, la frecuencia del reloj sería 100 Hz.\nEl tratamiento de la interrupción del reloj depende fuertemente del sistema. La interrupción del reloj tiene un npi bastante elevado, solamente superado por las interrupciones asociadas a los errores de la máquina. Es por ello que la rutina de tratamiento de la interrupción del reloj se implementa para que realice lo más rápidamente las siguientes tareas:\n12 Éste no es un valor universal y depende de cada variante de UNIX. También depende de la resolución del reloj hardware del sistema.Tema 5: Planificación de procesos en UNIX 239\n- Rearmar el reloj hardware si fuera necesario.\n- Adaptar las estadísticas de uso de la CPU para el proceso actual, es decir, usando la\nCPU.\n- Enviar una señal SIGXCPU al proceso actual si éste ha excedido su cuota de uso de la CPU (si hubiese).\n- Adaptar el reloj de la hora del día y otros relojes relacionados.\n- Comprobación de los callouts.\n- Despertar a los procesos del sistema, como por ejemplo el intercambiador o el ladrón de páginas, cuando sea necesario.\n- Comprobación de las alarmas. \n## Callouts\nLos callouts son un mecanismo interno del núcleo que le permite invocar funciones transcurrido un cierto tiempo. Un callout típicamente almacena el nombre de la función que debe ser invocada, un argumento para dicha función y el tiempo en tics transcurrido el cual la función debe ser invocada.\nLos usuarios no tiene ningún control sobre este mecanismo. Los callouts se pueden utilizar para la invocación de tareas periódicas tales como: la transmisión de paquetes de red, ciertas funciones de administración de memoria y del planificador, la monitorización de dispositivos para evitar la pérdida de interrupciones, etc.\nEs importante resaltar que la rutina de tratamiento de la interrupción del reloj no invoca directamente a los callouts. En cada tic, la rutina comprueba si se debe realizar algún callout. Si es así, activa un indicador para indicar que el manipulador de los callouts debe ser ejecutado. El sistema comprueba este indicador cuando retorna a su npi base, si está activado, invoca al manipulador de los callouts, el cual invocará al callout que sea necesario. Por lo tanto, un callout se ejecutará tan pronto como sea posible, pero sólo cuando todas las interrupciones que estaban pendientes hayan sido atendidas.\nEl núcleo mantiene una lista de callouts. La organización de esta lista puede afectar el rendimiento del sistema, si existen varios callouts pendientes, ya que la lista escomprobada por la rutina de tratamiento de la interrupción del reloj a un npi elevado en cada tic de reloj. En consecuencia, la rutina debe intentar optimizar el tiempo de comprobación. Por el contrario, el tiempo requerido para insertar un nuevo callout dentro de la lista es menos crítico puesto que la inserción típicamente ocurre a un npi más bajo y con mucha menos frecuencia que una vez cada tic.\nExisten varias formas de implementar la lista de callouts. Un método usado en BSD4.3 es ordenar la lista en función del tiempo que le resta al callout para ser invocado. A este tiempo comúnmente se le denomina tiempo de disparo. Cada entrada de la lista de callouts almacena la diferencia entre el tiempo de disparo de su callout asociado y el tiempo de disparo del callout asociado a la entrada anterior. El núcleo decrementa el tiempo de la primera entrada de la lista en cada tic de reloj y lanza el callout si el tiempo alcanza el valor 0.\nOtra posible aproximación sería utilizar también una lista ordenada, pero almacenar el tiempo absoluto de finalización para cada entrada. De esta forma, en cada tic, el núcleo compara el tiempo absoluto actual con el de la primera entrada y lanza el callout cuando los tiempos son iguales.En la AQUÍ VA UNA IMAGEN5-1(a) se muestra la lista de callouts en un cierto instante de tiempo. Se observa que dicha lista contiene cuatro entradas asociadas a cuatro callouts que han sido ordenados en función de su tiempo de disparo, es decir, el tiempo que resta para que sean invocados.\nLa primera entrada está asociada al callout para la función roundrobin y en ella también se almacena su tiempo de disparo que es 2 tics.\nLa segunda entrada está asociada al callout para la función schedcpu. En su entrada de la lista se almacena el tiempo que resta para ser invocada con respecto a roundrobin, en este caso es 1 tic. Su tiempo de disparo es la suma de los tiempos almacenados en esta segunda entrada y en la primera entrada, es decir, 2+1= 3 tics.Tema 5: Planificación de procesos en UNIX 241\n     Cabecera de la lista de callouts\nt=2\nroundrobin\nt=1\nschedcpu\nTiempo de disparo: 2 3 7 7\n(a) Lista de callouts en un cierto instante de tiempo\nTiempo de disparo: 1 2 6\n(b) Lista de callouts un tic más tarde\nAQUÍ VA UNA IMAGEN5-1: Implementación de la lista de callouts en el UNIX BSD\n6\nt=4\nf1\nt=0\nf2\n      Cabecera de la lista de callouts\nt=1\nroundrobin\nt=1\nschedcpu\nLa tercera entrada está asociada al callout para la función f1. En su entrada de la lista se almacena el tiempo que resta para ser invocada con respecto a schedcpu, en este caso es 4 tics. Su tiempo de disparo es la suma de los tiempos almacenados en esta tercera entrada y en las dos entradas anteriores, es decir, 2+1+4= 7 tics.\nLa cuarta entrada está asociada al callout para la función f2. En su entrada de la lista se almacena el tiempo que resta para ser invocada con respecto a f1, en este caso es 0 tics. Su tiempo de disparo es la suma de los tiempos almacenados en esta cuarta entrada y en las tres entradas anteriores, es decir, 2+1+4+0= 7 tics.\nPor otra parte, en la AQUÍ VA UNA IMAGEN5-1(b) se muestra la lista de callouts un tic más tarde. Se observa como se ha restado 1 tic a la primera entrada de la lista. En consecuencia el tiempo de disparo para los cuatro callouts se ha reducido también en 1 tic.\n ## Alarmas\nUn proceso puede solicitar al núcleo que le envíe una señal una vez haya transcurrido un determinado tiempo. A este mecanismo de aviso se le denomina alarma. Existen tres tipos de alarmas:\n- Alarma de tiempo real. Tiene asociado un contador o temporizador que se decrementa en tiempo real. Cuando el temporizador llega a 0 el núcleo envía al proceso una señal SIGALRM.\n- Alarma de tiempo virtual. Tiene asociado un temporizador que se decrementa cuando el proceso se está ejecutando en modo usuario (tiempo virtual). Cuando el temporizador llega a 0 el núcleo envía al proceso una señal SIGVTALRM.\nt=4\nf1\nt=0\nf2\n- Alarma de perfil. Tiene asociado un temporizador que se decrementa cuando el proceso se está ejecutando tanto en modo usuario como en modo supervisor. Cuando el temporizador llega a 0 el núcleo envía al proceso una señal SIGPROF.\nUna elevada resolución de una alarma de tiempo real no implica una alta precisión. Supóngase que un usuario solicita que se le envíe una alarma de tiempo real después de 60 milisegundos. Cuando el tiempo expira, el núcleo envía la señal SIGALRM al proceso. Sin embargo, éste no se percatará de ella y tratará la señal hasta que no sea planificado de nuevo. Esto podría introducir un retardo substancial dependiendo de la prioridad de planificación del proceso receptor y de la carga del sistema. Los temporizadores de alta resolución son útiles cuando son usados para procesos de alta prioridad, que son menos susceptibles de sufrir retardos de planificación.\nPor el contrario, la precisión de las alarmas de perfil y de tiempo virtual no sufren del problema descrito para las alarmas de tiempo real, puesto que no utilizan el tiempo real. Sin embargo, su precisión se ve afectada por el hecho de que la rutina de tratamiento de la interrupción del reloj carga todo el tic al proceso actual, incluso aunque éste solamente haya utilizado parte del mismo. De esta forma, el tiempo medido por estas alarmas refleja el número de interrupciones del reloj que han ocurrido mientras el proceso estaba ejecutándose. En general se puede afirmar que si se conAQUÍ VA UNA IMAGENun tiempo grande para el disparo de estas alarmas, entonces en promedio se compensa este efecto y el sistema mide bastante bien el tiempo utilizado por el proceso en su ejecución en modo usuario y/o en modo supervisor. En consecuencia la alarma se disparará con bastante precisión. Sin embargo, si el tiempo configurado para el disparo es pequeño, entonces estas alarmas sufren de una imprecisión bastante significativa.\nExisten diversas llamadas al sistema que permiten a los usuarios la configuración de alarmas. Así, por ejemplo en el UNIX System V, la llamada al sistema alarm permite solicitar una alarma de tiempo real. Mientras que en el UNIX BSD, la llamada al sistema setitimer permite al proceso solicitar cualquier tipo de alarma y especificar el intervalo en microsegundos. Internamente, el núcleo convierte este intervalo al número apropiado de tics de CPU, que es la más alta resolución que el núcleo puede suministrar.Tema 5: Planificación de procesos en UNIX 243\n ## Llamadas al sistema asociadas con el tiempo\n ###  Fijación de la fecha del sistema\nLa llamada al sistema stime permite fijar la fecha y la hora actuales de nuestro sistema. Su sintaxis es:\nresultado=stime(&valor);\nEl argumento de la función es un puntero a la variable valor de tipo time_t que es un entero que contiene los segundos transcurridos desde las 00:00:00 GMT13 del día 1 de enero de 1970. Si la llamada al sistema se ejecuta correctamente resultado contendrá el valor 0, en caso contrario contendrá el valor -1.\nLa fecha del sistema sólo la puede fijar un usuario con los privilegios del superusuario. Por lo tanto, stime sólo podrá ser ejecutada por aquellos procesos cuyo euid coincida con el del superusuario."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Lectura de la fecha del sistema",
"properties":
{
"type": "code",
"content": "",
"code_url": "ejemplo_5-3-4-1"     }
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Tiempos de ejecución asociados a un proceso",
"properties":
{
"type": "code",
"content": "",
"code_url": "ejemplo_5-3-4-2"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Planificación tradicional en UNIX",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "n esta sección se va a describir el diseño y la implementación del planificador utilizado en BSD4.314. La política de planificación que utiliza este planificador es del tipo round robin con colas multinivel con realimentación. Cada proceso tiene asignada una prioridad de planificación que cambia con el tiempo. El planificador agrupa las prioridades de planificación en niveles de prioridad, cada nivel de prioridad es un rango de valores de prioridad que el planificador maneja conjuntamente. De este modo el planificador mantiene una cola distinta para para cada nivel de prioridad. Como la prioridad de un proceso puede cambiar con el tiempo cada vez que se recalculen las prioridades el proceso podría cambiar de nivel de prioridad, moviéndose entonces a otra cola de planificación.\nEl planificador siempre selecciona al proceso que encontrándose en el estado preparado en memoria principal para ser ejecutado o en el estado expropiado tiene el mayor nivel de prioridad. En el caso de los procesos de igual prioridad (se encuentran en la misma cola) lo que hace es ceder el uso de la CPU a uno de ellos durante un cuanto, cuando finaliza dicho cuanto le expropia la CPU y se lo cede a otro proceso. El planificador varía dinámicamente la prioridad de los procesos basándose en su tiempo de uso de la CPU. Si un proceso de mayor prioridad alcanza el estado preparado en memoria principal para ser ejecutado, el planificador expropia el uso de la CPU al proceso actual incluso aunque éste no haya completado su cuanto.\nEl núcleo tradicional de UNIX es estrictamente no expropiable. Es decir, si el proceso actual se encuentra en modo núcleo (debido a una llamada al sistema o a una interrupción), no puede ser forzado a ceder la CPU a un proceso de mayor prioridad. Dicho proceso cederá voluntariamente la CPU cuando entre en el estado dormido. En caso contrario sólo se le podrá expropiar la CPU cuando retorne a modo usuario.\n14 El planificador en SVR3 es prácticamente idéntico, difiere únicamente en algunos aspectos menores, tales como el nombre de algunas funciones y variables.\n ## Prioridades de planificación de un proceso\nLa prioridad de planificación de un proceso es un valor entre 0 y 127. Numéricamente los valores más bajos corresponden a las prioridades más altas. Las prioridades entre 0 y 49 están reservadas para el núcleo, mientras que los procesos en modo usuario tienen las prioridades entre 50 y 127.\nLa entrada asociada a un proceso en la tabla de procesos posee los siguientes campos que contienen información relacionada con la prioridad de planificación:\n- p_pri. Contiene la prioridad de planificación actual.\n- p_usrpri. Contiene la prioridad de planificación actual en modo usuario.\n- p_cpu. Contiene el tiempo (en tics) de uso de la CPU.\n- p_nice. Contiene el factor de amabilidad, que es controlable por el usuario.\nLos campos p_pri y p_usrpri se utilizan de modo diferente. El planificador consulta p_pri para decidir qué proceso debe planificar. Cuando un proceso se encuentra en modo usuario, su valor p_pri es idéntico a p_usrpri, ya que cada vez que se retorna al modo usuario se establece p_pri=p_usrpri.\nCuando el proceso despierta después de haber entrado en el estado dormido durante una llamada al sistema, su prioridad p_pri es temporalmente aumentada para dar preferencia al procesamiento en modo núcleo. Por este motivo el planificador utiliza p_usrpri para salvar la prioridad que debe ser asignada al proceso cuando éste retorne al modo usuario.\nEl núcleo asocia una prioridad de dormir en función del evento por el que el proceso entró en el estado dormido. Ésta es una prioridad en modo núcleo, y por tanto su valor está comprendido entre 0 y 49. Por ejemplo (ver Tabla 3-1), la prioridad de dormir para un proceso esperando por la entrada en un terminal es 28, mientras que para un proceso esperando por una operación de E/S con el disco es 20. Cuando un proceso despierta, el núcleo conAQUÍ VA UNA IMAGENsu valor p_pri a la prioridad de dormir del evento o recurso. Puesto que las prioridades en modo núcleo son más altas que las prioridades en modo usuario, estos procesos son planificados antes que aquellos que ejecutan código de usuario. Esto permite que las llamadas al sistema se puedan completar apropiadamente, lo que es deseablepuesto que los procesos pueden tener bloqueado algún recurso clave del núcleo mientras ejecutan la llamada al sistema.\nCuando un proceso completa la llamada al sistema y va a retornar a modo usuario, su prioridad de planificación es configurada a su prioridad en modo usuario actual, es decir, al valor que se encontraba almacenado en p_usrpri. Si esta prioridad es más baja que la de otros procesos planificables, entonces el núcleo realizará un cambio de contexto.\nLa prioridad en modo usuario depende de dos factores: el factor de amabilidad (p_nice) y el tiempo de uso de la CPU (p_cpu).\nEl factor de amabilidad es un número entero entre 0 y 39. Su valor por defecto es 20. Se denomina factor de amabilidad, porque un usuario incrementando este valor está disminuyendo la prioridad de sus procesos y en consecuencia le está cediendo el turno de uso de CPU a los procesos de otros usuarios. A los procesos en segundo plano el núcleo les asigna de forma automática un factor de amabilidad elevado.\nEl factor de amabilidad de un proceso también puede ser disminuido y en consecuencia se estaría aumentando su prioridad. Esta acción solamente la puede realizar el superusuario.\nLa llamada al sistema nice permite aumentar o disminuir el factor de amabilidad actual del proceso que la invoca. Por lo tanto un proceso no puede modificar el factor de amabilidad de otro proceso. Su sintaxis es:\nresultado=nice(incremento);\ndonde incremento es una variable entera que puede tomar valores entre -20 y 19. El valor de incremento será sumado al valor del factor de amabilidad actual p_nice. Sólo el superusuario puede invocar a nice con valores de incremento negativos. Si se produceunerrordurantelaejecucióndenice,entoncesresultadocontendráelvalor - 1.\nTambién es posible modificar el factor de amabilidad de un proceso desde la línea de comandos mediante el uso del comando nice.\nLos sistemas de tiempo compartido intentan asignar el procesador de tal forma que las aplicaciones en competición reciban aproximadamente la misma cantidad de tiempo deTema 5: Planificación de procesos en UNIX 251\nCPU. Esto requiere monitorizar el uso de la CPU de los diferentes procesos y utilizar esa información en las decisiones de planificación. El campo p_cpu almacena una medida del uso de la CPU por parte del proceso. Este campo se inicializa a 0 cuando el proceso es creado. En cada tic, la rutina de tratamiento de la interrupción del reloj incrementa p_cpu para el proceso actualmente en ejecución, hasta un máximo de 127. Además, cada segundo, el núcleo invoca a una rutina denominada schedcpu que reduce el valor de p_cpu de un proceso mediante un factor de disminución (decay). SVR3 utiliza un factor de disminución fijo de 1/2, mientras que BSD4.3 utiliza la siguiente fórmula:\ndecay=(2*load_average)/(2*load_average+1); (1)\ndonde load_average es el número medio de procesos preparados para ejecución\nen el último segundo.\nLuego al cabo de un segundo el nuevo valor de p_cpu vendrá dado por la fórmula:\np_cpu=decay*p_cpu; (2)\nLa rutina schedcpu también recalcula las prioridades de usuario de todos los procesos usando la fórmula:\np_usrpri=PUSER+(p_cpu/4)+(2*p_nice); (3)\ndonde PUSER es la prioridad de usuario base, que vale 50. Este valor es la prioridad más alta que puede tomar un proceso ejecutándose en modo usuario y es justamente el límite con respecto a las prioridad en modo núcleo.\nComo resultado, si un proceso ha acumulado recientemente una gran cantidad de tiempo de CPU, su factor p_cpu aumentará. Ello producirá un mayor valor de p_usrpri, y por tanto una prioridad de ejecución más baja. Cuanto más tiempo está esperando un proceso en ser planificado, más disminuirá el factor de disminución su p_cpu y en consecuencia su prioridad irá aumentando.\nEste esquema evita que los procesos de baja prioridad nunca lleguen a ser ejecutados. También favorece a los procesos limitados por E/S (procesos que requieren muchas operaciones de E/S, por ejemplo, las consolas de comandos y los editores de texto) en contraposición a los procesos limitados por la CPU (procesos que requieren mucho uso de la CPU, por ejemplo, los compiladores). Un proceso limitado por E/S,mantiene una alta prioridad ya que su p_cpu es pequeño, y recibe tiempo de CPU rápidamente cuando la necesita. Por contra, los procesos limitados por la CPU tienen valores de p_cpu altos y por tanto una baja prioridad.\nEl factor de uso de la CPU suministra justicia y paridad en la planificación de los procesos de tiempo compartido. La idea básica es mantener la prioridad de todos estos procesos en un rango aproximadamente igual durante un periodo de tiempo. Los procesos subirán o bajarán dentro de un cierto rango dependiendo de cuánto tiempo de CPU hayan consumido recientemente. Si las prioridades cambian demasiado lentamente, los procesos que comenzaran con una prioridad más baja, permanecerían así durante largos periodos de tiempo, por lo que su ejecución se demorará demasiado.\nEl efecto del factor de disminución es suministrar un promedio ponderado exponencialmente de uso de la CPU a los procesos durante todo su tiempo de vida. La formula usada en el SVR3 conduce a un promedio exponencial simple, que tiene como efecto indeseable la elevación de las prioridades cuando la carga del sistema aumenta. Esto es así porque en un sistema con mucha carga cada proceso recibe poco uso de la CPU y en consecuencia su valor de uso de la CPU se mantiene bajo, y el factor de disminución lo reduce aún más. Como resultado, el uso de la CPU no tiene mucho impacto en la prioridad y los procesos que comienzan con una prioridad más baja se quedan sin usar la CPU durante un tiempo desproporcionado.\nLa aproximación BSD4.3 fuerza al factor de disminución a depender de la carga del sistema. Cuando la carga es elevada el factor de disminución es pequeño. Consecuentemente, procesos que reciben ciclos de CPU verán rápidamente disminuida su prioridad.\n ## Implementación del planificador\nEl planificador mantiene un array denominado qs de 32 colas de ejecución (ver AQUÍ VA UNA IMAGEN5-2). Cada cola se corresponde a cuatro prioridades adyacentes. Así, la cola 0 es utilizada por las prioridades 0-3, la cola 1 por las prioridades 4-7, etc. Cada cola contiene la cabecera de la lista doblemente enlazada de entradas de la tabla de procesos. La variable global whichqs contiene un mapa de bits con un bit asociado a cada cola. El bit está activado si hay al menos un proceso en la cola. Solamente procesos planificables son mantenidos en estas colas del planificador. Esto simplifica la tarea de selección de un proceso para ser ejecutado. El algoritmo del núcleo que implementa el cambio de contexto (swtch() en BSD4.3), examina whichqs para encontrar el índice del primer bit activado.Tema 5: Planificación de procesos en UNIX 253\nEste índice identifica la cola del planificador que contiene al proceso ejecutable de más elevada prioridad. El algoritmo swtch() borra al proceso de la cabeza de la cola, y realiza el cambio de contexto.En la AQUÍ VA UNA IMAGEN5-2 se muestra el array qs y la variable global whichqs. Se observa que la cola 3 (se comienza a contar desde 0) contiene 3 procesos cuyas prioridades se encuentran en el rango 12-15. En consecuencia, en la variable whichqs el cuarto bit desde la izquierda, que es el asociado a la cola 3, se encuentra activado. Asimismo se observa que la cola 5 contiene 2 procesos cuyas prioridades se encuentran en el rango 20-23. Por lo tanto, en la variable whichqs el sexto bit desde la izquierda, que es el asociado a la cola 5, se encuentra activado.\nCuando el algoritmo del núcleo que implementa el cambio de contexto (swtch()) examine whichqs comenzando por la izquierda el primer bit que encontrará activado será el asociado a la cola 3. El proceso que será planificado será el que se encuentre en la cabeza de la cola. Así que el algoritmo swtch() borra al proceso de la cabeza de la cola, y realiza el cambio de contexto.\n 32 bits\nwhichqs\n000101\nqs\n    0-3\n 4-7\n 8-11\n 12-15\n 16-19\n 20-23\n  124-127\n AQUÍ VA UNA IMAGEN5-2: Estructuras que usa el planificador en el UNIX BSD4.3\nPuesto que tanto BSD4.3, SVR2 y SVR3 tenían a la arquitectura VAX-11 como referencia, la implementación del planificador está fuertemente influenciado por esta arquitectura.\n ## Manipulación de las colas de ejecución\nEl planificador sigue las siguientes reglas para manipular las colas de ejecución:\nPPP PP\n- El proceso de más alta prioridad siempre se ejecuta, excepto si el proceso actual se está ejecutando en modo núcleo.\n- Un proceso tiene asignado un tiempo de ejecución fijo denominado cuanto (100 ms en 4.3BSD). Esto solamente afecta a la planificación de los procesos pertenecientes a la misma cola. Cada 100 milisegundos, el núcleo invoca (usando un callout) una rutina denomina roundrobin para planificar al siguiente proceso de la misma cola.\n- Si un proceso en una cola de mayor nivel de prioridad fuese puesto en el estado listo para ejecución, éste sería planificado de forma preferente sin esperar por roundrobin.\n- Si los procesos en el estado preparado en memoria para ser ejecutado o en el estado expropiado pertenecen a una cola de prioridad más baja que el proceso actual, éste continuará ejecutándose incluso aunque su cuanto haya expirado.\nLa rutina schedcpu recalcula la prioridad de todos los procesos una vez por segundo. Puesto que la prioridad no puede cambiar mientras el proceso está en la cola de planificados, schedcpu borra al proceso de la cola, cambia su prioridad, y lo vuelve a colocar, quizás en una cola de prioridad distinta. La rutina de tratamiento de la interrupción del reloj recalcula la prioridad del proceso actual cada cuatro tics.\nEl núcleo conAQUÍ VA UNA IMAGENun indicador denominado runrun, que indica que un proceso (B) de mayor prioridad que el actual (A) está esperando para ser planificado. Cuando el proceso A retorne a modo usuario, el núcleo comprueba el indicador runrun, si está activado, transfiere el control a la rutina de cambio de contexto, para iniciar un cambio de contexto y planificar a B.Supóngase que en un sistema UNIX el tic de reloj es de 10 ms y que el cuanto es de 100 ms. En consecuencia en un cuanto se producirán 10 tics.\nSupóngase también que tres procesos A, B y C han sido creados de forma simultánea con una prioridad inicial p_usrpri=90. El factor de amabilidad para todos ellos es p_nice=20. La prioridad de usuario base es PUSER=50. El tiempo de uso de la CPU (en tics) es p_cpu=0 para los tres procesos. Se va a utilizar la siguiente notación p_usrpri(X) y p_cpu(X) denotan la prioridad de usuario y el tiempo de uso de la CPU, respectivamente, para el proceso X.\nSupóngase además que los procesos durante su ejecución no invocan a ninguna llamada al sistema y que no existe ningún otro proceso en el sistema en el estado preparado para ejecución.Tema 5: Planificación de procesos en UNIX 255\nEn el modelo de planificador descrito la rutina de tratamiento de la interrupción de reloj (se ejecuta cada tic) recalcula usando la ecuación (3) la prioridad del proceso actual cada 4 tics (es decir, 40 ms). Al finalizar un cuanto se dispara a la rutina roundrobin que planifica al siguiente proceso de la misma cola de ejecución. Cada segundo se dispara a la rutina schedcpu que reduce el tiempo de uso de la CPU p_cpu de todos los procesos planificables mediante un factor de disminución decay=1/2 usando la ecuación (2) y recalcula la prioridad de usuario de todos los procesos planificables usando la ecuación (3).\nPor simplificar la descripción se va a suponer que la rutina del núcleo asociada al tratamiento de la interrupción de reloj, la rutina roundrobin y la rutina schedcpu se ejecutan de manera prácticamente instantánea.\nInicialmente los tres procesos se colocan al ser creados en la cola asociada al rango [88-91]En el rango de tiempo entre 0 y 100 ms se ejecuta el proceso A. Durante este tiempo la rutina de tratamiento de la interrupción de reloj recalcula la prioridad del proceso actual dos veces en 40 ms y 80 ms usando la ecuación (3). En 40 ms p_cpu(A)=4 tics, luego\np_usrpri(A)=PUSER+p_cpu(A)/4+2*p_nice(A)=50+(4/4)+(2*20)=91\nEn 80 ms p_cpu(A)=8 tics, luego p_usrpri(A)= 50+(8/4)+(2*20)=92\nEn este momento A pasa a la cola [92-95], pero se mantiene en ejecución15 hasta que acaba su cuanto de 100 ms. En ese momento p_cpu(A)=10 tics y finaliza el cuanto. Se dispara roundrobin que planifica al proceso B. Este se ejecuta en el rango entre 100 y 200 ms. La rutina de tratamiento de la interrupción de reloj recalcula la prioridad del proceso actual dos veces en 140 y 180 ms. En 140 ms p_cpu(B)=4 tics, luego\np_usrpri(B)= 50+(4/4)+(2*20)=91 En 180 ms p_cpu=8 tics, luego p_usrpri(B)= = 50+(8/4)+(2*20)=92\nEn 200 ms p_cpu(B)=10 tics y finaliza el cuanto. Se dispara roundrobin que planifica al proceso C. Este se ejecuta en el rango entre 200 y 300 ms. La rutina de tratamiento de la interrupción de reloj recalcula la prioridad del proceso actual dos veces en 240 y 280 ms. En 240 ms p_cpu(C)=4 tics, luego\n15 Nota: Si el proceso B llegase justamente en este momento (y no al principio), sería más prioritario que el proceso A y se planificaría sin esperar a que terminase el cuanto de A.p_usrpri(C)= 50+(4/4)+(2*20)=91\nEn 280 ms p_cpu=8 tics, luego\np_usrpri(C)= 50+(8/4)+(2*20)=92\nEn este momento todos los procesos se encuentran en la cola [92-95], puesto que están en la\nmisma cola se volverán a planificar en el mismo orden y este esquema de funcionamiento se iría repitiendo hasta llegar a 1s. Así se tiene que:\nEn el rango [300, 400] ms se ejecuta el proceso A. Su tiempo de CPU al finalizar el cuanto es p_cpu(A)=20 y su prioridad de usuario es p_usrpri(A)= 94 calculada con p_cpu(A)=18.\nEn el rango [400, 500] ms se ejecuta el proceso B. Su tiempo de CPU al finalizar el cuanto es p_cpu(B)=20 y su prioridad de usuario es p_usrpri(B)= 94 calculada con p_cpu(B)=18.\nEn el rango [500, 600] ms se ejecuta el proceso C. Su tiempo de CPU al finalizar el cuanto es p_cpu(C)=20 y su prioridad de usuario es p_usrpri(C)= 94 calculada con p_cpu(C)=18.\nEn esta segunda ronda ningún proceso ha cambiado de cola.\nEn el rango [600, 700] ms se ejecuta el proceso A. Su tiempo de CPU al finalizar el cuanto es p_cpu(A)=30 y su prioridad de usuario es p_usrpri(A)= 97 calculada con p_cpu(A)=28.\nEn el rango [700, 800] ms se ejecuta el proceso B. Su tiempo de CPU al finalizar el cuanto es p_cpu(B)=30 y su prioridad de usuario es p_usrpri(B)= 97 calculada con p_cpu(B)=28.\nEn el rango [800, 900] ms se ejecuta el proceso C. Su tiempo de CPU al finalizar el cuanto es p_cpu(C)=30 y su prioridad de usuario es p_usrpri(C)= 97 calculada con p_cpu(C)=28.\nTranscurrida esta ronda todos los procesos están en la cola [96-99].\nEn el rango [900, 1000] ms se ejecuta el proceso A. Su tiempo de CPU al finalizar el cuanto es p_cpu(A)=40 y su prioridad de usuario es p_usrpri(A)= 98 calculada con p_cpu(A)=38.\nAl cabo de 1 s se dispara la rutina schedcpu que disminuye el tiempo de uso de CPU de todos los procesos usando la fórmula (2)\np_cpu(A)=decay*p_cpu(A)=(1/2)*40=20\np_cpu(B)=decay*p_cpu(B)=(1/2)*30=15\np_cpu(C)=decay*p_cpu(C)=(1/2)*30=15\nAsimismo la rutina schedcpu recalcula la prioridad en modo usuario de todos los procesos usando la fórmula (3)\np_usrpri(A)= 50+(20/4)+(2*20)=95 p_usrpri(B)= 50+(15/4)+(2*20)=93 p_usrpri(C)= 50+(15/4)+(2*20)=93Tema 5: Planificación de procesos en UNIX 257\nAdemás quita a los tres procesos de la cola de ejecución [96-99] y los coloca en la cola de ejecución asociada al rango de prioridades [92-95].\nSi no aparece otro proceso más prioritario el próximo proceso en ser planificado será el proceso B.\n ## Análisis\nEl algoritmo de planificación tradicional es simple pero efectivo. Es adecuado para un sistema de tiempo compartido con una mezcla de trabajos interactivos y batch. El cálculo dinámico de las prioridades previene el abandono de cualquier proceso. Esta implementación favorece a los trabajos limitados por E/S que requieren de forma poco frecuente ciclos de CPU.\nEl planificador tiene varias limitaciones que lo hacen poco adecuado para su uso en una amplia variedad de aplicaciones comerciales:\n- No está bien escalado, si el número de procesos es muy grande resulta poco eficiente para calcular todas las prioridades cada segundo.\n- No hay forma de garantizar un determinado tiempo de uso de la CPU a un proceso o a un grupo de procesos en concreto.\n- Las aplicaciones tienen poco control sobre sus prioridades. El mecanismo del factor de amabilidad es demasiado simple y resulta inadecuado.\nPuesto que el núcleo no es expropiable, los procesos de mayor prioridad quizás tengan que esperar una cantidad de tiempo significativa incluso después de estar en el estado preparado para ejecución. A este fenómeno se le denomina inversión de prioridades.\nLos sistemas UNIX modernos son utilizados en una amplia gama de entornos. En particular, hay una fuerte necesidad para que el planificador soporte aplicaciones en tiempo real que requieren un comportamiento más predecible y tiempos de respuesta limitados. Por ello los sistemas UNIX modernos (SVR4, Solaris 2.x, etc) tuvieron que rediseñar por completo el planificador."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Planificador del SVR4",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "l planificador del SVR4 se rediseñó por completo con objeto de mejorar la planificación tradicional de UNIX. Los principales objetivos de este planificador son:- Soportar distintos tipos de aplicaciones incluyendo las aplicaciones en tiempo real. Es decir, ser lo suficiente general y versátil para tratar requerimientos de planificación distintos.\n- Separar la política de planificación de los mecanismos que la implementan.\n- Suministrar aplicaciones con un mayor control sobre sus prioridades y planificación.\n- Definir un entorno de planificación con una interfaz bien definida con el núcleo.\n- Permitir nuevas políticas de planificación que puedan ser añadidas de una forma modular, incluyendo la carga dinámica de las implementaciones del planificador.\n- Limitar el retardo de encaminamiento o distribución para aquellas aplicaciones que deben ser atendidas rápidamente.\nLa abstracción fundamental que introduce el planificador del SVR4 es la de clase de planificación, la cual define la política de planificación para todos los procesos que pertenecen a ella. El sistema puede suministrar diversas clases de planificación. Por defecto, SVR4 suministra dos clases: tiempo compartido y tiempo real.\nEl planificador dispone de un conjunto de rutinas independientes de la clase que implementan servicios comunes tales como: el cambio de contexto, manipulación de las colas de ejecución y la expropiación. También define una interfaz para funciones dependientes de la clase como las encargadas del cálculo de la prioridad y las encargadas de la herencia. Cada clase implementa estas funciones de forma diferente. Por ejemplo, la clase de tiempo real utiliza prioridades fijas, mientras que la clase de tiempo compartido varía la prioridad del proceso dinámicamente en respuesta a ciertos eventos.\nEsta aproximación orientada a objetos es similar a la utilizada en la interfaz nodo- v/sfv (ver sección 8.6). En este caso el planificador representa una clase base abstracta y cada clase de planificación actúa como una subclase.\n ## La capa independiente de la clase\nLa capa independiente de la clase es la responsable del cambio de contexto, gestión de la colas de ejecución y expropiación. El proceso con más alta prioridad siempre se ejecuta (excepto para el procesamiento del núcleo no expropiable). El número de prioridades es de 160. Hay una cola de ejecución para cada prioridad. Por defecto las 160Tema 5: Planificación de procesos en UNIX 259\nprioridades se dividen en tres rangos: 0-59 clase de tiempo compartido, 60-99 prioridades del sistema y 100-159 clase de tiempo real. A diferencia de la aproximación tradicional, los valores de prioridad más grandes numéricamente se corresponden con las prioridades más altas. La asignación y cálculo de las prioridades de los procesos son, sin embargo, realizadas por la capa dependiente de la clase.\nLa AQUÍ VA UNA IMAGEN5-3 describe las estructuras de datos para la gestión de las colas de ejecución. El mapa de bits dqactmap muestra que cola de ejecución tiene al menos un proceso listo para ejecución. Los procesos son colocados en la cola mediante setfrontdq()y setbackdq(). Son eliminados de una cola con dispdeq(). Estas funciones pueden ser invocadas desde la línea principal del código del núcleo, así como desde las rutinas dependientes de la clase. Típicamente un proceso nuevo listo para ejecución es colocado al final de una cola de ejecución, mientras que un proceso que fue expropiado antes de que su cuanto expirase es colocado al principio de la cola.\ndqactmap\n000101\ndispq\n   159\n 158\n 157\n 156\n 155\n 154\n  0\n AQUÍ VA UNA IMAGEN5-3; Colas de ejecución del planificador del SVR4\nLa principal limitación de UNIX para soportar aplicaciones de tiempo real es la naturaleza no expropiativa del núcleo. Los procesos en tiempo real necesitan tener un bajo retardo de distribución o encaminamiento, que es el retardo entre el tiempo que pasan a estar listos para ejecución y el tiempo en que realmente comienzan a ejecutarse.\nSi un proceso de tiempo real pasa a estar listo para ejecución mientras otro proceso está ejecutando una llamada al sistema, puede existir un retardo considerable antes de que se produzca el cambio de contexto.\nPPP PP\nPara solucionar este problema, el núcleo de del SVR4 define varios puntos de expropiación. Estos son lugares en el código del núcleo donde todas las estructuras de datos del núcleo están en un estado estable y el núcleo está próximo a embarcarse en una computación larga. Cuando se alcanza un punto de expropiación, el núcleo comprueba un indicador llamado kprunrun. Si este indicador esta activado significa que un proceso de tiempo real está listo para ejecutarse y el núcleo expropia la CPU al proceso actual. Esto limita la cantidad de tiempo que un proceso debe esperar antes de ser planificado. La macro PREEMPT() comprueba kprunrun y llama a la rutina preempt() para definitivamente expropiar al proceso. Algunos ejemplos de puntos de expropiación son:\nEn la rutina de búsqueda de una ruta de acceso, antes de comenzar a comprobar cada componente individual dentro de la ruta.\nEn la llamada al sistema open, antes de crear el fichero si éste no existe.\nEn el subsistema de memoria, antes de liberar las páginas de un proceso.\nEl indicador runrun es utilizado como en los sistemas tradicionales y solamente expropia a procesos que están cercanos a retornar al modo usuario. La función preempt() invoca a la operación CL_PREEMPT para realizar el procesamiento dependiente de la clase y después llama a swtch() para iniciar el cambio de contexto.\nswtch() primero llama a pswtch() para realizar la parte del cambio de contexto que es independiente de la máquina y después llama a un código de ensamblador de bajo nivel para, entre otras acciones, manipular el contexto a nivel de registro y vaciar los bufers de traducción de direcciones. pswtch() desactiva los indicadores runrun y kprunrun, selecciona el proceso listo para ejecución de mayor prioridad y lo borra de la cola de encaminamiento. Además actualiza dqactmap y establece el estado del proceso a SONPROC (ejecutándose en el procesador). Finalmente, actualiza los registros de direcciones de memoria para que apunten al área U y a los mapas de direcciones virtuales del nuevo proceso.\n ## Interfaz para las clases de planificación\nToda la funcionalidad dependiente de la clase está suministrada por una interfaz genérica cuyas funciones virtuales son implementadas de formas diferentes para cada clase de planificación. La interfaz define tanto la semántica de las funciones como las conexiones utilizadas para invocar la implementación especifica de cada clase.Tema 5: Planificación de procesos en UNIX 261\nLa AQUÍ VA UNA IMAGEN5-4 muestra cómo se implementa la interfaz dependiente de la clase. La estructura classfuncs es un vector de punteros a funciones que implementan la interfaz dependiente de la clase para cualquier clase. Una tabla global de clases contiene una entrada por cada clase. Esta entrada está compuesta por el nombre de la clase, un puntero a una función de inicialización y un puntero al vector classfuncs de cada clase.\nFunciones de inicialización\n  rt_init\n sys_init\nts_init\nTabla global de clases\np_cid p_clfuncs p_clproc ...\nDatos dependientes de la clase\nrt_classfuncs\n Tiempo real\n Sistema\n Tiempo compartido\n                  sys_classfuncs\n     ts_classfuncs\nEntradas de la tabla de procesos\n            p_cid p_cid p_cid p_clfuncs p_clfuncs p_clfuncs p_clproc p_clproc p_clproc ... ... ...\n    Datos dependientes de la clase\nDatos dependientes de la clase\nDatos dependientes de la clase\nAQUÍ VA UNA IMAGEN5-4: Interfaz dependiente de la clase del planificador del SVR4\nCuando un proceso es creado hereda la clase de prioridad de su padre. Posteriormente, puede ser movido a una clase diferente a través de la llamada al sistema priocntl, que suministra diferentes mecanismos para manipular las prioridades y el comportamiento de planificación de un proceso. Una entrada de la tabla de procesos contiene, entre otros, tres campos que son utilizados por las clases de planificación:\n- p_cid. Es un identificador de la clase que es simplemente un índice dentro de la tabla global de clases.\n- p_clfuncs. Puntero al vector classfuncs para la clase a la cual pertenece el proceso. Este puntero es copiado de la entrada de la tabla de clases.\n- p_clproc. Puntero a la estructura de datos privada dependiente de la clase.Un conjunto de macros resuelven las llamadas a las funciones de la interfaz genérica e invocan a la función correcta dependiente de la clase. Las funciones dependientes de la clase pueden ser accedidas de esta manera desde el código independiente de la clase y desde la llamada al sistema priocntl.\nLa clase de planificación decide las políticas para el cálculo de la prioridad y la planificación de los procesos que pertenecen a dicha clase. También determina el rango de prioridades para sus procesos y bajo que condiciones la prioridad del proceso puede cambiar. Asimismo decide el tamaño del cuanto de cada proceso. El cuanto puede ser el mismo para todos los proceso o variar de acuerdo a la prioridad. En general, puede estar comprendido entre un tic e infinito. Un cuanto infinito es apropiado para algunas tareas de tiempo real que deben completar su ejecución rápidamente.\nLa clase de planificación decide las acciones que cada función debe realizar y cada clase puede implementar estas funciones de forma diferente. Esto permite una aproximación muy versátil para planificar. Por ejemplo, el manipulador de la interrupción de reloj del planificador tradicional carga cada tic al proceso actual y recalcula su prioridad cada cuatro tics. En la nueva arquitectura del SVR4, el manipulador simplemente llama a la rutina CL_TIOK de la clase a la cual pertenece el proceso. Esta rutina decide cómo procesar ese tic del reloj. La clase de tiempo real, por ejemplo, utiliza prioridades fijas y no las recalcula. El código dependiente de la clase determina cuando finaliza el cuanto y activa el indicador runrun para iniciar un cambio de contexto.\n ## La clase de tiempo compartido\nLa clase de tiempo compartido es la clase por defecto para un proceso. En ella las prioridades de los procesos se cambian dinámicamente. Se utiliza un algoritmo de planificación de tipo round robin para los procesos con la misma prioridad. Además utiliza una tabla de parámetro de distribución para controlar las prioridades de los procesos y sus cuantos. El cuanto dado a un proceso depende de su prioridad de planificación. La tabla de parámetros define el cuanto para cada prioridad. Por defecto, cuanto menor es la prioridad de un proceso mayor es su cuanto. Esto puede parecer una contradicción pero su explicación es que puesto que los procesos de baja prioridad no se ejecutan muy a menudo es justo darles un cuanto mayor cuando son ejecutados.\nLa clase de tiempo compartido utiliza planificación conducida por eventos. En vez de recalcular las prioridades de los procesos cada segundo, SVR4 cambia la prioridad de un proceso en respuesta a eventos específicos relacionados al proceso. El planificadorTema 5: Planificación de procesos en UNIX 263\npenaliza al proceso (reduce su prioridad) cada vez que consume su cuanto. Por otra parte, SVR4 aumenta la prioridad de un proceso si se bloquea (a la espera de que ocurra un evento o esté disponible algún recurso) o si transcurre mucho tiempo hasta que el proceso puede usar su cuanto. Puesto que cada evento normalmente afecta a un único proceso, el recalculo de las prioridades se realiza rápidamente.\nLa clase de tiempo compartido utiliza la estructura tsproc para almacenar los datos dependientes de la clase. Algunos de sus campos son:\n- ts_timeleft. Contiene el tiempo que resta del cuanto.\n- ts_cpupri. Contiene la contribución del sistema a la prioridad del proceso.\n- ts_upri. Contiene la contribución del usuario (factor de amabilidad) a la prioridad del proceso.\n- ts_umdpri. Contiene la prioridad en modo usuario.\n- ts_dispwait. Contiene el número de segundos de la hora del reloj desde que\nempezó el cuanto.\nCuando un proceso se reanuda después de haber dormido, su prioridad es una prioridad para dormir. Cuando posteriormente retorna a modo usuario, la prioridad es restaurada al valor almacenado en ts_umdpri. La prioridad de usuario es la suma de ts_cpupri y ts_upri, pero está restringida a un valor comprendido entre 0 y 59. ts_upri varia entre -20 y 19 y su valor por defecto es 0. Este valor puede ser cambiado con la llamada al sistema priocntl, pero sólo el superusuario puede incrementarlo. ts_cpupri es ajustado de acuerdo a la tabla de parámetros de distribución.\nLa tabla de parámetros de distribución define cómo diferentes eventos cambian la prioridad de un proceso. Posee una entrada por cada prioridad perteneciente a la clase. Aunque cada clase en SVR4 tiene una tabla de parámetros de distribución, cada tabla tiene una forma diferente. Para la clase de tiempo compartido, cada entrada en la tabla contiene los siguientes campos:\n- ts_globpri. Prioridad global para esta entrada (coincide para la clase de tiempo compartido con su índice principal en la tabla).- ts_quantum. Valor del cuanto para esta prioridad.\n- ts_tqexp. Nuevo ts_cpupri a configurar cuando el cuanto expira.\n- ts_slpret. Nuevo ts_cpupri a configurar cuando se retorna a modo usuario después de dormir.\n- ts_maxwait. Número de segundos a esperar a que el cuanto expire antes de usar ts_lwait.\n- ts_lwait. Usar en vez de ts_tqexp si el proceso toma más de ts_maxwait en usar su cuanto.\nLa tabla de parámetros de distribución puede también ser indexada por el valor ts_cpupri actual para acceder a los campos ts_tqexp, ts_slpret y ts_lwait, puesto que estos campos suministran un nuevo valor de ts_cpupri basado en su viejo valor. También es indexada por ts_umdpri para acceder a ts_glopri, ts_quantum y ts_maxwait, puesto que estos campos se relacionan con la prioridad de planificación general.En la Tabla 5-1 se muestra una tabla de parámetros de distribución de tiempo compartido típica. Para ilustrar cómo se utiliza supóngase un proceso con ts_upri=14 y ts_cpupri=1. Su prioridad global (ts_globpri) y su ts_umdpri son ambas iguales a 15. Cuando su cuanto expira, su ts_cpupri será configurada a 0 (y por lo tanto se recalcula el valor de ts_umdpri que quedan configurado a 14). Si, no obstante, el proceso necesita más de 5 segundos para consumir su cuanto, su ts_cpupri es configurada a 11 (así, ts_umdpri es configurado 25).\nSupóngase, que antes de que su cuanto finalice, el proceso hace una llamada al sistema y debe bloquearse en espera de un recurso. Cuando se reanude y en algún momento vuelva a modo usuario, su ts_cpupri es configurado a 11 (a partir de la columna ts_slpret) y ts_umdpri a 25, sin importar cuánto tiempo fue necesario para usar su cuanto.\n   Índice\nts_cpupri\n   ts_ globpri\n   ts_ quantum\n   ts_ tqexp\n   ts_ slpret\n   ts_ maxwait\n   ts_ lwait\n  0\n1\n...\n15 ... 40 ...\n  0 1 ... 15 ... 40 ...\n  100 100 ... 80 ... 20 ...\n   0 0 ... 7 ... 30 ...\n 10 11 ... 25 ... 50 ...\n5 5 ... 5 ... 5 ...\n   10 11 ... 25 ... 50 ...\n       59 59 10 49 59 5 59\nTabla 5-1: Tabla de parámetros de distribución de la clase de tiempo compartido\n ## La clase de tiempo real\nLa clase de tiempo real utiliza prioridades en el rango 100-159. Estas prioridades son más altas que las de los procesos de tiempo compartido e incluso que las del núcleo, lo que significa que un proceso de tiempo real será planificado antes que cualquier proceso del núcleo. Supóngase que un proceso se está ejecutando en modo núcleo cuando un proceso de tiempo real pasa al estado listo para ejecución. El núcleo no expropia al proceso actual inmediatamente porque podría dejar al sistema en un estado inconsistente. El proceso de tiempo real debe esperar hasta que el proceso actual esté próximo a retornar a modo usuario o se alcance un punto de expropiación del núcleo. Solamente los procesos del superusuario pueden acceder a la clase de tiempo real, mediante la invocación de la llamada al sistema priocntl, especificando la prioridad y el valor del cuanto.\nLos procesos de tiempo real están caracterizados por una prioridad y cuanto fijos. La única forma en que pueden ser modificados es si el proceso invoca explícitamente a la llamada al sistema priocntl para cambiarlos. La tabla de parámetros de distribución de tiempo real es simple, únicamente almacena el valor por defecto del cuanto para cada prioridad, el cual será utilizado excepto si un proceso no especifica un cuanto mientras accede a la clase de tiempo real. Como en el caso de tiempo compartido, aquí también se asignan mayores cuantos para las prioridades más bajas. Los datos dependientes de la clase de un proceso de tiempo real están almacenados en la estructura rtproc que incluye el cuanto actual, el tiempo que resta del cuanto y la prioridad actual..\nLos procesos de tiempo real necesitan tener acotadas el retardo de distribución y el tiempo de respuesta. El retardo de distribución o encaminamiento es el tiempo que pasa desde que un proceso entra en el estado listo para ejecución hasta que comienza a ser ejecutado. Solamente es posible garantizar un valor límite para el retardo de distribución de un cierto proceso de tiempo real si dicho proceso se encuentra en el estado listo para ejecución y además posee la mayor prioridad.\nEl tiempo de respuesta es el tiempo que tarda un proceso en responder a un evento. Es la suma del tiempo requerido por el manipulador de la interrupción para procesar la\n      \ninterrupción, el retardo de distribución y el tiempo empleado en que el código del proceso de tiempo real responda al evento.\n ## Análisis\nSVR4 ha sustituido el planificador tradicional por uno completamente diferente tanto en diseño como en comportamiento. Posee una aproximación flexible que permite la adición de clases de planificación al sistema. Las tabla de parámetros de distribución dan más control al administrador del sistema, que puede modificar su comportamiento cambiando la configuración de estas tablas y recompilando el núcleo.\nEl planificador tradicional de UNIX recalcula la prioridad de cada proceso una vez por segundo. Esto puede emplear una cantidad desproporcionada de tiempo si existen muchos procesos. Por lo tanto el algoritmo no se escala bien para sistemas que tengan millares de procesos. La clase de tiempo compartido del SVR4 cambia la prioridad de un proceso basándose en eventos relacionados con el proceso. Puesto que cada evento normalmente afecta solamente afecta a un proceso, el algoritmo es rápido y altamente escalable.\nLa planificación basada en eventos favorece deliberadamente a los trabajos limitados por E/S y a los trabajos interactivos frente a los trabajos limitados por la CPU. Esta aproximación tiene algunos inconvenientes importantes. Por ejemplo, los usuarios interactivos cuyos trabajos requieran una gran computación pueden encontrase con que el sistema no responde, puesto que estos procesos pueden no generar suficientes eventos que eleven la prioridad para compensar los efectos del uso de la CPU. Por lo que puede ser necesario resintonizar las prioridades frecuentemente para conseguir que el sistema sea eficiente y receptivo.\nPara añadir una clase de planificación el programador debe seguir los siguientes pasos:\n1) Suministrar una implementación de cada función de planificación dependiente de la clase.\nInicializar un vector classfuncs para que apunte a dichas funciones. Suministrar una función de inicialización para realizar tareas de configuración como por ejemplo el alojamiento de las estructuras internas de datos.\nAñadir una entrada para esta clase en la tabla de clases en un fichero de configuración maestro, típicamente localizado en un subdirectorio\n  \nTema 5: Planificación de procesos en UNIX 267\nmaster.d del directorio de construcción del núcleo. Esta entrada contiene punteros a las funciones de inicializiación y el vector classfunctions. Reconstruir el núcleo.\nUna importante limitación del planificador de SVR4 es que no dispone de una forma adecuada de pasar un proceso de la clase de tiempo compartido a otra clase. La llamada al sistema priocntl está restringida al superusuario.\nEl principal problema con el planificador del SVR4 es que es extremadamente difícil ajustar el sistema adecuadamente para una mezcla de aplicaciones de distintos tipos. Es complicado encontrar una combinación de prioridades y asignación de clases de planificación que permita que todas las aplicaciones progresen adecuadamente.\nCon un estudio experimental adecuado, sería posible encontrar la configuración adecuada de prioridades para un conjunto de aplicaciones dado. Pero obviamente esta configuración solamente funcionaría para dicha mezcla especifica de programas. Puesto que la carga de un sistema varia constantemente se tendría que estar continuamente sintonizando manualmente el sistema, lo cual no resultaría útil."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Planificador del Solaris 2.x",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "olaris 2.x mejoró la arquitectura de planificación básica del SVR4 en varios aspectos. Solaris es un sistema multihebra, así como un sistema operativo multiprocesador simétrico. Por lo tanto su planificador puede soportar estas características. Adicionalmente, Solaris utiliza varios mecanismos de optimización del retardo de distribución de los procesos de alta prioridad que deben ejecutarse en un tiempo límite. El resultado es un planificador que es más adecuado para procesamiento en tiempo real.\nEl núcleo de Solaris 2.x es completamente expropiable, lo cual permite garantizar buenos tiempos de respuesta. Esto supone un cambio radical con respecto a las anteriores distribuciones de UNIX. Como consecuencia de esta característica la mayoría de las estructuras globales del núcleo deben ser protegidas con mecanismos de sincronización adecuados tales como cerrojos o semáforos.\nOtra consecuencia de la expropiabilidad del núcleo es la implementación de las interrupciones mediante hebras especiales del núcleo, que pueden usar primitivas de sincronización estándar del núcleo y bloquear recursos si es necesario. Como consecuencia, Solaris apenas necesita elevar el npi para proteger regiones críticas y tienesolamente unos pocos segmentos del código no expropiables. De esta forma los procesos de mayor prioridad pueden ser planificados tan pronto como acceden al estado listo para ejecución.\nSolaris mantiene un única cola de ejecución para todos los procesadores. Sin embargo, algunas hebras (como por ejemplo las hebras asociadas a las interrupciones) pueden ser restringidas a ser ejecutados en un determinado procesador. Los procesadores pueden comunicarse unos con otros usando las denominadas como interrupciones del procesador cruzadas. Cada procesador tiene el siguiente conjunto de variables de planificación en una estructura de datos por procesador:\n- cpu_thread. Hebra actualmente ejecutándose en este procesador.\n- cpu_dispthread. Última hebra seleccionada para ejecutarse en este procesador.\n- cpu_iddle. Hebra de ocio para este procesador.\n- cpu_runrun. Indicador de expropiación utilizado por las hebras de tiempo compartido.\n- cpu_krunrun. Indicador de expropiación utilizado por las hebras de tiempo real.\n- cpu_chosen_level. Prioridad de la hebra que va a expropiar a la hebra actual en\neste procesador.\nExisten ciertas situaciones donde una hebra de baja prioridad puede bloquear a una hebra de mayor prioridad durante un periodo de tiempo largo. Estas situaciones son causadas o por la planificación oculta o por la inversión de prioridad.\nEl núcleo a menudo realiza algunos trabajos asíncronamente en el nombre del proceso. El núcleo planifica este trabajo sin considerar la prioridad de la hebra para la cual está haciendo el trabajo. Ésto es lo que se conoce como planificación oculta. Un ejemplo donde se produce planificación oculta es en los callouts. UNIX sirve todos los callouts con el npi más bajo, el cual es todavía más alto que cualquier prioridad de tiempo real. Si el callout fuese dado a una hebra de baja prioridad, su servicio podría retrasar la planificación de una hebra de mayor prioridad. Para solventar este problema, Solaris trata los callouts mediante una hebra de callout que se ejecuta a la máxima prioridad del sistema, la cual es menor que cualquier prioridad de tiempo real.Tema 5: Planificación de procesos en UNIX 269\nPor otra parte, el problema de la inversión de prioridad, se refiere a la situación donde un proceso de baja prioridad retiene un recurso necesitado por un proceso de mayor prioridad, bloqueando por tanto a dicho proceso. Este problema puede ser resuelto usando una técnica conocida como traspaso de prioridad. Dicha técnica consiste en que cuando una hebra de alta prioridad se bloquea en espera de un recurso, temporalmente transfiere su prioridad a la hebra de más baja prioridad que posee el recurso, con objeto de que pueda finalizar su ejecución y liberar el recurso.\nSolaris necesita mantener un estado extra sobre los objetos bloqueados para implementar el traspaso de prioridad. Necesita identificar que hebra es la propietaria actual de cada objeto bloqueado, así como el objeto por el cual cada hebra bloqueada está esperando. Puesto que el traspaso de prioridad es temporal, el núcleo debe ser capaz de atravesar todos los objetos y hebras bloqueadas en la cadena de sincronización empezando desde cualquier objeto.\nEn resumen, Solaris 2.x suministra un entorno sofisticado para procesamiento mutihebra y en tiempo real para sistemas monoprocesador o multiprocesador. Resuelve varios inconvenientes de la implementación del planificador del SVR4. Así consigue mantener los retardos de distribución en unos niveles bajos. Esto es debido principalmente a que el núcleo de Solaris 2.x es completamente expropiable y a que implementa la técnica conocida como traspaso de prioridad"
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Resumen: ¿Qué hemos aprendido?",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "l planificador es el componente del sistema operativo que determina qué proceso debe ejecutarse en cada instante, y cede el uso de la CPU a cada proceso durante un tiempo llamado cuanto antes de planificar a otro proceso para su ejecución. En un sistema se ejecutará distintas aplicaciones de forma concurrente, que se clasifican en interactivas, aplicaciones batch, y en tiempo real. Una descripción adecuada del planificador debe centrarse en dos aspectos: la política de planificación y la implementación. La política de planificación debe intentar cumplir: dar respuesta rápida, productividad, garantizar límites para el tiempo, evitar el abandono de procesos, asegurar que las funciones del núcleo se ejecuten.\n2. Cada máquina UNIX tiene un reloj hardware que interrumpe al sistema a intervalos de tiempo. Se denomina tic al periodo de tiempo entre dos interrupciones del reloj. El tratamiento de la interrupción depende del sistema fuertemente, y debe realizar las siguientes tareas: rearmar el reloj, adaptar las estadísticas de uso de la CPU, enviar unaseñal SIGXCPU, comprobación de los callouts, despertar a los procesos del sistema, y comprobar alarmas.\nLos callouts son un mecanismo interno del núcleo que le permite invocar funciones transcurrido un cierto tiempo. Suele almacenar el nombre de la función a invocar, un argumento para dicha función y el tiempo en tics transcurrido el cual la función debe ser invocada. Se suele emplear para la invocación de tareas periódicas, como la transmisión de paquetes. Los usuarios no tienen ningún control sobre este mecanismo. El núcleo mantiene una lista de callouts, que se puede implementar de varias formas.\nEl mecanismo de aviso en el que un proceso solicita al núcleo el envío de una señal una vez transcurrido un determinado tiempo se conoce como alarma. Existen tres tipos: alarma de tiempo real, de tiempo virtual, y de perfil. Una elevada resolución de una alarma de tiempo real no implica una alta resolución, al contrario que ocurre con los otros dos tipos.\nEn este capítulo también se analizan algunas llamadas al sistema asociadas con el tiempo, como stime, que permite fijar la fecha y hora actuales. La llamada al sistema time permite leer la fecha y la hora actuales. La llamada al sistema times permite conocer el tiempo empleado por un proceso en su ejecución.\nPor otro lado, se estudia la planificación tradicional del planificador utilizado en BSD4.3, que es del tipo round robin con colas multinivel con realimentación. El planificador siempre selecciona al proceso que encontrándose en el estado preparado en memoria principal para ser ejecutado o en el estado expropiado tiene la mayor prioridad. El planificador varía dinámicamente la prioridad de los procesos basándose en su tiempo de uso de la CPU. Si un proceso de mayor prioridad alcanza el estado preparado en memoria principal para ser ejecutado, el planificador expropia el uso de la CPU al proceso actual incluso aunque éste no haya completado su cuanto.\nEl núcleo tradicional de UNIX es estrictamente no expropiable. La prioridad de planificación de un proceso es un valor entre 0 y 127. El núcleo asocia una prioridad (en modo núcleo) de dormir en función del evento por el que el proceso entró en el estado dormido. La prioridad en modo usuario depende de dos factores: el factor de amabilidad y el tiempo de uso de la CPU. En el factor de amabilidad, cuando un usuario incrementa este valor, disminuye la prioridad de sus procesos y le cede el turno de uso de CPU a otros usuarios. El factor de uso de la CPU suministra justicia y paridad en la planificación de los procesos de tiempo compartido.Tema 5: Planificación de procesos en UNIX 271\n3. Por último, se analizan los planificadores del SVR4 y del Solaris 2.x.\nLos principales objetivos del planificador del SVR4 son: soportar distintos tipos de aplicaciones, separar la política de planificación de los mecanismos que la implementan, mayor control sobre prioridades y planificación de las aplicaciones, definir un entorno de planificación con interfaz bien definida, permitir nuevas políticas de planificación añadidas de forma modular, y limitar el retardo de encaminamiento.\nLa abstracción fundamental que introduce este planificador es la de clase de planificación, la cual define la política de planificación para todos los procesos que pertenecen a ella. La capa independiente de la clase es la responsable del cambio de contexto, gestión de las colas de ejecución y expropiación.\nLa clase de planificación decide las políticas para el cálculo de la prioridad y la planificación de los procesos que pertenecen a dicha clase. También determina el rango de prioridades para sus procesos y bajo que condiciones la prioridad del proceso puede cambiar; y el tamaño del cuanto de cada proceso. La clase de tiempo compartido es la clase por defecto para un proceso, y utiliza planificación conducida por eventos. La clase de tiempo real utiliza prioridades en el rango 100-159, lo que significa que un proceso de tiempo real será planificado antes que cualquier proceso del núcleo.\n4. Solaris 2.x mejoró la arquitectura de planificación básica del SVR4 en varios aspectos. Solaris es un sistema multihebra, y multiprocesador simétrico. Adicionalmente, Solaris utiliza varios mecanismos de optimización del retardo de distribución de los procesos de alta prioridad que deben ejecutarse en un tiempo límite. El resultado es un planificador que es más adecuado para procesamiento en tiempo real. El núcleo de Solaris 2.x es completamente expropiable, lo cual permite garantizar buenos tiempos de respuesta."
}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe qué son las aplicaciones batch.",
"responses":[                         "Se trata de actividades planificadas por el usuario que típicamente se suelen realizar en segundo plano. Ejemplos de estas actividades son los compiladores, programas de cálculo científico, etc. Para este tipo de actividades, una medida de la eficiencia del planificador es la diferencia entre el tiempo que tarda en completarse estas tareas en presencia de otro tipo de actividades y el tiempo que tardan en completarse cuando son el único tipo de tareas presentes en el sistema.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué objetivos debe cumplir una política de planificación?",
"responses":[                         "- Dar una respuesta rápida a las aplicaciones interactivas.\n- Conseguir una productividad alta de los trabajos batch.\n- Garantizar unos límites para el tiempo de respuesta de las aplicaciones en tiempo real.\n- Evitar el abandono de procesos, es decir, que los procesos pasen mucho tiempo sin recibir el uso de la CPU.\n- Asegurar que las funciones del núcleo tales como, paginación, tratamiento de interrupciones y administración de procesos puedan ser ejecutadas apropiadamente cuando se necesita.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe una forma de implementar la lista de callouts.",
"responses":[                         "Existen varias formas de implementar la lista de callouts. Un método usado en BSD4.3 es ordenar la lista en función del tiempo que le resta al callout para ser invocado. A este tiempo comúnmente se le denomina tiempo de disparo. Cada entrada de la lista de callouts almacena la diferencia entre el tiempo de disparo de su callout asociado y el tiempo de disparo del callout asociado a la entrada anterior. El núcleo decrementa el tiempo de la primera entrada de la lista en cada tic de reloj y lanza el callout si el tiempo alcanza el valor 0.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe los tres tipos de alarmas.",
"responses":[                         "Alarma de tiempo real. Tiene asociado un contador o temporizador que se decrementa en tiempo real. Cuando el temporizador llega a 0 el núcleo envía al proceso una señal SIGALRM.\nAlarma de tiempo virtual. Tiene asociado un temporizador que se decrementa cuando el proceso se está ejecutando en modo usuario (tiempo virtual). Cuando el temporizador llega a 0 el núcleo envía al proceso una señal SIGVTALRM.\nAlarma de perfil. Tiene asociado un temporizador que se decrementa cuando el proceso se está ejecutando tanto en modo usuario como en modo supervisor. Cuando el temporizador llega a 0 el núcleo envía al proceso una señal SIGPROF.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué llamada al sistema es la que permite conocer el tiempo empleado por un\n                    proceso en su ejecución? Escribe su sintaxis.",
"responses":[                         "La llamada al sistema times permite conocer el tiempo empleado por un proceso en su ejecución. Su sintaxis es:\nresultado=times(&tbuffer);\nLa llamada al sistema times rellena la estructura tbuffer del tipo predefinido tms con la información estadística relativa a los tiempos de ejecución empleados por el proceso, desde su inicio hasta el momento de invocar a times.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe la llamada al sistema nice.",
"responses":[                         "La llamada al sistema nice permite aumentar o disminuir el factor de amabilidad actual del proceso que la invoca. Por lo tanto un proceso no puede modificar el factor de amabilidad de otro proceso. Su sintaxis es:\nresultado=nice(incremento);\ndonde incremento es una variable entera que puede tomar valores entre -20 y 19. El valor de incremento será sumado al valor del factor de amabilidad actual. Sólo el superusuario puede invocar a nice con valores de incremento negativos. Si se produce un error durante la ejecución de nice, entonces resultado contendrá el valor -1.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe el factor de uso de la CPU",
"responses":[                         "El factor de uso de la CPU suministra justicia y paridad en la planificación de los procesos de tiempo compartido. La idea básica es mantener la prioridad de todos estos procesos en un rango aproximadamente igual durante un periodo de tiempo.\nLos procesos subirán o bajarán dentro de un cierto rango dependiendo de cuánto tiempo de CPU hayan consumido recientemente. Si las prioridades cambian demasiado lentamente, los procesos que comenzaran con una prioridad más baja, permanecerían así durante largos periodos de tiempo, por lo que su ejecución se demorará demasiado.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cuál es el efecto del factor de disminución?",
"responses":[                         "El efecto del factor de disminución es suministrar un promedio ponderado exponencialmente de uso de la CPU a los procesos durante todo su tiempo de vida. La formula usada en el SVR3 conduce a un promedio exponencial simple, que tiene como efecto indeseable la elevación de las prioridades cuando la carga del sistema aumenta\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué reglas sigue el planificador para manipular las colas de ejecución en la\n                    aproximación BSD4.3?",
"responses":[                         "El planificador sigue las siguientes reglas para manipular las colas de ejecución:\n- El proceso de más alta prioridad siempre se ejecuta, excepto si el proceso actual se\nestá ejecutando en modo núcleo.\n- Un proceso tiene asignado un tiempo de ejecución fijo denominado cuanto (100 ms en 4.3BSD). Esto solamente afecta a la planificación de los procesos pertenecientes a la misma cola. Cada 100 milisegundos, el núcleo invoca (usando un callout) una rutina denomina roundrobin para planificar al siguiente proceso de la misma cola.\n- Si un proceso de más alta prioridad fuese puesto en el estado listo para ejecución, éste sería planificado de forma preferente sin esperar por roundrobin.- Si los procesos en el estado preparado en memoria para ser ejecutado o en el estado expropiado pertenecen a una cola de prioridad más baja que el proceso actual, éste continuará ejecutándose incluso aunque su cuanto haya expirado.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cuáles son los principales objetivos del planificador del SVR4?",
"responses":[                         "Los principales objetivos de este planificador son:\n- Soportar distintos tipos de aplicaciones incluyendo las aplicaciones en tiempo real. Es decir, ser lo suficiente general y versátil para tratar requerimientos de planificación distintos.\n- Separar la política de planificación de los mecanismos que la implementan.\n- Suministrar aplicaciones con un mayor control sobre sus prioridades y planificación.\n- Definir un entorno de planificación con una interfaz bien definida con el núcleo.\n- Permitir nuevas políticas de planificación que puedan ser añadidas de una forma modular, incluyendo la carga dinámica de las implementaciones del planificador.\n- Limitar el retardo de encaminamiento o distribución para aquellas aplicaciones que deben ser atendidas rápidamente.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué son los puntos de expropiación en el planificador del SVR4?",
"responses":[                         "Estos son lugares en el código del núcleo donde todas las estructuras de datos del núcleo están en un estado estable y el núcleo está próximo a embarcarse en una computación larga. Cuando se alcanza un punto de expropiación, el núcleo activa un indicador llamado kprunrun. Si este indicador esta activado significa que un proceso de tiempo real está listo para ejecutarse y el núcleo expropia la CPU al proceso actual. Esto limita la cantidad de tiempo que un proceso debe esperar antes de ser planificado. La macro PREEMPT() comprueba kprunrun y llama a la rutina preempt() para definitivamente expropiar al proceso. Algunos ejemplos de puntos de expropiación son:\n- En la rutina de búsqueda de una ruta de acceso, antes de comenzar a comprobar cada componente individual dentro de la ruta.- -\nEn la llamada al sistema open, antes de crear el fichero si este no existe. En el subsistema de memoria, antes de liberar las páginas de un proceso.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe la clase de tiempo compartido en SRV4",
"responses":[                         "La clase de tiempo compartido es la clase por defecto para un proceso y se corresponde con el rango de prioridad 0-59. En ella las prioridades de los procesos se cambian dinámicamente. Se utiliza un algoritmo de planificación de tipo round robin para los procesos con la misma prioridad. Además utiliza una tabla de parámetros de distribución para controlar las prioridades de los procesos y sus cuantos.\nEl cuanto dado a un proceso depende de su prioridad de planificación. La tabla de parámetros define el cuanto para cada prioridad. Por defecto, cuanto menor es la prioridad de un proceso mayor es su cuanto. Esto puede parecer una contradicción pero su explicación es que puesto que los procesos de baja prioridad no se ejecutan muy a menudo es justo darles un cuanto mayor cuando son ejecutados.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿En que mejora Solaris 2.x el tiempo de ejecución de las actividades de tiempo\n                    real?",
"responses":[                         "Solaris 2.x suministra un entorno sofisticado para procesamiento mutihebra y en tiempo real para sistemas monoprocesador o multiprocesador, esto permite un uso más rápido del los recuso.\nPor otra parte resuelve varios inconvenientes de la implementación del planificador del SVR4. Así consigue mantener los retardos de distribución en unos niveles bajos. Esto es debido principalmente a que el núcleo de Solaris 2.x es completamente expropiable y a que implementa la técnica conocida como traspaso de prioridad.\nAdicionalmente, Solaris utiliza varios mecanismos de optimización del retardo de distribución de los procesos de alta prioridad que deben ejecutarse en un tiempo límite. El resultado es un planificador que es más adecuado para procesamiento en tiempo real.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "COMUNICACIÓN Y SINCRONIZACIÓN DE PROCESOS EN UNIX",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "- Conocimiento de los servicios IPC (interprocess comunication) universales: señales y tuberías, y seguimiento de procesos.\n- Conocimiento de los mecanismos IPC del System V: semáforos, colas de mensajes y memoria compartida.\n- Conocimiento de los principales mecanismos de sincronización tradicionales.\n- Descripción del seguimiento de procesos.\n- Conocimiento de los mecanismos de sincronización modernos de UNIX.\nUNIX es un sistema operativo multiproceso, es decir, varios procesos pueden estar ejecutándose en el núcleo de UNIX al mismo tiempo. En un sistema con un único procesador solamente un proceso puede estar ejecutándose en la CPU. El sistema rápidamente conmuta de un proceso a otro, generando la ilusión de que todos ellos se ejecutan concurrentemente.\nLos procesos deben comunicarse y sincronizarse entre sí para conseguir distintos objetivos:\n- Transferencia de datos. Un proceso puede necesitar transferir datos a otro proceso. La cantidad de datos puede variar desde un byte hasta varios megabytes.\n- Compartir datos. Múltiples procesos pueden necesitar operar sobre datos compartidos, de tal forma que si un proceso modifica estos datos, los cambios realizados deben ser visibles para el resto de procesos que comparten dichos datos.\n- Notificación de eventos. Un proceso puede notificar a otro proceso o a un conjunto de procesos que se ha producido algún evento. Por ejemplo, cuando un proceso termina,-\npuede necesitar informar de este hecho a su proceso padre. El receptor puede ser notificado asíncronamente, en cuyo caso su procesamiento normal se verá interrumpido. Alternativamente, el receptor quizás desee esperar por la notificación del evento.\nCompartir recursos. Aunque el núcleo suministra sus propias semánticas para la asignación de recursos, éstas pueden no ser adecuadas para todas las aplicaciones. Un conjunto de procesos puede desear definir su propio protocolo de acceso a ciertos recursos. Tales reglas se implementan normalmente mediante un esquema de sincronización y bloqueo.\nControl de procesos. Un proceso (controlador), por ejemplo un depurador, necesita disponer de un control total sobre la ejecución de otro proceso (objetivo). El proceso controlador puede interceptar todas las interrupciones software y excepciones generadas por el proceso objetivo.\nEn consecuencia, el núcleo debe disponer de mecanismos adecuados que implementen la comunicación y sincronización de los procesos.\nEn este capítulo en primer lugar se describen dos mecanismos de comunicación universales disponibles en todas las versiones de UNIX: las señales y las tuberías. En segundo lugar se describen los mecanismos colectivamente denominados como mecanismos IPC (InterProcess Comunication) del System V, es decir, los semáforos, las colas de mensajes y la memoria compartida. En tercer lugar se analizan los mecanismos de sincronización en las distribuciones de UNIX clásicas. El cuarto apartado está dedicado al seguimiento de procesos, otro mecanismo de comunicación universal. Por último se describen los mecanismos de sincronización en las distribuciones modernas de UNIX."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Servicios IPC universales",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "Las primeras distribuciones de UNIX únicamente disponían de tres mecanismos que podían ser utilizados para la comunicación entre procesos: las señales, las tuberías y el seguimiento de procesos (ver apartado 6.6)\n ## Señales\nLas señales se utilizan principalmente para notificar a un proceso eventos asíncronos. Originariamente fueron concebidas para el tratamiento de errores, aunque también pueden ser utilizadas como mecanismo IPC. Las versiones modernas de UNIXreconocen 32 señales diferentes (45 en el caso de Solaris). La mayoría tienen un significado predefinido, pero existen dos, SIGUSR1 y SIGUSR2, que pueden ser utilizadas por los usuarios según sus necesidades. Un proceso puede enviar una señal a un proceso o a un grupo de procesos usando por ejemplo la llamada al sistema kill. Además el núcleo genera señales internamente en respuesta de distintos eventos.\nComo mecanismo IPC, las señales poseen varias limitaciones:\n- Las señales resultan costosas en relación a las tareas que suponen para el sistema. El proceso que envía la señal debe realizar una llamada al sistema; el núcleo debe interrumpir al proceso receptor y manipular la pila de usuario de dicho proceso, para invocar al manipulador de la señal y posteriormente poder retomar la ejecución del proceso interrumpido.\n- Tienen un ancho de banda limitado, ya que solamente existen 32 tipos de señales distintas.\n- Una señal puede transportar una cantidad limitada de información.\nEn conclusión, las señales son útiles para la notificación de eventos, pero resultan\npoco útiles como mecanismo IPC.\n ## Tuberías\nEn su implementación tradicional, una tubería es un mecanismo de comunicación unidireccional, que permite la transmisión de un flujo de datos no estructurados. Unos procesos (emisores) pueden escribir datos en un extremo de la tubería y otros procesos (receptores) pueden leer estos datos en el otro extremo (ver AQUÍ VA UNA IMAGEN6-1). Si bien debe quedar claro que en un cierto instante de tiempo solamente un proceso estará usando la tubería, bien para escribir o bien para leer. Una vez que los datos son leídos por un proceso, estos son borrados de la tubería y en consecuencia ya no pueden ser leídos por otros procesos.P P\nP\nDatos\nP\nP\n       AQUÍ VA UNA IMAGEN6-1: Datos fluyendo a través de una tubería\nLas tuberías proporcionan un mecanismo de control del flujo de datos bastante simple. Un proceso intentando leer de una tubería vacía se bloqueará hasta que se escriban datos en la tubería. Asimismo, un proceso intentando escribir en una tubería llena se bloqueará hasta que otro proceso lea (y entonces se borren) los datos de la tubería.\nExisten dos tipos de tuberías, las tuberías sin nombre (llamadas simplemente tuberías) y las tuberías con nombre o ficheros FIFO."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Tuberías sin nombre",
"properties":
{
"type": "code",
"content": "",
"code_url": "ejemplo_6.3.2"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Mecanismos IPC del System V ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Consideraciones generales\nLos mecanismos IPC descritos en la sección anterior no satisfacían las necesidades de muchas aplicaciones. Un gran avance llegó con el UNIX System V, que suministraba tres nuevos mecanismos: semáforos, colas de mensajes y memoria compartida, que se conocen de forma colectiva como mecanismos IPC del System V. Posteriormente estos mecanismos fueron implementados por la mayoría de las distribuciones de UNIX, incluso las BSD.\nPara entender adecuadamente la nomenclatura usada en relación con los mecanismos IPC se definen los siguientes conceptos:\nUn mecanismo IPC: Es cada una de las formas posibles de comunicación, esto es, semáforos, colas de mensajes y memoria compartida. Existe una tabla en el núcleo por cada mecanismo IPC.\nSe denomina recurso a cada realización concreta de dicho mecanismo (por ejemplo el vector de semáforos número 7). Cada recurso tiene una entrada en la tabla asociada al mecanismo al que pertenece (en el ejemplo anterior el semáforo estaría indexado con índice It=7 en la tabla de semáforos). Por último se conoce como instancia a cada utilización del recurso por un determinado proceso. Cada proceso se refiere al mismo recurso mediante un identificador numérico distinto Nipc. (Por ejemplo, si los procesos P1 y P2 acceden al mismo semáforo It=7 cada uno de ellos lo hará usando un Nipc distinto.)\nA continuación se describen en detalle las características de cada uno de los mecanismos.\n ###  Características comunes de los mecanismos IPC del System V\nLos mecanismos IPC del System V están implementados en el sistema como una unidad y comparten características comunes, entre las que se encuentran:\n1) Cada tipo de mecanismo IPC tiene asignada una entrada en una tabla en el espacio de memoria del núcleo. Por lo tanto en el núcleo existen tres tablas relacionadas con los mecanismos IPC: una para semáforos, otra para mensajes y una tercera para la memoria compartida.\nCada tabla asignada a un tipo de mecanismo IPC posee un número de entradas configurable. Cada entrada contiene información relativa a un recurso de dicho mecanismo IPC o canal IPC.\nCada entrada de la tabla tiene asignada una llave numérica, que permite controlar el acceso a dicha instancia del mecanismo IPC.\nCada entrada de la tabla asociada a un tipo de mecanismo IPC tiene asignado un índice IT para su localización dentro de la tabla.\nCada entrada de la tabla asociada a un tipo de mecanismo IPC tiene almacenada una estructura ipc_perm que presenta la siguiente definición:\n- Identificador de usuario del proceso propietario del recurso.\n- Identificador de grupo del proceso propietario del recurso.\n- Identificador de usuario del proceso creador del recurso.\n- Identificador de grupo del proceso creador del recurso.\n- Modo de acceso (permisos de lectura, escritura y ejecución para el usuario, el grupo y otros usuarios).\n- Número de secuencia. Es un contador que mantiene el núcleo y que se incrementa siempre que se cierra una instancia o canal de un mecanismo IPC. Este contador es necesario para identificar los canales abiertos e impedir que mediante una elección aleatoria del identificador de canal, un proceso pueda adquirirlo.\n- Llave de acceso.\nCada entrada de la tabla asociada a un tipo de mecanismo IPC, además de la estructura ipc_perm, tiene almacenada también otras informaciones\n     Structm ipc_perm\n    ushort uid;\n    ushort gid;\n    ushort cuid;\n    ushort cgid;\n    ushort mode;\n ushort seq;\nkey_t key; \n \ncomo por ejemplo el pid del último proceso que ha utilizado la entrada y la fecha de la última actualización o acceso.\nCada instancia de un recurso IPC tiene asignado un descriptor numérico NIPC elegido por el núcleo, que la referencia de forma única y que será utilizado para localizar la instancia rápidamente cuando se realicen operaciones sobre ella. Recordemos que NIPC es único para cada proceso. Cada tipo de mecanismo IPC dispone de una llamada al sistema tipo get [shmget (memoria compartida), semget (semáforos) y msgget (colas de mensajes)] que permite crear una nueva instancia de un determinado tipo de mecanismo IPC o acceder a alguna ya existente.\nCada tipo de mecanismo IPC dispone de una llamada al sistema tipo ctl [shmctl (memoria compartida), semctl (semáforos) y msgctl (colas de mensajes)] que permite acceder a la información administrativa y de control de una instancia de un mecanismo IPC.\n ###  Asignación de un índice IT a una instancia NIPC\nEl núcleo calcula el descriptor numérico NIPC que asigna a una instancia de un mecanismo IPC usando la siguiente fórmul:\n  NIPC seq*NT IT\n(1)\ndonde seq es el número de secuencia de la instancia, NT es el tamaño de la tabla asociada al mecanismo IPC, e IT es el índice de la instancia en la tabla. Esto asegura que un nuevo NIPC es generado si una entrada de la tabla de un cierto mecanismo IPC es reutilizada, puesto que seq es incrementado en una unidad. Asimismo se evita que los procesos accedan a una instancia usando un descriptor viejo.\nEl usuario pasa el NIPC como un argumento de las siguientes llamadas al sistema asociadas con la instancia del mecanismo IPC. El núcleo traduce el NIPC a la posición de la instancia en la tabla usando la fórmula:\nIT NIPCmod(NT)NIPC%NT(2)\n La tabla asociada a un determinado tipo de mecanismo IPC posee NT=100 entradas. Calcular IT en los siguientes casos: a) NIPC=5. b)NIPC=30. c) NIPC=101. d) NIPC=303.Aplicando la fórmula (2) se obtiene:\nIT= 5 mod (100) = 5 % 100 = 5 IT= 30 mod (100) = 30 % 100 = IT= 101 mod (100) = 101 % 100 IT= 303 mod (100) = 303 % 10030 = 1 = 3\n La tabla asociada a un determinado tipo de mecanismo IPC posee NT=100 entradas. Calcular los descriptores posibles NIPC de la entrada IT =1 si el número de secuencia puede tomar como máximo el valor 3.\nLos posibles valores NIPC de la entrada IT =1 se obtendrán usando la fórmula (1) para los valores seq=0, 1, 2 y 3.\nseq=0\nseq=1\nseq=2\nseq=3\nSupóngase que el descriptor asociado a una instancia de un mecanismo IPC es NIPC=201. En un\ndeterminado instante dicha instancia es eliminada de la tabla. Cuando se vuelva a utilizar dicha entrada de la tabla, es decir, cuando se cree otra nueva instancia de un mecanismo IPC, el núcleo le asignara NIPC=301. Aquellos procesos que intenten acceder con NIPC=201 recibirán una señal de error ya que no es una entrada válida. Los descriptores NIPC son reciclados por el núcleo transcurrido un cierto intervalo de tiempo."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Creación de llaves",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "ejemplo_6-4-1"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Mecanismos IPC del System V 2",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,     "content": "###  Algunos comentarios sobre las llamadas al sistema tipo get\nUn proceso adquiere una instancia de un mecanismo IPC haciendo una llamada al sistema del tipo get, pasándole una llave, ciertos indicadores y otros argumentos que dependen de cada mecanismo. Los indicadores permitidos son IPC_CREAT y IPC_EXCL. Su significado es el siguiente:\nIPC_CREAT pide al núcleo que cree la instancia si ésta no existe ya.\nIPC_EXCL es utilizado junto con IPC_CREAT y pide al núcleo que devuelva un error si la instancia ya existía.\nSi no se especifica ningún indicador, el núcleo busca una instancia ya existente con la misma llave. Si la encuentra y el proceso invocador tiene permiso de acceso, el núcleo devuelve el descriptor numérico NIPC de la instancia. En caso contrario devuelve el valor - 1.\nSi la llave toma el valor especial IPC_PRIVATE, el núcleo crea una nueva instancia. En este caso la instancia no podrá ser accedida a través de posteriores llamadas tipo get. Por lo tanto el proceso que invoca a la llamada al sistema con este argumento tiene propiedad exclusiva sobre la instancia. Eso sí, el propietario puede compartir el recurso con sus hijos, que lo heredan cuando se realiza la llamada al sistema fork.\n ###  Algunos comentarios sobre las llamadas al sistema tipo ctl\nTodos los tipos de mecanismos IPC poseen una llamada al sistema de control del tipo ctl que implementa diversos comandos. Estos comandos incluyen IPC_STAT y IPC_SET para obtener y configurar información del estado de un recurso e IPC_RMID para eliminar un recurso. Los semáforos disponen de comandos adicionales para obtener y configurar los valores de un determinado semáforo perteneciente a un cierto conjunto.\nCada recurso IPC debe ser explícitamente eliminado mediante el uso del comando IPC_RMID. En caso contrario, el núcleo considera que se encuentra activo incluso aunque todos los procesos que lo estaban utilizando hayan terminado. Por lo tanto, un recurso IPC puede perdurar y ser utilizado más allá del tiempo de vida de los procesos que lo han estado utilizando. Esta propiedad puede ser bastante útil. Por ejemplo, un proceso puede escribir datos en una región de memoria compartida o un mensaje en una cola y después finalizar. Más tarde, otro proceso puede recuperar estos datos.\nÚnicamente el creador, el propietario actual o el superusuario pueden usar el comando IPC_RMID. La eliminación de un recurso afecta a todos los procesos que actualmente acceden a él y el núcleo debe asegurarse de que todos estos procesos tratan este evento adecuadamente.\nUna forma de controlar desde la línea de órdenes los mecanismos IPC abiertos es la orden ipcs. En caso de querer cerrar un recurso IPC que haya quedado abierto por error puede usarse la orden ipcrm."
}
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Semáforos",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "ejemplo_6-4-2-1"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Mecanismos IPC del System V 3",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,           "content": "###  Realización de operaciones con los elementos de un conjunto de semáforos\nLa llamada al sistema semop es utilizada para realizar operaciones sobre los elementos de un determinado conjunto de semáforos. Su sintaxis es:\nresultado=semop(semid, sops, nsops);\ndonde semid es un identificador de un array o conjunto concreto de semáforos, sops es un puntero a un array de estructuras del tipo sembuf que indican las operaciones que se van a llevar a cabo sobre los semáforos y nsops es el número total de elementos que tiene el array de operaciones, es decir, el número total de operaciones.\nEn general, el núcleo lee el array de operaciones sops del espacio de direcciones del usuario y verifica que los números de los semáforos son legales y que el proceso tiene los permisos necesarios para leer o cambiar los valores de los semáforos. Si no cuenta con los permisos adecuados la llamada semop falla y en resultado se almacena el valor -1.\nLa definición de la estructura del tipo sembuf utilizada es: struct sembuf\nunsigned short sem_num;\nshort sem_op;\n    short sem_flg;\nEl significado de cada uno de los elementos de una estructura sembuf es el siguiente:\n- sem_num identifica a uno de los semáforos del conjunto semid. Su valor está comprendido entre 0 y N-1, donde N es el número total de semáforos en el conjunto.\n- sem_op especifica la acción a realizar en el semáforo elegido. Los valores de sem_op se interpretan de la siguiente manera:\n- sem_op > 0. Añadir sem_op al valor actual del semáforo. Los procesos que estaban durmiendo en espera de que el valor fuese incrementado serán despertados.- sem_op = 0. Bloquear el proceso hasta que el valor del semáforo sea cero.\n- sem_op < 0. Bloquear el proceso hasta que el valor del semáforo sea mayor o igual que el valor absoluto de sem_op, a continuación restar sem_op de dicho valor. Si el valor del semáforo ya es superior al valor absoluto de sem_op, el proceso que invoca esta llamada al sistema no se bloqueará.\n- sem_flg, permite suministrar dos indicadores a la llamada. El indicador IPC_NOWAIT pide al núcleo que devuelva un error en vez de bloquear al proceso. Asimismo, puede ocurrir un interbloqueo si un proceso que retiene un semáforo termina prematuramente sin liberarlo. Otros procesos esperando para adquirir dicho semáforo pueden quedar para siempre bloqueados. Para evitar este problema, es posible pasar a semop el indicador SEM_UNDO para que el núcleo recuerde la operación y automáticamente la deshaga si el proceso termina.Las siguientes líneas de código C muestran cómo realizar emular una operación wait_sem() y signal_sem() sobre los semáforos 2 y 4 respectivamente del conjunto de semáforos semid que agrupa un total de 5 semáforos.\nstruct sembuf operaciones[5];\n...\noperaciones[0].sem_num=2; /*Semáforo número 2*/ operaciones[0].sem_op=-1; /*Operación que emula P*/ operaciones[0].sem_flg=0;\noperaciones[1].sem_num=4; /*Semáforo número 4*/ operaciones[1].sem_op=1; /*Operación que emula a V*/ operaciones[1].sem_flg=0;\nsemop(semid,operaciones,2);\n...\nEn realidad el funcinamiento externo es similar a las operaciones P() y V() del semáforo clásico,pero su implementación interna es distinta. Una operación P() clásica sobre un semáforo a cero pondría el semáforo en un valor -1 bloqueando el proceso que lo invoque (que llamaremos A). Cuando otro proceso B hiciese una operación V() el semáforo se pondría a cero y se desbloquería el proceso A. Con las operaciones sem_op=-1 y sem_op=1 ocurre algo ligeramente distinto. Si el proceso A realiza la operación sem_op=-1 el proceso A se bloquea a la espera de que el semáforo valga 1 sin modificar el valor del semáforo (semval=0). Cuando el proceso B haga una operación sem_op=1 el semáforo se pone a 1 (semval=1), esto hará que se despierte el proceso A. Una vez que se despierte restará 1 alsemáforo que quedará a cero. En ambos casos se bloquea el proceso A hasta que lo desbloquea el proceso B y el semáformo queda como al principio.\nFinalmente es interesante comentar que el núcleo mantiene una lista para cada proceso que ha solicitado una operación sobre un semáforo con el indicador SEM_UNDO. Esta lista contiene un registro por cada operación que debe ser deshecha. Cuando un proceso termina, el núcleo chequea si tiene una lista de estas características, si la tiene el núcleo recorre la lista deshaciendo todas las operaciones realizadas con anterioridad."
}
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Acceso a la información administrativa y de control de un conjunto de semáforos",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "ejemplo_6-4-2-1"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Colas de mensajes 1",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null, "content": "## \nUna cola de mensajes es una estructura de datos gestionada por el núcleo, en ella van a poder escribir varios procesos. Los mecanismos de sincronización para que no se\nwait_sem(semid) ;produzcan colisiones en el uso de la cola de mensajes son responsabilidad del núcleo. Los datos que se escriben en la cola deben tener formato de mensaje y son tratados como un todo indivisible, es decir, el proceso extrae o coloca la información en una única operación.\nEl mecanismo de comunicación de las colas de mensajes corresponde a la implementación del concepto de buzón, que permite la comunicación indirecta entre procesos. Un proceso tiene la posibilidad de depositar mensajes o extraerlos del buzón. Cada mensaje esta tipificado y cada proceso extraerá de una cola de mensajes aquellos que quiera extraer.\nEn la implementación del UNIX System V todos los mensajes son almacenados en el espacio del núcleo y tienen asociado un identificador de cola de mensaje, denominado msqid. Los procesos pueden leer y escribir mensajes de cualquier cola."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Estructuras de datos asociadas a los mensajes",
"properties":
{
"type": "code",
"content": "",
"code_url": "ejemplo_6-4-3-1"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Creación u obtención de una cola de mensajes",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "ejemplo_6-4-3-2"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Colas de mensajes 2",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": " ###  Envío de mensajes\nLa llamada al sistema msgsnd permite a un proceso enviar un mensaje desde su espacio de direcciones a una determinada cola de mensajes. Su sintaxis es:\nresultado=msgsnd(msqid,&buffer,msgsz,msgflags);\nDonde msqid es un identificador de una cola de mensajes, buffer es una estructura\nque contiene el tipo del mensaje y el texto, como por ejempl:\n    struct {long msg_type;\n     char msg_sopt[100];\n     } buffer;\nPor otra parte, msgsz es la longitud del texto del mensaje en bytes (esto es, la longitud de la estructura excluyendo su tipo) y msgflags es una máscara de indicadores que permite especificar el comportamiento del proceso emisor en caso de que no pueda enviarse el mensaje debido a una saturación del mecanismo de colas. Si la llamada al sistema tiene éxito en resultado se almacenará el valor 0, si falla se almacenará el valor -1.\nNótese que aunque se hable de “texto del mensaje” la estructura del mensaje puede ser cualquiera, UNIX sólo interpreta el tipo del mensaje y transmite el resto como bytes sin interpretar, es tarea del receptor saber el tipo de estructura que está recibiendo.Por defecto la llamada al sistema msgsnd es bloqueante, es decir, el proceso que la invoca pasará al estado dormido interrumpible por señales si no se puede escribir en la cola de mensajes y se le despertará cuando se pueda escribir. También se le despertaría si la cola de mensajes fuese borrada, o recibiese una señal que no ignora. Es posible hacer que esta llamada sea no bloqueante; para ello, hay que colocar el indicador IPC_NOWAIT en la máscara msgflags de msgsnd. En dicho caso si no se puede escribir en la cola la llamada devolverá el valor –1 y asignará a la variable errno el valor EAGAIN.\nCuando se realiza la llamada al sistema msgsnd el núcleo realiza la siguiente secuencia de acciones:\nComprueba que el proceso emisor tiene permiso de escritura para la cola msqid.\nComprueba que la longitud del mensaje no excede los límites del sistema y que no contiene demasiados bytes.\nComprueba que el tipo de mensaje es un entero positivo.\nSi todos las comprobaciones anteriores son superadas con éxito, asigna espacio para el mensaje en el área de datos del núcleo y copia los datos desde el espacio de direcciones del usuario al espacio de direcciones del núcleo.\nAsigna una cabecera de mensaje y la coloca al final de la lista enlazada de cabeceras de mensajes de la cola de mensajes msqid.\nSalva el tipo de mensaje y su tamaño en la cabecera del mensaje. ConAQUÍ VA UNA IMAGENla cabecera del mensaje para que apunte al texto de mensaje en el área de datos del núcleo.\nActualiza varios campos de tipo estadístico en la entrada de la tabla de colas asignada a la cola msqid.\nEl núcleo despierta a los procesos que estaban dormidos esperando por la llegada de un mensaje en dicha cola.\nSi el número de bytes en la cola excede el límite de la cola, el proceso emisor dormirá hasta que otros mensajes sean eliminados de la cola.\nSi el proceso estableció en su llamada a msgsnd (indicador IPC_NOWAIT del campo msgflag) que no desea esperar, entonces la llamada devolverá el valor –1."
}
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Recepción de mensajes",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},          "content": "",
"code_url": "ejemplo_6-4-3-3"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Colas de mensajes 3",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "###  Acceso a la información administrativa y de control de una cola de mensajes\nLa llamada al sistema msgctl permite leer y modificar la información estadística y de control de una cola de mensajes, su declaración es:\nresultado=msgctl(msqid, cmd, &buffer);\ndonde msqid es el identificador de la cola, cmd es un número entero o una constante simbólica que especifica la operación a efectuar y buffer es una estructura del tipo predefinido msqid_ds que contiene los argumentos de la operación. Si la llamada msgctl tiene éxito, en resultado se almacenará un número entero cuyo valor depende del comando cmd. Si falla en resultado se almacenará el valor –1.\nLas operaciones que se pueden especificar con el argumento cmd de msgctl son:\n{}- IPC_RMID. Borra del sistema la cola de mensajes identificada por msqid. Si la cola está siendo usada por otros procesos, la eliminación de la cola no se hace efectiva hasta que todos los procesos terminan de utilizarla.\n- IPC_STAT. Lee el estado de la estructura msg_perm asociada a la entrada msqid de la tabla de colas y lo almacena en buffer.\n- IPC_SET. Modifica el valor de los campos de la estructura msg_perm asociada a la entrada msqid de la tabla de colas. Los nuevos valores para estos campos los toma de buffer.\nEn la estructura msg_perm los campos modificables por el usuario son: msg_perm.uid, msg_perm.gid y msg_perm.mode. Mientras que, el superusuario puede además modificar el campo msg_perm.qbytes de la estructura msquid_ds. Los demás campos o no son modificables o son manipulados por el sistema directamente.\n ###  Discusión\nLas colas de mensajes suministran servicios similares a las tuberías. Sin embargo las colas de mensajes son más versátiles y no poseen las limitaciones de las tuberías. Las colas de mensajes transmiten datos como mensajes discretos, a diferencia de las tuberías que transmiten datos como un fllujo de bytes sin formato. Esto permite un mejor procesamiento de los datos. El campo tipo de mensaje de los mensajes permite asociar prioridades a los mensajes, lo que posibilita a un proceso receptor el poder comprobar antes los mensajes más urgentes. Asimismo en escenarios donde una cola de mensajes es compartida por múltiples procesos, el campo tipo de mensaje puede ser utilizado para designar un receptor.\nLas colas de mensajes son útiles para transferir pequeñas cantidades de datos. Sin embargo si hay que transferir grandes cantidades de datos el rendimiento del sistema se deteriora. Esto es debido a que la transferencia de un mensaje requiere de dos operaciones de copia de datos en memoria: la primera del espacio de direcciones del proceso emisor a un buffer interno del núcleo y la segunda de dicho buffer al espacio de direcciones del proceso receptor.\nOtra limitación de las colas de mensajes es que no pueden especificar un determinado receptor. Cualquier proceso con los permisos apropiados puede recuperar mensajes de la cola. Aunque, como se mencionó con anterioridad, procesos cooperantespueden acordar un protocolo para especificar receptores. Finalmente, otra limitación de las colas de mensajes es que no suministran un mecanismo de difusión, es decir, un proceso no puede enviar un único mensaje a varios receptores.\nDebido a las limitaciones de las colas de mensajes, la mayoría de las aplicaciones de los sistemas UNIX más modernos encuentran en el uso de los streams un mecanismo más potente para implementar el paso de mensajes.\n ## Memoria Compartida\nLa forma más rápida de comunicar dos procesos es hacer que compartan una zona de memoria. Para enviar datos de un proceso a otro, el proceso emisor solamente tiene que escribir en memoria y automáticamente esos datos estarán disponibles para que los lea otro proceso.\nEs conocido que la memoria convencional que puede direccionar un proceso a través de su espacio de direcciones virtuales es un espacio local a dicho proceso y cualquier intento de direccionar esa memoria desde otro proceso va a provocar una violación de segmento.\nEl sistema UNIX System V soluciona este problema permitiendo crear regiones de memoria virtual que pueden ser direccionadas por varios procesos simultáneamente.\n ###  Estructuras de datos utilizadas para compartir memoria\nEl núcleo posee una tabla de memoria compartida, cada entrada en dicha tabla está asignada a una región de memoria compartida que viene identificada por un descriptor numérico shmid. Además, cada entrada contiene una estructura del tipo shmid_ds, que se define de la siguiente forma:\nEstructura que mantiene los permisos Tamaño del segmento\nPid del proceso que realizó la última operación sobre la región de memoria compartida\nPid del proceso creador\nNúmero de procesos unidos a la región de memoria compartida\n struct shmid_ds{struct ipc_perm shm_perm;\nint shm_segsz;\nushort shm_lpid;\nushort shm_cpid;\nushort shm_nattch; time_t shm_atime;\ntime_t shm_dtime;\ntime_t shm_ctime;\nUnsigned long *shm_pages;\n};\nFecha de la última conexión\nFecha de la última desconexión Fecha de la última operación shmctl Puntero a la tabla de regiones\n ###  Creación u obtención de una región de memoria compartida\nPara crear un segmento de memoria compartida o acceder a uno que ya existe, se utiliza la llamada al sistema shmget, cuya sintaxis es:\nshmid=shmget(key,size,flags);\ndonde key es la clave de acceso a un segmento de memoria compartida, size especifica el tamaño en bytes del segmento de memoria solicitado y flags es una máscara de indicadores (similar a la descrita para los semáforos). Si la llamada al sistema shmget se ejecuta con éxito entonces en shmid se almacenará el identificador entero de la zona de memoria compartida asociada a la llave key. En caso contrario en shmid se almacenará el valor -1.\nEl identificador devuelto por shmget es heredado por los procesos descendientes del actual. Por otra parte, cuando un proceso realiza la llamada al sistema shmget el núcleo realiza las siguientes acciones:\n- Busca en la tabla de memoria compartida la región asociada con el parámetro key, si encuentra dicha región y el proceso tiene los permisos de acceso correctos entonces devuelve el descriptor shmid.\n- Si no encuentra la región asociada con el parámetro key y el usuario ha configurado el indicador IPC_CREAT de flags para crear una nueva región entonces:\no Compruebaqueeltamañoespecificadosizeseencuentraentrelos límites mínimo y máximo permitidos\no Asignaunaregiónmedianteelusodelalgoritmoallocreg().o Salvalospermisos,tamañoyunpunteroalatabladeregionesdentro de la estructura shmid_ds asociada a la entrada shmid de la tabla de memoria compartida.\no Activaunbitenlaentradadelatabladeregionesasignadaalaregión de memoria compartida shmid para identificarla como una región de memoria compartida.\no Tambiénenlaentradadelatabladeregionesasignadaalaregiónde memoria compartida shmid el núcleo activa un bit para indicar que dicha región no debe ser liberada cuando el último proceso que la comparta termine. Por lo tanto, los datos en una región de memoria compartida permanecerán intactos incluso aunque ningún proceso comparta ya dicha región.Las siguientes líneas de código C muestran cómo crear una zona de memoria compartida de tamaño 4096 bytes, sólo el usuario va a tener permisos de lectura y escritura.\n#include <sys/types.h> #include <sys/ipc.h> #include <sys/shm.h> ...\nint shmid;\n...\nshmid=shmget(IPC_PRIVATE,4096,IPC_CREAT | 0600);\nif (shmid==-1)\n{/* Error en la creación de la memoria compartida.\nTratamiento del error.*/ \n ###  Ligar una región de memoria compartida al espacio de direcciones virtuales de un proceso\nAntes de que un proceso pueda usar la región de memoria compartida shmid, es necesario asignarle un espacio de direcciones virtuales de dicho proceso. Esto es lo que se conoce como unirse o enlazarse al segmento de memoria compartida.La llamada shmat asigna un espacio de direcciones virtuales al segmento de memoria cuyo identificador shmid ha sido dado por shmget. Por lo tanto shmat enlaza una región de memoria compartida de la tabla de regiones con el espacio de direcciones de un proceso.\nLa llamada al sistema shmat tiene la siguiente sintaxis:\nresultado=shmat(shmid,shmdir,shmflags);\ndonde shmid es un identificador de una región de memoria compartida, shmdir es la dirección virtual del proceso donde se desea que empiece la región de memoria compartida, shmflags, es una máscara de bits que indica la forma de acceso a la memoria. Si el bit SHM_RDONLY está activo, la memoria será accesible para leer, pero no para escribir. Por defecto un segmento de memoria se comparte para lectura y escritura. Si la llamada al sistema shmat tiene éxito en resultado se almacena la dirección a la que está unido el segmento de memoria compartida shmid. En caso contrario en resultado se almacena el valor -1.En la AQUÍ VA UNA IMAGEN6-4(a) se muestran las estructuras de datos del núcleo utilizadas en la implementación del mecanismo IPC de memoria compartida. Se observa que la tabla de memoria compartida tiene dos entradas activas (IT=0 e IT=1). La primera entrada (IT=0) contiene información de una región de memoria compartida cuyo descriptor numérico es shmid=0, mientras que la segunda entrada (IT=1) contiene información de una región de memoria compartida cuyo descriptor numérico es shmid=1. Entre otras informaciones (estructura shmid_ds) estas entradas contienen un puntero a la tabla de regiones del núcleo.\n Tabla de regiones por proceso (A)\n  Código\n      Datos\n    Pila de usuario\n      Tabla de regiones por proceso (A)\nIT=0\nshmid=0\nIT=0\nshmid=1\nTabla de regiones\nTabla de memoria compartida\nIT=0\nshmid=0\nIT=0\nshmid=1\n     (a)\nTabla de regiones\nTabla de memoria compartida\n     Código\n       Datos\n     Pila de usuario\n     Memoria compartida\n   (b)\nAQUÍ VA UNA IMAGEN6-4: Estructuras de datos del núcleo para un proceso (A) que desea acceder a la región de memoria compartida shmid=1: (a) Antes de llamar a shmat. (b) Después de llamar a shmat\nAsimismo en la AQUÍ VA UNA IMAGEN6-4(a) se observa que ninguna de las regiones de memoria compartida está ligada al espacio de direcciones virtuales de ningún proceso. Supóngase que un determinado proceso (A) desea ligar su espacio de direcciones virtuales a la región de memoria compartida shmid=1 entonces deberá invocar a la llamada al sistema shmat. Las estructuras de datos del núcleo se modificarían en la forma mostrada en la AQUÍ VA UNA IMAGEN6-4(b). Se crearía una región de memoria compartida en la tabla de regiones por proceso del proceso A que apuntaría a la región de la tabla de regiones asociada a la región de memoria compartida shmid=1.\nLas reglas que utiliza shmat para determinar la dirección son:\nSi shmdir = 0, el sistema selecciona la dirección. Es la opción más adecuada si se\ndesea conseguir portabilidad.Si shmdir  0, el valor de la dirección devuelto depende si se especificó o no el bit SHM_RND del parámetro shmflags. Si se especificó el segmento de memoria es enlazada en la dirección especificada por el parámetro shmdir redondeada por la constante SHMLBA (SHare Memory Lower Boundary Address). En caso contrario el segmento de memoria es enlazado en la dirección especificada por el parámetro shmdir.\nEn el momento que una región de memoria compartida shmid se une a un proceso, ésta pasa a formar del espacio de direcciones virtuales de dicho proceso, siendo por tanto accesible de la misma forma (mediante el uso de punteros) que las restantes direcciones virtuales. Luego no es necesario invocar a ninguna llamada al sistema especial para acceder a los datos almacenados en un segmento de memoria compartida.\n ###  Desligar una región de memoria compartida del espacio de direcciones virtuales de un proceso\nCuando un proceso ha terminado de usar un segmento de memoria compartida shmid entonces debe desenlazarse o desunirse de él, para conseguirlo utiliza la llamada al sistema shmdt. Su sintaxis es:\nresultado=shmdt(shmdir);\ndonde shmdir es la dirección virtual del segmento de memoria compartida que se quiere separar del proceso. Si la llamada tiene éxito en resultado se almacena el valor 0. En caso contrario se almacena el valor -1."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "###  Acceso a la información administrativa y de control de una región de memoria compartida",
"properties":
{
"type": "code",
"content": "",
"code_url": "ejemplo_6-4-4-1"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Mecanismos de sincronización tradicionales",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "n las distribuciones clásicas de UNIX existían principalmente tres mecanismos de sincronización: el carácter no expropiable del núcleo, el enmascaramiento o bloqueo de\nshmdt(array);\nshmctl(shmid, IPC_RMID,0);interrupciones y el uso de los indicadores bloqueado y deseado. Estos mecanismos de sincronización son usados exclusivamente por el núcleo.\n ## Núcleo no expropiable\nEn UNIX varios procesos pueden estar ejecutándose al mismo tiempo, quizás incluso se encuentren ejecutando la misma rutina. En un sistema con un único procesador solamente un proceso puede estar ejecutándose en la CPU. Sin embargo el sistema rápidamente conmuta de un proceso a otro, generando la ilusión de que todos ellos se ejecutan concurrentemente. Esta característica se suele denominar multiprogramación. Puesto que estos procesos comparten el núcleo, éste debe sincronizar el acceso a sus estructuras de datos para evitar su corrupción.\nLa primera medida de seguridad que utiliza UNIX es asegurar la no expropiabilidad del núcleo. Es decir, cualquier proceso ejecutándose en modo núcleo continuará ejecutándose, incluso aunque su cuanto haya expirado, hasta que vuelva a modo usuario o entre en el estado dormido en espera de algún recurso que se encuentra ocupado. Esto permite al código del núcleo manipular las estructuras de datos sin necesidad de bloquearlas, sabiendo que ningún otro proceso podrá acceder a ellas hasta que el proceso actual haya terminado de utilizarlas y esté listo para ceder el núcleo en un estado consistente.\n ## Bloqueo de interrupciones\nLa no expropiación del núcleo es una herramienta de sincronización bastante útil para un amplio rango de situaciones. Sin embargo, aunque el proceso actualmente ejecutándose en modo núcleo no pueda ser expropiado sí que puede ser interrumpido. Las interrupciones son una parte fundamental de la actividad del sistema y normalmente requieren ser atendidas urgentemente. El manipulador de las interrupciones puede manipular las mismas estructuras de datos con las que el proceso actual estaba trabajando, lo que puede producir una corrupción de los datos. Por lo tanto el núcleo debe sincronizar el acceso a los datos que son utilizados tanto por el código normal del núcleo como por el manipulador de interrupciones. UNIX resuelve este problema suministrando un mecanismo para bloquear (enmascarar) las interrupciones mediante la manipulación del npi.\nPor ejemplo, una rutina del núcleo puede desear eliminar de una cola de buffers a un determinado buffer que almacena una copia de un bloque del disco; esta cola también puede ser accedida por el manipulador de las interrupciones del disco. El código para manipular la cola es una región crítica. Antes de acceder a la región crítica, la rutina delnúcleo elevará el npi para bloquear las interrupciones del disco. Después de completar la manipulación de la cola, la rutina restaurará el npi a su valor original, con lo que las interrupciones del disco podrían ser atendidas. De esta forma el npi permite la sincronización efectiva de los recursos compartidos por el núcleo y los manipuladores de interrupciones.\n ## Uso de los indicadores bloqueado y deseado\nA menudo un proceso desea garantizarse el uso exclusivo de un determinado recurso incluso aunque entre en el estado dormido. Por ejemplo, un proceso A puede desear leer un bloque de datos del disco duro desde un buffer. Para ello en primer lugar se asignará un buffer para almacenar el bloque y después iniciará la operación de E/S con el disco. El proceso deberá esperar hasta que la operación de E/S se complete, lo que significa que mientras tanto deberá ceder el uso de la CPU para que sea ejecutado otro proceso B. Si dicho proceso B requiere usar el mismo buffer y lo utiliza para algún propósito diferente, el contenido del buffer puede quedar indeterminado o corrupto. Por lo tanto, es necesario disponer de alguna forma de bloquear el recurso mientras un proceso A se encuentra en el estado dormido.\nUNIX asocia dos indicadores, bloqueado y deseado, a cada recurso compartido. Cuando un proceso A desea acceder a un recurso compartido, como un buffer, primero el núcleo comprueba el indicador bloqueado. Si no está activado, lo activa y procede a usar el recurso. Si un segundo proceso B intentara acceder al mismo recurso, se encontraría con el indicador bloqueado activado y debería entrar en el estado dormido hasta que el recurso quedase disponible. Antes de colocar a dicho proceso en el estado dormido el núcleo activa el indicador deseado.\nCuando el primer proceso A ha terminado de usar el recurso, el núcleo desactiva el indicador bloqueado y comprueba el indicador deseado. Si se encuentra activado, eso significará que al menos un proceso se encuentra esperando para usarlo. En ese caso, examina la lista de procesos dormidos y despierta a estos procesos. Cuando uno de ellos sea planificado para ser ejecutado, el núcleo comprobara de nuevo el indicador de bloqueado y encontrará que está desactivado, entonces lo activará y procederá a usar el recurso.\n ## Limitaciones\nUna de las suposiciones básicas en el modelo de sincronización clásico es que un proceso retiene el uso exclusivo del núcleo (excepto por las interrupciones) hasta quevoluntariamente deja el núcleo o se bloquea en espera de usar un determinado recurso. Esta suposición ya no es válida en un sistema multiprocesador, puesto que cada procesador podría estar ejecutando código del núcleo al mismo tiempo.\nEn consecuencia en sistemas multiprocesador es necesario proteger aquellos datos que no necesitaban protección en un sistema con un único procesador. Para ello se tuvieron que usar otros mecanismos de sincronización tales como los semáforos, los cerrojos con bucle de espera (spin locks) y las variables de condición (que se detallan en el apartado 6.7). Estos mecanismos de sincronización aunque ideados para sistemas multiprocesador también se pueden utilizar en sistemas con un único procesador."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Seguimiento de procesos",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "tro mecanismo de comunicación disponible en las primeras distribuciones de UNIX era el conocido como seguimiento de procesos. La llamada al sistema ptrace suministra un conjunto de servicios para el seguimiento de procesos. Principalmente es utilizada por programas depuradores. Utilizando ptrace, un proceso puede controlar la ejecución de un proceso hijo. Su sintaxis e:\n   ptrace(cmd,id,addr,data);\ndonde id es el pid del proceso hijo, addr se refiere a una posición en el espacio de direcciones del hijo y la interpretación del argumento data depende de cmd. El argumento cmd permite al padre realizar las siguientes operaciones:\n- Lectura o escritura de una palabra en el espacio de direcciones, en el área U o en los registros de propósito general asociados al proceso hijo.\n- Interceptar determinadas señales. Cuando una señal interceptada es generada para el hijo, el núcleo suspenderá al hijo y notificará al padre el evento.\n- Configurar puntos de chequeo en el espacio de direcciones del hijo.\n- Reanudar la ejecución de un hijo suspendido o parado.\n- Reanudar la ejecución del hijo pero solo durante una instrucción, ejecutada la cual volverá a suspenderse el hijo.- Terminar al proceso hijo.\nTípicamente un proceso padre crea un hijo y éste invoca a la llamada ptrace para permitir al padre controlarle. El padre entonces utiliza la llamada al sistema wait para esperar por un evento que cambie el estado del proceso hijo. Cuando el evento ocurre, el núcleo despierta al padre. El valor de retorno de wait indica que el hijo se ha parado y suministra información sobre el evento que ha causa esta parada. De esta forma el padre entonces controla al hijo mediante las operaciones que se hayan especificado en ptrace. Aunque ptrace ha permitido el desarrollo de muchos depuradores, tiene varios inconvenientes y limitaciones:\nUn proceso solo puede controlar la ejecución de su hijo. Si éste hijo crea otro proceso, el depurador no puede controlar la ejecución de este nuevo proceso o sus descendientes.\nptrace es extremadamente ineficiente, requiere de varios cambios de contexto para transferir una sola palabra desde el hijo al padre. Estos cambios de contexto son necesarios porque el depurador no tiene acceso directo al espacio de direcciones del hijo.\nUn depurador no puede seguir a un proceso que ya se está ejecutando, puesto que el hijo primero necesita llamar a ptrace para informar al núcleo de que desea ser seguido.\nDurante mucho tiempo, ptrace era la única herramienta para depurar programas. Los sistemas UNIX modernos tales como SVR4 o Solaris suministran servicios de depuración más eficientes."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "Mecanismos de sincronización modernos",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},	"content": "",
"code_url": "ejemplo_6-7-1"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Mecanismos de sincronización modernos 2",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Cerrojos con bucle de espera\nUncerrojoconbucledeespera(spinlocks)18 esunaprimitivamuysimplequepermite el acceso en exclusiva a un recurso. Si un recurso está protegido por un cerrojo, un proceso intentando acceder a un recurso no disponible estará ejecutando un bucle, lo que se denomina espera ocupada, hasta que el recurso esté disponible. Un cerrojo suele ser una variable escalar que vale 0 si el recurso está disponible y que vale 1 si el recurso no está disponible. Poner a 1 el cerrojo significa “cerrar el cerrojo” y ponerlo a 0 significa “abrir el cerrojo”. La variable es manipulada usando un bucle sobre una instrucción atómica del tipo comprobar-configurar (test_and_set).\nEs muy importante que la CPU garantize que la operación sea atómica ya que en caso contrario, si un proceso leyese la variable (test) y fuese iterrumpido por otro proceso antes de llegar a realizar el set, ambos procesos leerían el mismo valor y ninguno de ellos quedaría a la espera en el cerrojo.Las siguientes líneas de código C muestran una implementación de un cerrojo.\nvoid spin_lock (spinlock_t *s) /*Función para cerrar el cerrojo*/ {while (test_and_set(s)!=0) /*Todavía no disponible*/\n        /* Se ejecuta el bucle hasta que esté disponible\n     }void spin_unlock (spinlock_t *s) /*Función para abrir el cerrojo*/ {18 Por comodidad, en lo que resta de sección se escribirá únicamente cerrojo en vez de cerrojo con bucle de espera\n \n*s=0; \nSi un proceso A desea obtener el uso de un recurso invocará a la función spin_lock para cerrar el cerrojo. La función test_and_set(s) comprueba y devuelve el valor pasado del cerrojo s. En el momento que el cerrojo sea abierto por otro proceso B, test_and_set() devolverá 0 y el proceso saldrá del bucle. Además test_and_set() pone el cerrojo a 1 para asegurar al proceso A el uso exclusivo del recurso. Cuando proceso termina de usar un recurso, debe invocar a la función spin_unlock para abrir el cerrojo.\nLa característica más importante de un cerrojo es que un proceso retiene una CPU mientras espera a que el cerrojo sea abierto. Es por lo tanto esencial que un cerrojo permanezca cerrado durante periodos de tiempo muy pequeños. En particular, no debe estar cerrados entre operaciones de bloqueo. Asimismo también es deseable bloquear las interrupciones antes de cerrar un cerrojo, para así garantizar que el tiempo de cierre será pequeño.\nLa premisa básica de un cerrojo es que un proceso realiza una espera ocupada en un procesador mientras que otro proceso está usando el recurso en un procesador diferente. Obviamente esto sólo es posible en sistemas multiprocesador. En un sistema con un único procesador, si el proceso intenta cerrar un cerrojo que ya está cerrado, entonces permanecerá en un bucle infinito. Los algoritmos para sistemas multiprocesador, no obstante, deben operar adecuadamente independientemente del número de procesadores, lo que significa que también deben funcionar adecuadamente en un sistema monoprocesador. En el caso de los cerrojos, esto requiere el cumplimiento estricto de la siguiente regla: un proceso nunca le cede el uso de la CPU mientras tiene cerrado un cerrojo. De esta forma, se asegura en el caso monoprocesador que una hebra nunca tendrá una espera ocupada en un cerrojo.\nLa mayor ventaja de los cerrojos es que son muy económicos en cuanto a tiempo de ejecución. Cuando no hay disputa por un cerrojo, tanto la operación de cierre como la de apertura típicamente requieren únicamente una instrucción cada una. Resultan ideales para estructuras de datos de uso exclusivo que necesitan ser accedidas rápidamente, como por ejemplo la eliminación de un elemento en una lista doblemente enlazada o mientras se realiza una operación del tipo carga-modificación-almacenamiento de una variable. Por tanto, los cerrojos son utilizados para proteger aquellas estructuras de datos que no necesitaban de protección en un sistema monoprocesador. Los semáforos utilizan un cerrojo para garantizar la atomicidad de sus operaciones.\n## Variables de condición\nUna variable de condición es un mecanismo más complejo asociado con un predicado (una expresión lógica para evaluar si es verdadera o falsa) basado en algún dato compartido. Permite a un proceso bloquearse en función de su valor y suministra los servicios para despertar a uno o todos los procesos bloqueados cuando el resultado del predicado cambia. En general, resulta más útil para implementar la espera por un evento que para asegurar el acceso exclusivo a un recurso.\nSupóngase, por ejemplo, uno o más procesos de un servidor que están esperando por la llegada de peticiones de clientes. Las peticiones entrantes son pasadas a los procesos que esperan o colocadas en una cola si no hay ningún proceso listo para atenderlas. Cuando un proceso del servidor está listo para atender la siguiente petición, primero comprueba la cola. Si hay una petición pendiente, el proceso la elimina de la cola y la atiende. Si la cola está vacía, el proceso se bloquea hasta que llega una petición. Este escenario de funcionamiento se puede implementar asociando una variable de condición con la cola. El dato compartido es la propia cola de peticiones y el predicado es que la cola no este vacía.\nPuede suceder que una petición llegue después de comprobar la cola pero antes de bloquear el proceso. El proceso se bloqueará aunque exista una petición pendiente. En consecuencia se requiere una operación atómica para comprobar el predicado y bloquear al proceso si fuese necesario.\nLas variables de condición suministran esta atomicidad usando un cerrojo. El cerrojo protege el dato compartido y evita el problema de no atención de peticiones anteriormente comentado. Se implementa para cada variable de condición una función llamada wait() que recibe el cerrojo como argumento y atómicamente bloquea al proceso y abre el cerrojo. Cuando se produce el evento wait() despierta al proceso y vuelve a cerrar el cerrojo antes de retornar.\nEn el caso del ejemplo, el proceso del servidor cierra el cerrojo sobre la cola de peticiones, entonces comprueba si la cola está vacía. En caso afirmativo, llama a la función wait() de la variable de condición con el cerrojo cerrado para bloquearse y abrir el cerrojo. Cuando una petición llegue a la cola el proceso será despertado, la función wait() vuelve a cerrar el cerrojo antes de retornar"
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Resumen: ¿Qué hemos aprendido?",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "NIX es un sistema operativo multiproceso. Por tanto los procesos requieren comunicación y sincronización entre sí, para conseguir distintos objetivos: transferencia y compartir datos, notificación de eventos, compartir recursos y control de procesos. En este tema, se estudian los mecanismos adecuados que debe disponer el núcleo para implementar la comunicación y sincronización entre los procesos.\n1.Las primeras distribuciones de UNIX únicamente disponían de tres mecanismos IPC universales para la comunicación entre procesos: las señales, las tuberías y el seguimiento de procesos.\nLas señales se utilizan principalmente para notificar a un proceso eventos asíncronos. Como mecanismo IPC, las señales poseen varias limitaciones: son costosas, ancho de banda limitado, y limitación en la información a transportar. Por tanto, resultan poco útiles como mecanismo IPC:\nLas tuberías son un mecanismo de comunicación unidireccional, que permite la transmisión de un flujo de datos no estructurado. Un proceso emisor escribe datos en un extremo de la tubería y otro proceso receptor puede leer estos datos en el otro extremo, y una vez leídos son borrados. Existen dos tipos: tuberías sin nombre y ficheros FIFO.\nLas tuberías sin nombre se crean mediante la invocación a la llamada al sistema pipe, y solo puede usarse por el proceso que hace la llamada y sus descendientes. Como mecanismo IPC, las tuberías proporcionan una forma eficiente de transferir datos de un proceso a otro, pero poseen limitaciones, pues no puede ser usada para transmitir datos a múltiples procesos, o que no se puede determinar cuántos mensajes han sido enviados y el envío se realiza en una única operación. Existen varias formas de implementar las tuberías: sistema de ficheros con asociación de un nodo-i y una entrada en la tabla de ficheros o conectores (sockets). SVR4 proporcional tuberías bidireccionales basadas en stream.\nLas tuberías con nombre o ficheros FIFO se crean invocando a la llamada al sistema mknod y pueden ser utilizadas por cualquier proceso siempre que disponga de los permisos adecuados. Tienen la ventaja frente a las tuberías sin nobre que poseen un nombre, pueden ser accedidos por procesos sin relación familiar, y son persistentes.La E/S en una tubería es como la E/S en un fichero, y por tanto se realiza también mediante las llamadas al sistema read y write sobre los descriptores de la tubería.\nOtro mecanismo disponible es el seguimiento de procesos. La llamada al sistema ptrace suministra un conjunto se servicios para el seguimiento, que se usa principalmetne para programas depuradores.\n2.Los mecanismos IPC del System V (semáforos, colas de mensajes y memoria compartida) vinieron a satisfacer las necesidades de muchas aplicaciones y que no resolvían los mecanismos universales antes mencionados. Estos mecanismos están implementados como una unidad y tienen las siguientes características comunes: cada tipo tiene asignada una tabla en el espacio de memoria de tamaño fijo. Cada tabla asignada tiene un número de entradas configurable, una llave numérica, un índice IT y una estructura ipc_perm, y otras informaciones como el pid del último proceso. También cada instancia tiene asignado un descriptor numérico, y dispone de llamadas al sistema tipo get para crear una nueva instancia, y tipo ctl para acceder a la información administrativa y de control.\nLos semáforos son objetos que pueden tomar valores enteros que soportan dos operaciones atómicas: P() y V(). La operación P() decrementa en una unidad el valor y bloquea al proceso que solicita la operación si su nuevo valor es menor que cero. La operación V() incrementa en una unidad el valor; si el valor resultante es mayor o igual a cero, despierta a los procesos que estuvieran esperando. En el capítulo se estudian asimismo las llamadas al sistema: semget para crear un conjunto de semáforos; semop para realizar operaciones sobre los elementos de un semáforo, y semctl para acceder a la información de control y administrativa.\nUna cola de mensajes es una estructura de datos gestionada por el núcleo, donde pueden escribir varios procesos. En la implementación del UNIX System V todos los mensajes son almacenados en el espacio del núcleo y tienen asociado un identificador de cola de mensaje denominado msgid.\nUn mensaje se implementa mediante una estructura que consta de dos campos: el tipo y el texto. El núcleo mantiene básicamente tres tipos de estructuras de datos para implementar las colas de mensajes: la tabla de colas de mensajes, la lista enlazada de cabeceras de mensajes asociadas a una cola y un área de datos. En el capítulo se estudianlas llamadas al sistema: msgget para crear una cola; msgsnd para enviar un mensaje, msgrcv para extraer un mensaje, msgctl para leer y modificar la información de control.\nLa forma más rápida de comunicar dos procesos es la memoria compartida. Para enviar datos de un proceso a otro, el proceso emisor solamente tiene que escribir en memoria y automáticamente esos datos estarán disponibles para que los lea otro proceso.\nEl núcleo posee una tabla de memoria compartida, donde cada entrada está asignada a una región de memoria compartida que viene identificada por un descriptor numérico shmid. Igualmente, el capítulo presenta las llamadas shmget para crear un segmento de memoria compartida, shmat para asignar un espacio de direcciones virtuales; shmdt para que un proceso se desuna a un segmento; shmctl para realizar operaciones de control.\n3 Los mecanismos de sincronización tradicionales son: el núcleo no expropiable, el bloqueo de interrupciones, y el uso de los indicadores bloqueado y deseado. En multiprogramación, varios procesos comparten el núcleo, por lo que este debe sincronizar el acceso a sus estructuras. La primera medida es asegurar la no expropiabilidad, donde cualquier proceso ejecutándose en modo núcleo continuará su ejecución hasta que vuelva a modo usuario o entre el estado dormido.\nAunque un proceso en modo núcleo no puede ser expropiado sí puede ser interrumpido. El núcleo debe sincronizar el acceso a los datos utilizados tanto por el código normal como por el manipulador de interrupciones, por lo que UNIX suministrar un mecanismo para bloquear mediante la manipulación del npi.\nA menudo un proceso quiero asegurarse el uso exclusivo de un determinado recurso aunque esté en estado dormido. UNIX asocia dos indicadores: bloqueado y deseado, a cada recurso compartido.\n4. Por último, el capítulo presenta los mecanismos de sincronización modernos de UNIX: semáforos, cerrojos con bule de espera, que permite el acceso en exclusiva a un recurso; y las variables de condición, mecanismo asociado con un predicado, que permite a un proceso bloquearse en función de su valor y suministra los servicios para despertar a uno o todos los procesos bloqueados."
}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe las principales limitaciones que presentan las señales.",
"responses":[                   "Como mecanismo IPC, las señales poseen varias limitaciones:\n- Las señales resultan costosas en relación a las tareas que suponen para el sistema. El proceso que envía la señal debe realizar una llamada al sistema; el núcleo debe interrumpir al proceso receptor y manipular la pila de usuario de dicho proceso, para invocar al manipulador de la señal y posteriormente poder retomar la ejecución del proceso interrumpido.\n- Tienen un ancho de banda limitado, ya que solamente existen 32 tipos de señales distintas.\n- Una señal puede transportar una cantidad limitada de información.",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe las principales limitaciones que presentan las tuberías.",
"responses":[                   "Como mecanismo IPC, las tuberías proporcionan una forma eficiente de transferir datos de un proceso a otro. Sin embargo poseen algunas limitaciones importantes:\n- Una tubería no puede ser utilizada para transmitir datos a múltiples procesos receptores de forma simultánea, ya que al leer los datos de la tubería estos son borrados.\n- Si existen varios procesos que desean leer en un extremo de la tubería, un proceso que escriba en el otro extremo no puede dirigir los datos a un proceso en concreto. Asimismo, si existen varios procesos que desean escribir en la tubería, no existe forma de determinar cuál de ellos envía los datos.\n- Si un proceso envía varios mensajes de diferente longitud en una sola operación de escritura en la tubería, el proceso que lee el otro extremo de la tubería no puede determinar cuántos mensajes han sido enviados, o dónde termina un mensaje y donde empieza el otro, ya que los datos en la tubería son tratados como un flujo de bytes no estructurados.",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Explica las pricipales ventajas y desventajas que presentan los ficheros FIFO frente a las tuberías sin nombre.",
"responses":[                   "Los ficheros FIFO poseen las siguientes ventajas sobre las tuberías sin nombre:\n- Tienen un nombre en el sistema de archivo.\n- Pueden ser accedidos por procesos sin ninguna relación familiar.\n- Son persistentes, es decir, continúan existiendo hasta que un proceso los desenlaza explícitamente usando la llamando al sistema unlink. Por tanto son útiles para mantener datos que deban sobrevivir a los usuarios activos.\nAsimismo, poseen las siguientes desventajas:\n- Deben ser borrados de forma explícita cuando no son usados.\n- Son menos seguros que las tuberías, puesto que cualquier proceso con los privilegios adecuados puede acceder a ellos.\n- Son difíciles de configurar y consumen más recursos.",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe cómo es el tratamiento de la operación de lectura en las tuberías.",
"responses":[                   "El tratamiento de la operación distingue dos casos:\nSi el tamaño requerido es mayor que la cantidad de datos existentes actualmente en la tubería, el núcleo lee los datos que están disponibles y retorna el número de bytes leídos al proceso solicitante.\nSi no existe disponible ningún dato, el proceso receptor se bloqueará hasta que otro proceso escriba en la tubería. La especificación de la opción O_NDELAY en el campo modo de mknod pone a la tubería en modo no bloqueante, es decir, las lecturas y escrituras se completarán sin bloquear, transfiriendo tantos datos como sea posible.",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Explica brevemente qué es una llave numérica.",
"responses":[                   "Cada entrada de una tabla de un determinado tipo de mecanismo IPC tiene una llave numérica, que permite controlar el acceso a dicha instancia del mecanismo IPC. La llamada al sistema ftok permite a un usuario crear una llave. Su sintaxis es la siguiente:\nresultado=ftok(ruta,letra);\nEsta llamada tiene dos parámetros de entrada, ruta que es la ruta de acceso de un fichero que ya debe estar creado y letra que es un carácter. Si la llamada se ejecuta con éxito en resultado, que es una variable del tipo predefinido key_t, se almacenará una llave. En caso de error en resultado se almacenará el valor -1.\nEn general ftok produce una llave de 32 bits combinando el parámetro letra con el número del nodo-i del fichero del parámetro ruta y con el número de dispositivo del sistema de archivos al que pertenece este fichero.",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Explica la llamada al sistema semget en los semáforos",
"responses":[                   "La llamada al sistema semget crea u obtiene un array o conjunto de semáforos. Su\nsintaxis es:\nsemid=semget(key,count,flags);\ndonde key es una llave numérica del tipo predefinido key_t o bien la constante IPC_PRIVATE, count es el número entero de semáforos del conjunto o array asociados a key y flags es una máscara de indicadores (máscara de bits). Estos indicadores permiten especificar, de forma similar a como se hace para los ficheros, los permisos de acceso al conjunto de semáforos. Asimismo en flags también se pueden introducir los indicadores IPC_CREAT e IPC_EXCL.\nSi la llamada al sistema semget se ejecuta con éxito entonces en semid se almacenará el identificador entero de un array o conjunto de count semáforos asociados a la llave key. Si no existe un conjunto de semáforos asociado a la llave la orden fallará y en semid se almacenará el valor –1 a menos que se haya realizado con el indicador IPC_CREAT de flags activo, lo que fuerza a crear un nuevo conjunto de semáforos. También se crea un nuevo conjunto de semáforos si el parámetro key se conAQUÍ VA UNA IMAGENal valor IPC_PRIVATE.",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cómo se implementa un mensaje?",
"responses":[                   "De forma general un mensaje se implementa mediante una estructura que consta de dos campos: el tipo del mensaje y el texto o cuerpo del mensaje. El tipo del mensaje es un entero positivo que permite identificar al mensaje de acuerdo con una tipificación previamente establecida por el programador. Por su parte, el texto del mensaje es un array de caracteres que contiene el mensaje propiamente dicho.\n",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué estructuras de datos mantiene el núcleo para implementar las colas de\n              mensajes?",
"responses":[                   "El núcleo mantiene básicamente tres tipos de estructuras de datos para implementar las colas de mensajes: la tabla de colas de mensajes, la lista enlazada de cabeceras de mensajes asociadas a una cola y un área de datos.\n",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Enumera las acciones que realiza el núcleo en la llamada al sistema msgsnd",
"responses":[                   "Cuando se realiza la llamada al sistema msgsnd el núcleo realiza la siguiente\nsecuencia de acciones:\n- Comprueba que el proceso emisor tiene permiso de escritura para la cola msqid.\n- Comprueba que la longitud del mensaje no excede los límites del sistema y que no contiene demasiados bytes.\n- Comprueba que el tipo de mensaje es un entero positivo.\n- Si todos las comprobaciones anteriores son superadas con éxito, asigna espacio para el mensaje en el área de datos del núcleo y copia los datos desde el espacio de direcciones del usuario al espacio de direcciones del núcleo\n- Asigna una cabecera de mensaje y la coloca al final de la lista enlazada de cabeceras de mensajes de la cola de mensajes msqid.- Salva el tipo de mensaje y su tamaño en la cabecera del mensaje.\n- ConAQUÍ VA UNA IMAGENla cabecera del mensaje para que apunte al texto de mensaje en el área de\ndatos del núcleo.\n- Actualiza varios campos de tipo estadístico en la entrada de la tabla de colas asignada a la cola msqid.\n- El núcleo despierta a los procesos que estaban dormidos esperando por la llegada de un mensaje en dicha cola.\n- Si el número de bytes en la cola excede el límite de la cola, el proceso emisor dormirá hasta que otros mensajes sean eliminados de la cola.\n- Si el proceso estableció en su llamada a msgsnd (indicador IPC_NOWAIT del campo msgflag) que no desea esperar, entonces la llamada devolverá el valor –1.",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿En qué consiste la llamada al sistema msgrcv ?",
"responses":[                   "La llamada al sistema msgrcv permite que un proceso pueda extraer un mensaje de\nuna determinada cola de mensajes. Su sintaxis es:\nresultado=msgrcv(msqid,&buffer,msgsz,msgtipo,msgflags);\ndonde msqid es un identificador de una cola de mensajes, buffer es la variable del espacio de direcciones del usuario donde se va almacenar el mensaje, msgsz es la longitud del texto del mensaje en bytes, msgtipo indica el tipo del mensaje que se desea extraer y msgflags es una máscara de indicadores que permite especificar el comportamiento del proceso receptor en caso de que no pueda extraerse ningún mensaje del tipo especificado. Si la llamada al sistema tiene éxito en resultado se almacenará el número de bytes del mensaje recibido (este número no incluye los bytes asociados al tipo de mensaje). En caso de error en resultado se almacenará el valor -1.",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Explica en qué consiste la llamada shmat",
"responses":[                   "Antes de que un proceso pueda usar la región de memoria compartida shmid, es necesario asignarle un espacio de direcciones virtuales de dicho proceso. Esto es lo que se conoce como unirse o enlazarse al segmento de memoria compartida.La llamada shmat asigna un espacio de direcciones virtuales al segmento de memoria cuyo identificador shmid ha sido dado por shmget. Por lo tanto shmat enlaza una región de memoria compartida de la tabla de regiones con el espacio de direcciones de un proceso.\nLa llamada al sistema shmat tiene la siguiente sintaxis:\nresultado=shmat(shmid,shmdir,shmflags);",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Explica en qué consiste la no expropiabilidad del núcleo.",
"responses":[                   "El núcleo no expropiable es un mecanismo de sincronización tradicional. En multiprogramación, la primera medida de seguridad que utiliza UNIX es asegurar la no expropiabilidad del núcleo. Es decir, cualquier proceso ejecutándose en modo núcleo continuará ejecutándose, incluso aunque su cuanto haya expirado, hasta que vuelva a modo usuario o entre en el estado dormido en espera de algún recurso que se encuentra ocupado. Esto permite al código del núcleo manipular las estructuras de datos sin necesidad de bloquearlas, sabiendo que ningún otro proceso podrá acceder a ellas hasta que el proceso actual haya terminado de utilizarlas y esté listo para ceder el núcleo en un estado consistente.\n",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué limitaciones presenta la llamada ptrace?",
"responses":[                   "Aunque ptrace ha permitido el desarrollo de muchos depuradores, tiene varios\ninconvenientes y limitaciones:\n- Un proceso solo puede controlar la ejecución de su hijo. Si éste hijo crea otro proceso, el depurador no puede controlar la ejecución de este nuevo proceso o sus descendientes.\n- ptrace es extremadamente ineficiente, requiere de varios cambios de contexto para transferir una sola palabra desde el hijo al padre. Estos cambios de contexto son necesarios porque el depurador no tiene acceso directo al espacio de direcciones del hijo.\n- Un depurador no puede seguir a un proceso que ya se está ejecutando, puesto que el hijo primero necesita llamar a ptrace para informar al núcleo de que desea ser seguido.Durante mucho tiempo, ptrace era la única herramienta para depurar programas. Los sistemas UNIX modernos tales como SVR4 o Solaris suministran servicios de depuración más eficientes.",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Explique qué es un cerrojo con bucle de espera y cuales son sus principales\n              ventajas.",
"responses":[                   "Un cerrojo con bucle de espera (spin locks) es una primitiva muy simple que permite el acceso en exclusiva a un recurso. Si un recurso está protegido por un cerrojo, un proceso intentando acceder a un recurso no disponible estará ejecutando un bucle, lo que se denomina espera ocupada, hasta que el recurso esté disponible. Un cerrojo suele ser una variable escalar que vale 0 si el recurso está disponible y que vale 1 si el recurso no está disponible. Poner a 1 el cerrojo significa “cerrar el cerrojo” y ponerlo a 0 significa “abrir el cerrojo”. La variable es manipulada usando un bucle sobre una instrucción atómica del tipo comprobar-configurar.\nLa mayor ventaja de los cerrojos es que son muy económicos en cuanto a tiempo de ejecución. Cuando no hay disputa por un cerrojo, tanto la operación de cierre como la de apertura típicamente requieren únicamente una instrucción cada una. Resultan ideales para estructuras de datos de uso exclusivo que necesitan ser accedidas rápidamente, como por ejemplo la eliminación de un elemento en una lista doblemente enlazada o mientras se realiza una operación del tipo carga-modificación-almacenamiento de una variable. Por tanto, los cerrojos son utilizados para proteger aquellas estructuras de datos que no necesitaban de protección en un sistema monoprocesador. Los semáforos utilizan un cerrojo para garantizar la atomicidad de sus operaciones.",
null,
null,
null
],
"correctAnswer":1        } ,"code_url":null, "content":""}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "GESTIÓN DE MEMORIA EN UNIX",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "- Cuál es la política de demanda de páginas en el SVR3.\n- Cuáles son las estructuras de datos del núcleo asociadas a la gestión de memoria\nmediante demanda de páginas.\n- Análisis de la realización de la llamada al sistema fork en un sistema con paginación.\n- Análisis de la realización de la llamada al sistema exec en un sistema de paginación.\n- Transferencia de páginas de memoria principal en el área de intercambio\n- Tratamiento de los fallos de página\n- Cómo se realiza el cambio de modo de un proceso desde el punto de vista de la gestión de memoria.\n- Localización y estructura en memoria del área U de un proceso.\nLa memoria principal o memoria física de una computadora es típicamente una memoria de acceso aleatorio (RAM) cuyo tiempo de acceso es mucho más pequeño que el de la memoria secundaria (discos duros, máquinas en red,...). Sin embargo la memoria principal tiene un coste mucho mayor y una capacidad mucho más pequeña que la memoria secundaria. En definitiva la memoria principal es un recurso limitado muy preciado.\nEl sistema operativo debe administrar toda la memoria física y asignarla tanto a los subsistemas del núcleo como a los programas de usuario. Cuando el sistema arranca, el núcleo reserva parte de la memoria principal para su código y sus estructuras de datos estáticas. Esta parte nunca es liberada y por lo tanto no se encuentra disponible para ningún otro propósito. El resto de la memoria principal es administrada dinámicamente, el núcleo asigna porciones de memoria a sus numerosos clientes (procesos y subsistemas del núcleo) y la libera cuando ya no la necesitan.\nLa parte del núcleo responsable de gestionar la memoria principal es el subsistema de administración de memoria que interactúa fuertemente con la unidad de administración de memoria (MMU19), que funcionalmente se sitúa entre la CPU y la memoria principal. La arquitectura de la MMU tiene un fuerte impacto sobre el diseño del sistema de administración de memoria del núcleo. La tarea principal de la MMU es la traducción de direcciones virtuales. La mayoría de los sistemas implementan los mapas de traducción de direcciones utilizando tablas de páginas, TLBs20, o ambos.\nLas primeras implementaciones de UNIX (versión 7 y anteriores) se ejecutaban sobre una máquina PDP-11, que tenía una arquitectura de 16 bits con un espacio de direcciones de 64 Kilobytes. Algunos modelos soportaban espacios de direcciones y de datos independientes, pero esto todavía restringía el tamaño de un proceso a 128 Kilobytes. Los mecanismos de administración de memoria estaban restringidos a una política de intercambio (Ver AQUÍ VA UNA IMAGEN7-1). Los procesos eran cargados por completo en memoria de forma contigua. Solamente un pequeño número de procesos podían estar cargados al mismo tiempo en memoria principal. Si otro proceso tenía que ser ejecutado, uno de los procesos cargados en memoria tenía que ser intercambiado a memoria secundaria, en concreto a una partición predefinida en el disco duro denominada partición o área de intercambio. El espacio de intercambio era asignado en esta partición para cada proceso\n19 MMU es el acrónimo derivado del término inglés Memory Management Unit (MMU)\n20 TLB es el acrónimo derivado del término inglés Translation Lookaside Buffer. Un TLB es una\nmemoria caché asociativa de traducción de direcciones virtuales accedidas recientemente.en el momento de la creación del proceso, así se garantizaba su disponibilidad cuando fuese necesitado.\nMemoria principal\nArea de intercambio en el disco\n  Sistema operativo\n A\n B\n C\n    Sistema operativo\n D\n B\n C\n Memoria No utilizada\nt=t0\nt=t1\nt=t2\n   Sistema operativo\n D\n A\n C\nAQUÍ VA UNA IMAGEN7-1: Administración de memoria basada en intercambio\nLa política de gestión de memoria mediante demanda de página hizo su aparición en UNIX con la aparición de la máquina VAX-11/780 en 1978, que tenía una arquitectura de 32 bits, un espacio direccionable de 4 Gigabytes y soporte hardware para la realización de demanda de páginas. BSD3 fue la primera distribución de UNIX que soportaba demanda de páginas. A mediados de los 80, todas las distribuciones de UNIX utilizaban demanda de página como principal política de administración de memoria principal, quedando la política de intercambio relegada a un segundo plano.\nEn un sistema con política de gestión de memoria mediante demanda de página, la memoria principal es dividida en bloques de tamaño fijo denominados páginas físicas o marcos de página. Asimismo los procesos también son divididos en páginas, que son cargadas en los marcos de página conforme son requeridas. Varios procesos pueden estar activos al mismo tiempo y la memoria física puede contener solo algunas de las páginas de cada proceso (ver AQUÍ VA UNA IMAGEN7-2).\nD\nA\n  B\n Memoria\nA\nB\nC\nprincipal\nD\nE\nAQUÍ VA UNA IMAGEN7-2: La memoria física almacena unas pocas páginas de cada proceso\nUn esquema de demanda de páginas posee las siguientes ventajas con respecto a un esquema de intercambio:\n- El tamaño de un programa está limitado sólo por la memoria virtual, para una máquina de 32 bits este tamaño puede ser cercano a los 4 Gigabytes.\n- El arranque de los programas es rápido puesto que no es necesario que todo el programa se encuentre cargado en memoria principal para comenzar a ejecutarse.\n- Muchos programas pueden estar cargados en memoria principal al mismo tiempo, puesto que solo unas pocas páginas de cada programa necesitan estar en memoria en un cierto instante.\n- Mover páginas dentro y fuera de la memoria principal es mucho menos costoso que intercambiar procesos enteros o segmentos.\nLa base teórica que justifica la política de demanda de página es el hecho de que los programas cumplen con el principio de localidad es decir, los procesos tienden a ejecutar instrucciones que se encuentran cercanas en el código del mismo, como por ejemplo bucles. A partir del principio de localidad surge el concepto de conjunto de trabajo que es el conjunto de páginas que el proceso ha referenciado en sus últimos n accesos a memoria. El número n indica la ventana del conjunto de trabajo.Puesto que UNIX es un sistema de memoria virtual, las páginas que son lógicamente contiguas en el espacio de direcciones virtual de un proceso no necesitan estar adyacentes físicamente en la memoria principal. Las direcciones del programa son virtuales y son divididas por la MMU en un número de página virtual y un desplazamiento desde el origen de la página. La MMU, junto con el sistema operativo, traduce el número de página virtual en el espacio de direcciones del programa a un número de marco de página para acceder a la localización adecuada. Cuando un proceso referencia a una página que no pertenece al conjunto de trabajo se produce una excepción denominada fallo de página. En su tratamiento el núcleo realiza principalmente las siguientes acciones:\nSuspender la ejecución de la instrucción en curso.\nBuscar la página en memoria secundaria.\nCargar la página en un marco de página.\nReiniciar la instrucción que se estaba ejecutando en ese momento.\nCuando se necesita cargar una página en memoria principal y no existen marcos libres, el núcleo debe reemplazar una página que se encuentra actualmente en memoria. La política de sustitución de páginas hace referencia a cómo el núcleo decide que página en memoria debe ser reemplazada, típicamente se suele usar una política del tipo LRU. La página reemplazada es almacenada en un área de intercambio. Si una página que ha sido salvada en el área de intercambio es de nuevo accedida, el núcleo manipula el fallo de página cargándola en memoria principal desde el área de intercambio. Para poder hacerlo, debe mantener alguna clase de mapa de intercambio que describa la localización de todas las páginas intercambiadas a dicha área. Si esta página debe ser intercambiada fuera de la memoria principal de nuevo, será salvada en el área de intercambio solamente si sus contenidos son diferentes de la copia salvada.\nPor otra parte, otra política de gestión de memoria es la segmentación. Esta técnica divide el espacio de direcciones de un proceso en varios segmentos o regiones. Cada dirección en el programa consiste en un identificador del segmento y un desplazamiento desde la base del segmento. Cada segmento puede tener protecciones individuales (lectura/escritura/ejecución) asociadas con él. Los segmentos son cargados en memoria física de manera independiente, ocupando cada uno de ellos una región contigua de memoria. Cada segmento está descrito por un descriptor que contiene la dirección física en la que es cargado (su dirección base), su límite o tamaño y su protección. El hardware comprueba los límites del segmento en cada acceso a memoria, para prevenir que el proceso pueda corromper a un segmento adyacente. La unidad de carga e intercambio de\nun programa es el segmento en vez de todo el programa como ocurre con la política de intercambio.\nLa segmentación puede también ser combinada con la paginación para suministrar un mecanismo de administración de memoria híbrido que resulta bastante flexible. En tales sistemas, los segmentos no necesitan ocupar un rango de posiciones contiguas en memoria. Cada segmento tiene su propio mapa de traducción, que traduce desplazamientos dentro del segmento a posiciones de memoria física. La arquitectura Intel 80x86 (es decir, Intel 80386, Intel 80486 y Pentium), por ejemplo, soporta este modelo.\nLos programadores típicamente piensan en el espacio de direcciones virtual de un proceso como formado por las regiones de código, datos y pila, la noción de segmentos traduce bien esta perspectiva. Aunque muchas versiones de UNIX explícitamente definen estas tres regiones, estas son usualmente soportadas como una abstracción a alto nivel compuestas de un conjunto de páginas virtuales contiguas y no como segmentos reconocidos por el hardware. La segmentación no ha sido muy popular en las distribuciones más utilizadas de UNIX.\nPor su importancia conceptual y mayor sencillez este capítulo está dedicado principalmente a describir la política de gestión de memoria mediante demanda de página implementada en un sistema UNIX clásico como SVR3. En primer lugar se analizan las estructuras de datos del núcleo necesarias para implementar la política de demanda de página. En segundo lugar se describe cómo se realizan las llamadas al sistema fork y exec en un sistema con demanda de página. En tercer lugar se describe la transferencia de páginas de memoria principal al área de intercambio. En cuarto lugar se describe la manipulación que realiza el núcleo de los fallos de página. Por último, disponiendo ya de todos los elementos necesarios para su adecuada comprensión, se ofrece una explicación del cambio de modo de un proceso desde el punto de vista de la gestión de memoria. Asimismo se describe la localización en memoria del área U de un proceso."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Estructuras de datos asociadas a la gestión de memoria mediante demanda de páginas en el SVR3",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "El núcleo mantiene fundamentalmente seis tipos de estructuras de datos para implementar la política de memoria mediante demanda de página: las tablas de regiones por proceso, la tabla de regiones, las tablas de páginas, las tablas de descriptores de bloques de disco (tabla dbd para abreviar), la tabla de datos de los marcos de página (tabla dmp para abreviar) y la tabla de intercambio:1) Cada proceso está dividido en regiones (texto datos y pila entre otras), por lo que se necesita una tabla de regiones denominada tabla de regiones por proceso. Dicha tabla asigna regiones de memoria virtual a cada parte de dicho proceso. Su utilidad es separar la memoria del proceso en zonas independientes e impedir que se realicen lecturas o escrituras en regiones de memoria virtual no asignadas.\n2) A su vez cada región se divide en páginas. Para llevar la cuenta de esta asignación existe una tabla global que se denomina tabla de regiones que relaciona cada una de las regiones con las páginas de memoria virtual que la compone. Para ello la tabla de regiones contiene está compuesta por una seria de tablas tabla de páginas por cada región. La tabla es global para permitir compartir regiones entre procesos (memoria compartida).\n3) La tabla de páginas indica entre otras cosas en que marco está cada página y si es válida. La MMU usa estos datos para traducir las direcciones virtuales a físicas. Cada tabla de páginas tiene asociada una tabla dbd con las mismas filas que indica dónde está la copia de la página en el disco (si hubiese alguna). Se necesitan dos tablas debido a que la tabla de regiones es manejada por el HW en la traducción de direcciones físicas a virtuales y tiene un formato limitado por el mismo. El resto de datos que el SO necesita para intercambiar páginas con el disco y que el HW no puede gestionar se encuentra en la tabla dbd.\n4) Para gestionar el espacio libre y ocupado en la memoria se utiliza una tabla de marcos de página dmp. El núcleo asigna espacio para la tabla dmp una vez durante el tiempo de vida del sistema por el contrario asocia páginas de memoria para las otras estructuras dinámicamente.\nLa tabla dmp es una estructura única para todo el sistema y permite conocer que hay en cada marco de la memoria principal, cuantos procesos lo usan y la localización de copias en un dispositivo de intercambio (si las hubiera). Además mantiene una lista enlazada de marcos libres. Esto permite llevar la contabilidad del uso de la memoria y determinar encontrar fácilmente marcos libres para cargar procesos.\nLa información que contiene es redundante con respecto al resto de tablas pero sería muy costoso recorrer todas las tablas de páginas de cada proceso para encontrar dicha información. Por ejemplo para localizar un marco de memoria libre.\n5) Finalmente y de forma análoga, por cada dispositivo de intercambio (archivo o partición) se mantiene una tabla de intercambio. Dicha tabla indica cuantas referencias acada bloque existen con el fin de determinar si un bloque está libre o no. Dicha información es redundante con respecto a la tabla dbd pero permite un acceso rápido a la misma.\nEn principio puede parecer que la tabla dbd tiene información redundante respecto a dmp que en principio parece innecesaria. Sin embargo, como se verá al estudiar el funcionamiento exec en un sistema con paginación (apartado 7.5) dmp es fundamental para localizar las páginas de un proceso que todavía no se ha cagado completamente en memoria (se encuentra en disco pero todavía no hay referencias al mismo en dbd).\n ## Relación entre regiones y páginas: tablas de páginas\nEl concepto de región es una abstracción de alto nivel independiente de las políticas de administración de memoria implementadas por el sistema operativo. Como ya se estudió en el Capítulo 3 (véase la AQUÍ VA UNA IMAGEN3-3 y la AQUÍ VA UNA IMAGEN3-4), una región es un subconjunto o área de direcciones contiguas de memoria virtual. En cualquier programa se pueden distinguir al menos tres regiones: la región de código o texto, la región de datos y la región de pila.\nCada proceso tiene asignada una tabla de regiones por proceso, cada una de sus entradas contiene entre otras informaciones la dirección virtual de comienzo de una región DIRV0 asociada al proceso y un puntero (dirección física) que señala a una entrada de la tabla de regiones.\nPor otra parte, en una arquitectura que trabaje con páginas, cada región es divida en múltiples páginas de tamaño SP. De esta forma cada entrada de la tabla de regiones contiene entre otras informaciones, la tabla de páginas. Es decir, hay una tabla de páginas en cada entrada de la tabla de regiones.\nCada entrada i de una tabla de páginas contiene los siguientes campos:\n- DIRF0, dirección física de inicio de una página.\n- Edad, que se utiliza para indicar cuánto tiempo lleva la página perteneciendo al conjunto de trabajo de un proceso\n- Copiar al escribir, este campo consta de un único bit que se conAQUÍ VA UNA IMAGENinicialmente durante la llamada al sistema fork. Si este campo está activado y un proceso intenta escribir en la página, se produce un fallo de protección. Al tratar este fallo el núcleo creará una nueva copia de la página.- Modificada, este campo consta de un único bit que se activa si un proceso ha modificado recientemente el contenido de la página.\n- Referenciada, este campo consta de un único bit que se activa si un proceso ha referenciado a la página recientemente.\n- Válida, este campo consta de un único bit que se activa si el contenido de una página es legal, pero la referencia a dicha página no es necesariamente ilegal si este bit está sin activar. Este bit está desactivado cuando la página no pertenece al conjunto de trabajo del proceso o bien no tienen memoria física asignada.\n- Bits de protección, que configuran los permisos de acceso (lectura, escritura, ejecución) de la página.\n- En general, el núcleo es el encargado de manipular los campos de válida, copiar al escribir, edad y bits de protección, mientras que el hardware se encarga de los campos de referenciada y modificada.\nPara acceder a una dirección virtual DIRV contenida en una determinada región, una forma de hacerlo es especificando la dirección virtual de comienzo DIRV0 de la región y el desplazamiento relativo DESV dentro de la misma. Se verifica la siguiente relación:\nDIRV  DIRV 0  DESV\n(1)\nDe forma análoga, para acceder a una dirección física DIRF en memoria principal asociada a una determinada página, una forma de hacerlo, es especificar la dirección física de comienzo DIRF0 de la página y el desplazamiento relativo DESF dentro de la misma. Se verifica la siguiente relación:\nDIRF DIRF0 DESF\n(2)\nPor otra parte, conocido el desplazamiento relativo DESV dentro de una región asociada a un proceso, la tabla de páginas asociada a dicha región y el tamaño de una página SP, es posible calcular la entrada i de dicha tabla de páginas que le corresponde mediante la siguiente expresión:DES  i  floor V \n SP \nLa función matemática floor (X) redondea X hacia el entero más cercano a menos\ninfinito, por ejemplo, floor(2.1)=2, floor(2.5)=2, floor(2.8)=2.\nSi se conoce la entrada i, se obtiene de forma inmediata la dirección física DIRF0 de comienzo de la página donde se va a encontrar la dirección física DIRF asociada a la dirección virtual DIRV.\nPara calcular DIRF mediante la expresión (2), sería necesario calcular previamente el desplazamiento relativo DESF dentro de la página. Se utiliza la siguiente expresión:\nDESF DESV modSP DESV%SP\nEs decir, DESF es el resto de la división entera que tiene como dividendo a DESV y\ncomo divisor a SP.En la AQUÍ VA UNA IMAGEN7-3 se muestra la asignación de memoria física de un proceso A indexada por el número de marco de página. Supongamos que desea acceder a la dirección virtual expresada en decimal DIRV=68432 siendo el tamaño de página es SP=1Kbytes. Se desea Calcular la dirección física DIRF asociada a DIRV.\n(3)\n(4) AQUÍ VA UNA IMAGEN7-3: Asignación de memoria física de un proceso A\nDe acuerdo con la tabla de regiones por proceso del proceso A representada en la AQUÍ VA UNA IMAGEN7-3, la dirección DIRV hace referencia a una posición de la región de pila, ya que ésta comienza en la dirección virtual DIRV0=64K=64·210=65536. Si se supone que el crecimiento de la pila se realiza hacia las direcciones virtuales más altas, entonces el desplazamiento relativo DESV asociado a DIRV desde el comienzo DIRV0 de la región de pila se calcularía, despejando DESV de la ecuación (1) de la siguiente forma:\nDESV DIRV DIRV0 68432655362896\nPor otra parte, la entrada de la tabla de regiones por proceso que contiene la región de pila del proceso A, apunta a una entrada de la tabla de regiones, que entre otras informaciones, contiene la tabla de páginas asociada a dicha región. De la AQUÍ VA UNA IMAGEN7-3 es inmediato identificar la tabla de páginas asociada a la región de pila del proceso A.\nHay que calcular la entrada i de dicha tabla de páginas para conocer la dirección DIRF0 de comienzo de la página donde se va a encontrar la dirección física DIRF asociada a la dirección virtual DIRV. Para ello se utiliza la expresión (3):\nDES  2896\ni  floor V   floor   floor(2.82)  2\n SP 1024De acuerdo con la AQUÍ VA UNA IMAGEN9.3, la entrada i=2 de la tabla de páginas asociada a la región de pila del proceso A, indica que DIRF0=986K. A partir de la expresión (4) se calcular el desplazamiento relativo DESF dentro de dicha página:\nDESF 2896mod1024848\nFinalmente el cálculo de la dirección física DIRF expresada en decimal asociada a DIRV, se realiza\nutilizando la expresión (2):\nDIRF  986K  848  986·1024  848  1010512\nPor último, comentar que la generación y el mantenimiento de las tablas de páginas dependen fuertemente de la computadora y de la distribución del sistema UNIX que se considere.\n ## Tabla de descriptores de bloques de disco\nCada una de las tabla de páginas tiene asignada una tabla de descriptores de bloques de disco (tabla dbd) . El número de entradas de una tabla dbd es igual al número de entradas de la tabla de páginas a la que está asignada.\nLa entrada i de una tabla dbd contiene información sobre la copia en memoria secundaria de la página a la que hace referencia la entrada i de la tabla de páginas a la que está asociada. Se distinguen los siguientes campos:\n- Dispositivo de intercambio. Es el número que identifica al dispositivo lógico de memoria secundaria donde se encuentra la copia de la página.\n- Número de bloque del dispositivo de intercambio dónde se almacena la copia de la página.\n- Tipo. Este campo permite al núcleo conocer dónde se encuentra alojada una página en memoria secundaria: en un área de intercambio (tipo=disco) o en un bloque de disco asociado a un fichero ejecutable (tipo=fichero). Asimismo este campo también permite al núcleo conocer las acciones que debe realizar sobre el marco de página donde se va alojar una página asociada a una región de un fichero ejecutable creada a través de la llamada al sistema exec cuando dicha página es accedida por primera vez por un proceso. Se distinguen dos acciones:o Llenardeceroslapáginafísica(tipo=DZ).Silapáginaperteneceala región de datos no inicializados del fichero, la página física tiene que ser llenada de ceros cuando la página es cargada en memoria. A esta acción se le denotará por el acrónimo DZ que se deriva del término inglés “Demand Zero”.\no Cargar el contenido del marco de página con el contenido de una página de un fichero ejecutable. A esta acción se le denotará por el acrónimo DF que se deriva del término inglés “Demand Fill”.\nLos procesos que comparten una región por lo tanto acceden a las mismas entradas de las tablas de páginas y descriptores de los bloques de disco. El contenido de una página virtual está o en un bloque particular en un dispositivo de intercambio o en un bloque de un fichero ejecutable en el disco. Si la página se encuentra en el área de intercambio, el descriptor de bloque de disco contiene el número de dispositivo lógico y el número de bloque que contiene los contenidos de la página. Si la página está contenida en un fichero ejecutable en disco, el descriptor de bloque del disco contiene el número de bloque lógico del fichero que contiene la página. El núcleo puede rápidamente traducir este número en direcciones del disco.\n ## La tabla de datos de marcos de página\nLa tabla de datos de marcos de páginas (tabla dmp, también conocida en la literatura como pfdata) del núcleo se inicializa al arrancar el sistema y describe cada marco de página o página física de la memoria principal. Esta tabla es indexada por el número de marco de página. Cada entrada de esta tabla posee los siguientes campos:\n- Estado de página. Indica si la página se encuentra en el área de intercambio o en un fichero ejecutable en el disco. Además indica si la página está siendo leída actualmente del dispositivo de intercambio. También indica si la página puede ser reasignada.\n- Contador de referencias, que indica el número de procesos que hacen referencia a la página física. Este contador de referencias es igual al número de entradas en las tablas de páginas que hacen referencia a dicha página física. Puede diferir del número de procesos que comparten regiones que contengan esta página, como se verá posteriormente en la sección \n## cuando se reconsidere el algoritmo fork.- El dispositivo lógico (área de intercambio o sistema de ficheros) y el número de bloque que contiene una copia de la página.\n- Punteros a otras entradas de la tabla dmp. El núcleo usa estos punteros para mantener una lista de marcos de páginas libres, que contiene a los marcos de páginas que están disponibles para ser reasignados. El núcleo utiliza esta lista a modo de caché software de páginas y la gestiona mediante una política LRU.\nAsimismo, el núcleo usa estos punteros para mantener un conjunto de colas de dispersión. Cada entrada ocupada de la tabla dmp, en función de su número de dispositivo y número de bloque, pertenecerá a una determinada cola de dispersión. De esta forma dados un número de dispositivo y número de bloque el núcleo puede acceder a la cola de dispersión adecuada para determinar rápidamente si la página que busca está cargada en memoria.\nTanto la lista de marcos de página libres o caché de páginas como las colas de dispersión guardan una fuerte analogía con la caché de bloques de disco. De hecho algunas distribuciones tales como SVR4 usan la misma caché tanto para bloques como para páginas.\nCuando se requiere un marco de página libre el núcleo accede a lista de marcos libres, elimina la entrada de la tabla dmp situada a la cabeza de la lista (será el marco libre usado menos recientemente), actualiza su número de dispositivo y número de bloque y la pone en la cola de dispersión correcta. Asimismo cuando se produce un fallo de página el núcleo consulta esta lista por si alguno de sus marcos de página contuviera aún la página que necesita, evitándose así el tener que realizar operaciones de lectura innecesarias en el dispositivo de intercambio o en el disco.\nSupuesto que se dispone de una memoria principal de una capacidad CMp y que el tamaño de página es SP entonces el número total de marcos de páginas NTM de la memoria principal se calcula de la siguiente forma:\nCMp NTM  SP\n(5)Los marcos de la memoria principal se van a identificar por número de marco j que puede tomar los siguientes valores j=0,1,2,...NTM-1. Luego cada entrada de la tabla dmp viene indexada por el número j.\nPor otra parte una dirección de memoria principal (dirección física) DIRF expresada en binario se puede descompone en dos campos (ver AQUÍ VA UNA IMAGEN7-4): el número j de marco de página y el desplazamiento relativo dentro de la página DESF .\nAQUÍ VA UNA IMAGEN7-4:Dirección de memoria principalSupóngase un computador con una memoria principal de capacidad CMp=2 Mbytes y un tamaño de página SP= 1Kbytes. Calcular el contenido en binario y en decimal de cada uno de los campos en que se descompondría la dirección física DIRF=1010512.\nEl tamaño n de una dirección de memoria es el número de bits que se necesitan para codificar el número total de posiciones direccionables de memoria, puesto que su capacidad es CMp=221 bytes, supuesto que cada posición de memoria contiene una palabra y que ésta tiene un tamaño de 1 bytes, entonces:\nnlog2 221 21bits\nPor otro lado el número total de marcos de página, se calcularía con la ecuación (5:\n CMp 221 11\nNTM   10 2 2048\nSP 2 marcos de página\nEl tamaño m del campo “Número j de marco de página” se puede obtener de la siguiente forma\nmlog2NTM log221111bits\nY el tamaño d del campo DESF, se obtiene entonces como: d nm211110bits\nLuego DIRF tiene la configuración que se muestra en la AQUÍ VA UNA IMAGEN7-5\nPasando a binario DIRF se obtiene:\nDIRF=01111011010 1101010000\nLuego j= 01111011010 = 986 y DESF = 1101010000= 848\nEste resultado está de acuerdo con el obtenido en el Ejemplo 7.1 tal como muestra la AQUÍ VA UNA IMAGEN7-5. AQUÍ VA UNA IMAGEN7-5: Configuración de DIRF\n ## Tabla de intercambio\nEl núcleo dispone de una tabla de intercambio que contiene una fila por cada copia de una página situada en un dispositivo de intercambio. En cada fila de esta tabla se mantiene un contador de referencias o contador de entradas que indica el número de entradas de las tablas de páginas que apuntan a una misma copia de página situada en un dispositivo de intercambio.Considérese la dirección virtual DIRV=68432, en el Ejemplo 7.1se calculó que la dirección física a la que hace referencia es DIRF=1010512 y que estaba contendida en la página con DIRF0=986 K. Por otra parte en el Ejemplo Ejemplo 7.2 se calculó que el número de marco de página j asociado a DIRF era j=986.\nEn la AQUÍ VA UNA IMAGEN7-6 se han representado dentro de la memoria principal, varios marcos de página que contienen páginas, una tabla de páginas, una tabla dbd, la tabla dmp y la tabla de intercambio. Además se han representado varios bloques almacenados en un dispositivo de intercambio (identificado mediante el número 1) en memoria secundaria.\nLa dirección virtual DIRV=68432 de un proceso está asociada a una entrada de una tabla de páginas cuyo campo DIRF0 apunta a la dirección de memoria 986K y al marco de página j=986. Asimismo la entrada de la tabla dbd asociada a dicha entrada de la tabla de página indica que una copia de esta página existe en el bloque no 2743 del dispositivo de intercambio 1.\nPor otra parte, la entrada j=986 de la tabla dmp indica que una copia de dicha página existe en el bloque no 2743 del dispositivo de intercambio 1 y que su contador de referencias contiene el valor 1, lo que indica que solamente un proceso está haciendo referencia a dicha página.\nPor otra parte, la entrada de la tabla de intercambio posee un contador de entradas que marca el valor 1, lo que indica que una única entrada de las tablas de páginas apunta a la copia de la página en el dispositivo de intercambio. AQUÍ VA UNA IMAGEN7-6: Estructuras de datos asociadas a la gestión de la memoria mediante demanda de páginas"
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Fork() en un sistema con paginación",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "omo se explicó en la sección 4.3 al describir la llamada al sistema fork, el núcleo\nduplica cada región del proceso padre y se la asigna al proceso hijo. Tradicionalmente, el núcleo en un sistema con intercambio hace una copia física del espacio de direcciones del padre para asignársela al proceso hijo.En el sistema de paginación del System V, el núcleo evita realizar la copia del espacio de direcciones del padre mediante la adecuada manipulación de la tabla de regiones, las tablas de páginas y la tabla dmp. El núcleo simplemente incrementa el contador de referencias en la tabla de regiones de las regiones compartidas (como por ejemplo la región de código) por el proceso padre y el proceso hijo. Para regiones privadas tales como la región de datos o la de pila, sin embargo, el núcleo asigna una nueva entrada de la tabla de regiones y una nueva tabla de páginas y después examina cada entrada de la tabla de páginas del padre. Si una página es válida, incrementa el contador de referencias ubicado en la entrada de la tabla dmp, que indica el número de procesos que comparten la página a través de diferentes regiones (en oposición al número de procesos que comparten la página por compartir la región). Además, si la página existe en un dispositivo de intercambio, incrementa el contador de entradas de la tabla de intercambio.\nLa página ahora puede ser referenciada a través de ambas regiones, que comparten la página hasta que un proceso la escriba. En dicho caso el núcleo entonces copia la página para que cada región tenga una copia privada. Para poder proceder de este modo, el núcleo activa el bit copiar al escribir en cada entrada de la tabla de páginas asignada a una región privada del padre y del hijo durante fork. Si un proceso escribe una página, provocará un fallo de protección. Cuando se trate el fallo, el núcleo hará una nueva copia de la página para el proceso que provocó el fallo. La copia física de la página es así aplazada hasta que un proceso realmente la necesita.Supóngase que un cierto proceso P ha realizado una llamada al sistema fork para generar un proceso hijo H. En la AQUÍ VA UNA IMAGEN7-7 se representan ciertas estructuras de datos del núcleo una vez finalizada la llamada. Se observa que el proceso P y el proceso H comparten la región de código y por ello el contador de referencias de la entrada de la tabla de regiones asociada a dicha región contiene el valor 2. Al compartir la región de código, P y H también están compartiendo la tabla de páginas asociada a dicha región. Por este motivo, el contador de referencias de las entradas de la tabla dmp para las páginas en la región de texto contendrá el valor 1. Por ejemplo a la dirección física 967K, supuesto páginas de 1K, le corresponde el marco de página j=967, cuya entrada asociada en la tabla dmp tiene el contador de referencias a 1.\nPor otra parte el núcleo ha asignado para H una región de datos, que es una copia de la región de datos del proceso padre P, por eso las tablas de páginas de las dos regiones son idénticas. Por lo tanto, el contador de referencias de las entradas de la tabla dmp para las páginas asociadas a dichas región de datos contendrá el valor 2. Por ejemplo a la dirección física 613K, supuesto páginas de 1K, le corresponde el marco de página j=613, cuya entrada asociada en la tabla dmp tiene el contador de referencias a 2, yaque es apuntada por dos tablas de páginas, la asociada a la región de datos de P y la asociada a la región de datos de H.\nAQUÍ VA UNA IMAGEN7-7: Una página en un proceso que ha realizado una llamada al sistema fork"
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Exec() en un sistema de paginación",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "Cuando un proceso invoca a la llamada al sistema exec, el núcleo carga el fichero\nejecutable en memoria principal desde el sistema de ficheros, como se describió en la sección \n##. En un sistema con demanda de página, el fichero ejecutable puede ser demasiado grande para caber en la memoria principal disponible. Por lo tanto, el núcleo no preasigna memoria al fichero ejecutable, sino que se la va asignando según la va necesitando, es decir, conforme se van produciendo fallos de página\nPrimero asigna las tablas de páginas y las tablas dbd para las regiones del fichero ejecutable y va marcando las entradas de las tablas dbd como DF o DZ. Cuando el núcleo va cargando el fichero ejecutable en memoria, el proceso incurre en un fallo de página en cada lectura de página. El manipulador de fallos comprueba si la página es DF o DZ pararealizar en cada caso las acciones oportunas. Si no existe espacio libre en memoria, el proceso del núcleo denominado ladrón de páginas periódicamente intercambiará páginas a memoria secundaria para hacer sitio para el fichero.\nExisten varios inconvenientes en este esquema de funcionamiento. En primer lugar, un proceso provoca un fallo de página cuando se lee cada una de sus páginas desde el fichero ejecutable. En segundo lugar, el ladrón de páginas puede intercambiar páginas del propio fichero ejecutable fuera de memoria principal antes de que la llamada al sistema exec esté completada, lo que resulta en dos operaciones de intercambio extra si el proceso necesita dicha página de nuevo.\nPara hacer a la llamada al sistema exec más eficiente, el núcleo puede solicitar las páginas directamente desde el fichero ejecutable. Para poder implementar este esquema el núcleo obtiene todos los números de bloque de disco del fichero ejecutable cuando ejecuta la llamada exec y adjunta la lista al nodo-i del fichero. Cuando conAQUÍ VA UNA IMAGENlas tablas de páginas para el fichero ejecutable, el núcleo marca el descriptor del bloque de disco con el número de bloque lógico (empezando por el bloque 0 del fichero) que contiene la página; posteriormente el manipulador de fallos de página utilizará esta información para cargar la página desde el fichero.Supóngase que el núcleo tiene que cargar en memoria una página perteneciente a un fichero ejecutable. El núcleo accede a la región a la que está asociada la tabla de páginas que contiene dicha página y sigue el puntero (almacenado en dicha región) al nodo-i asociado al fichero ejecutable. Por otra parte en la entrada apropiada de la tabla dbd asociada a dicha página, encuentra que el descriptor de bloque en disco es, por ejemplo, 84. Entonces accede al nodo-i y en la lista de números de bloque de disco del fichero ejecutable adjuntada al nodo-i durante la llamada a exec busca la posición 84, que de acuerdo a la AQUÍ VA UNA IMAGEN7-8 está asociada al número de bloque de disco 279. Por lo tanto el bloque en disco número 279 contiene la página que se desea cargar en memoria. AQUÍ VA UNA IMAGEN7-8: Ejemplo de lista de números de bloques del fichero ejecutable almacenada en el nodo-i durante la ejecución de la llamada al sistema exec\nID\n# Transferencia de páginas de memoria principal al área de intercambio\nEl ladrón de páginas es un proceso del núcleo que se encarga de transferir al dispositivo de intercambio las páginas que ya no forman parte del conjunto de trabajo de un proceso. El núcleo crea al ladrón de páginas durante la inicialización del sistema y lo invoca cuando disminuye el número de páginas físicas libres.\nCuando una página se encuentra en memoria principal su campo de edad (en la entrada de la tabla de páginas asociada a la página) se incrementa si no es referenciada. Para observar si una página ha sido referenciada el núcleo examina el campo referenciada de la entrada de la tabla de páginas asociada a la página. El sistema trabaja sobre un valor umbral para dicho campo edad, de tal forma que pueden darse dos posibles casos:\n- edad < umbral, la página no es elegible para transferencia ya que hace poco tiempo que se encuentra en memoria principal.\n- edad > umbral, la página será candidata para ser transferida al dispositivo de intercambio.\nEl núcleo tiene un valor máximo y un valor mínimo para el espacio libre que se debe mantener en memoria principal. Estos valores pueden ser ajustados por el administrador del sistema. Cuando el espacio libre en la memoria principal se encuentra por debajo del valor mínimo establecido el núcleo despierta al ladrón de páginas para que transfiera páginas al dispositivo de intercambio. El ladrón de páginas se ejecutará hasta conseguir el valor máximo de espacio libre. De esta manera se consigue reducir la transferencia de páginas que se encuentran en memoria principal hacia un dispositivo de intercambio conel objetivo de conseguir espacio y poder almacenar nuevas páginas necesarias para la ejecución de un determinado proceso.\nCuando el ladrón de páginas pretende realizar una transferencia de una página al dispositivo de intercambio debe considerar si ya existe una copia de dicha página en el dispositivo, se pueden presentar tres casos:\nNo existe una copia de la página en el dispositivo de intercambio. Entonces el núcleo “planifica” la página para ser transferida, es decir, coloca la página en una lista de páginas que deben ser transferidas. Cuando esta lista alcanza un cierto tamaño (que depende de las capacidades del manejador del disco) el núcleo copia todas las páginas de esta lista en el dispositivo de intercambio.\nExiste una copia de la página en el dispositivo de intercambio y no se ha modificado el contenido de la página de memoria principal (el campo modificada de la entrada de tabla de páginas asociada a dicha página está sin activar). Entonces el núcleo desactiva el campo válida, decrementa el contador de referencias en la entrada de la tabla dmp y coloca dicha entrada en la lista de marcos de página libres.\nExiste una copia de la página en el dispositivo de intercambio y se ha modificado el contenido de la página almacenada en memoria principal. Entonces el núcleo “planifica” la página para ser transferida y decrementa el contador de entradas de la tabla de intercambio. Cuando el contador llega a cero, libera el espacio que ocupaba la copia de la página en el dispositivo de intercambio. Cuando se vuelva almacenar la página en el dispositivo de intercambio, su copia se almacenará en otra posición distinta.\nEn conclusión el ladrón de páginas únicamente copia una página en el dispositivo de intercambio si se dan los casos 1 o 3.\nPara ilustrar la diferencia entre los casos 2 y 3, supóngase que una página está en un dispositivo de intercambio y es intercambiada a la memoria principal después de que un proceso haya provocado un fallo de página. Supóngase que el núcleo no elimina la copia de la página ubicada en el dispositivo de intercambio automáticamente. Puede suceder que en un determinado momento, el ladrón de páginas tenga que intercambiar de nuevo la página de memoria principal al dispositivo de intercambio. Si ningún proceso ha escrito dicha página desde que se puso en memoria principal, la copia en memoria es idéntica a\nla existente en el dispositivo de intercambio y por lo tanto no hay ninguna necesidad de modificar la copia existente en el dispositivo de intercambio. Por el contrario, si un proceso ha escrito la página desde que se puso en memoria principal, la copia en memoria difiere de la existente en el dispositivo de intercambio y por lo tanto el núcleo debe escribirla en el dispositivo de intercambio, aunque lo hace en una posición distinta a la que ocupaba la primera copia.\nEl ladrón de páginas va llenando una lista con las páginas que deben ser transferidas, posiblemente de diferentes regiones y las transfiere al dispositivo de intercambio cuando la lista está llena. Cuando el núcleo escribe una página en el dispositivo de intercambio, desactiva el campo valida de su entrada de la tabla de páginas y decrementa el contador de referencias de su entrada de la tabla dmp. Si el contador alcanza el valor 0, coloca la entrada de la tabla dmp al final de la lista de marcos de página libres. Asimismo si el contador no alcanza el valor 0, significa que varios procesos están compartiendo la página como resultado de una llamada al sistema fork realizada con anterioridad, pero aún así el núcleo transferirá la página. Finalmente, el núcleo asigna espacio en el dispositivo de intercambio, salva la dirección del dispositivo de intercambio donde se ha almacenado la página en la entrada de la tabla dbd asociada a dicha página, e incrementa el contador de entradas de la tabla de intercambio.\nPuesto que el contenido de una página física es válido hasta que ésta es reasignada, el núcleo cuando se produce un fallo de página consulta la lista de marcos de página libres por si alguno de sus marcos de página contuviera aún la página que necesita para evitar así tener que leerla del dispositivo de intercambio. No obstante, la página será, de todos modos, intercambiada si ya se ha colocado en la lista de páginas que deben ser transferidas.Supóngase que el ladrón de páginas debe transferir a un dispositivo de intercambio 30, 40, 50 y 20 páginas de los procesos A, B, C y D, respectivamente y que en una operación de escritura puede transferir 64 páginas al dispositivo de intercambio. En la AQUÍ VA UNA IMAGEN7-9 se muestra la secuencia de operaciones de intercambio de páginas que sucedería si el ladrón de páginas examina las páginas de los procesos en el orden A, B, C y D. Se distinguen tres pasos:\n1) El ladrón de páginas asigna espacio para 64 páginas y transfiere al dispositivo de intercambio 30 páginas del proceso A y 34 páginas del proceso B. Luego ha transferido todas las páginas del proceso A, le restan por transferir 6 páginas del proceso B, 50 del proceso C y 20 del proceso D.\n2) El ladrón de páginas asigna espacio para otras 64 páginas y transfiere al dispositivo de intercambio 6 páginas del proceso B, las 50 páginas del proceso C y 8 páginas del proceso D. Luego hatransferido todas las páginas del proceso B y del proceso C y le restan por transferir 12 páginas del proceso D.\n3) El ladrón de páginas guarda las 12 páginas que restan por intercambiar del proceso D en la lista de páginas de intercambio y no las intercambiará hasta que la lista este llena.\nPor otra parte, las dos áreas del dispositivo de intercambio utilizadas en los pasos 1) y 2) no tienen por qué ser necesariamente contiguas.\nAQUÍ VA UNA IMAGEN7-9: Asignación del espacio de intercambio en un esquema de gestión de memoria por demanda de página"
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Tratamiento de los fallos de página",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "l sistema puede incurrir en dos tipos de fallos de página: fallos de validez y fallos de protección.\n- Un fallo de validez se produce cuando un proceso intenta acceder a una página cuyo bit válida (en su entrada asociada en una tabla de páginas) no está activado. El bit válida no está activado para aquellas páginas que no pertenecen al espacio de direcciones virtuales del proceso, ni para aquellas páginas que siendo parte del espacio de direcciones virtuales del proceso no tienen asignado actualmente un marco de página.\n- Un fallo de protección se produce cuando un proceso intenta acceder a una página válida cuyos bits de protección no permiten acceder a la página (por ejemplo si un proceso intenta escribir en su región de código). Asimismo un proceso puede incurrir en un fallo de protección cuando intenta escribir una página cuyo bit copiar al escribir esté activado. El núcleo debe determinar la causa del fallo de protección.Cuando se produce un fallo de página, la MMU genera una excepción que es tratada por un manipulador del núcleo. Cada tipo de fallo de página tiene un cierto manipulador asociado. Estos manipuladores son una excepción a la regla general de que los manipuladores de interrupciones no pueden dormir, ya que un manipulador de fallos cuando se precisa leer una página del disco tiene que dormir mientras se realiza la operación de E/S. Estos manipuladores siempre duermen en el contexto del proceso que provocó el fallo de página.\n ## El manipulador de fallos de validez\nPara tratar un fallo de validez el núcleo invoca al manipulador de fallos de validez, que necesita como argumento de entrada la dirección virtual que al ser accedida ha provocado el fallo de validez. Esta dirección es suministrada al núcleo por la MMU. El manipulador en primer lugar busca la región, la entrada de la tabla de páginas y la entrada de la tabla dbd asociadas a dicha dirección. En segundo lugar bloquea la región. A continuación comprueba si la dirección que ha provocado el fallo se encuentra fuera del espacio de direcciones virtuales del proceso. En caso afirmativo, el intento de referencia a memoria no es válido y el núcleo envía una señal de violación de segmento (SIGSEGV) al proceso que lo provocó, que al ser tratada provocará la finalización del proceso. Si la referencia a memoria es legal, el núcleo asigna un marco de memoria para la página y lo carga con la página correspondiente que debe ser leída desde el área de intercambio o desde el fichero ejecutable ubicado en el disco.\nLa página que provocó el fallo se encontrará en uno de los siguientes cinco estados:\nFuera de memoria principal alojada en un dispositivo de intercambio. En la lista de marcos de páginas libres de memoria principal.\nFuera de memoria principal en un fichero ejecutable en el disco. Marcada como DZ.\nMarcada como DF.\nSe van a considerar cada uno de estos casos en detalle.\nSi una página se encuentra fuera de memoria principal alojada en un dispositivo de intercambio (caso 1), eso significa que dicha página residió en el pasado en memoria principal pero el ladrón de páginas tuvo que intercambiarla fuera de ella. A partir de la entrada correspondiente de la tabla dbd, el núcleo encuentra el dispositivo de intercambio y el número de bloque de disco donde la página se encuentra almacenada. Asimismo\nverifica que la página no se encuentra en la lista de marcos de página libres por si pudiera ahorrarse la operación de lectura en disco. El núcleo actualiza la entrada de la tabla de páginas para que apunte al marco de página donde se va cargar la página, sitúa la entrada de la tabla dmp en la cola de dispersión correspondiente y lee la página desde el dispositivo de intercambio (si fuera necesario). El proceso que provocó el fallo duerme hasta que la operación de E/S se completa, entonces el núcleo despierta a los procesos que estaban esperando a que dicha página fuese cargada en memoria.Supóngase (ver AQUÍ VA UNA IMAGEN7-10) que un proceso provoca un fallo de validez cuando intenta acceder a la dirección virtual 66K. El manipulador de fallos examina la entrada asociada de la tabla dbd y encuentra que la página está contenida en el bloque 847 del dispositivo de intercambio (supuesto que solamente hay un dispositivo de intercambio). Por tanto, la dirección virtual es legal, es decir, se encuentra dentro del espacio de direcciones virtuales del proceso. A continuación, el manipulador de fallos de validez busca en la lista de marcos de página libres pero no encuentra una entrada que contenga el bloque 847. Por lo tanto no hay una copia de la página cargada en la memoria principal y el manipulador de fallos debe leerla desde el dispositivo de intercambio.\nSupóngase que el núcleo asigna el marco de página 1776 (ver AQUÍ VA UNA IMAGEN7-11), entonces copia en dicho marco la página desde el dispositivo de intercambio y actualiza la entrada de la tabla de páginas para que apunte a la página física 1776. Finalmente, actualiza la entrada de la tabla dbd para indicar que existe todavía una copia de la página en el dispositivo de intercambio y la entrada de la tabla dmp asociada al marco 1776 para indicar que el bloque 847 del dispositivo de intercambio contiene una copia de la página.\nEl núcleo no siempre tiene que hacer una operación de E/S cuando incurre en un fallo de validez, si la entrada de la tabla dbd indica que la página está intercambiada (caso 2). Es posible que el núcleo no haya reasignado el marco de página después de transferir la página fuera de la memoria principal, o que otro proceso haya provocado que la misma página se haya cargado en otro marco de página. En ambos casos, el manipulador de fallos encuentra la página en la lista de marcos de página libres. Entonces conAQUÍ VA UNA IMAGENla entrada de la tabla de páginas para que apunte a la página física que se acaba de encontrar, incrementa el contador de referencias de la entrada de la tabla dmp asociada al marco de página donde se encuentra la página y elimina el marco de página de la lista de marcos de paginas libres, si fuese necesario. AQUÍ VA UNA IMAGEN7-10: Detalle en un determinado instante de tiempo de parte del contenido de algunas de las estructuras asociadas a la gestión de memoria mediante demanda de páginas AQUÍ VA UNA IMAGEN7-11: Detalle después de tratar el fallo de validez de parte del contenido de algunas de las estructuras asociadas a la gestión de memoria mediante demanda de páginasSupóngase que un proceso provoca un fallo de validez cuando intenta acceder a la dirección virtual 64K (ver AQUÍ VA UNA IMAGEN7-10). Supóngase además que buscando la página en la lista de marcos de página libres, el núcleo encuentra que el marco de página 1861 está asociado con el bloque de disco 1206, que coincide con el bloque contenido en de la tabla dbd asociada a dicha dirección virtual. Entonces conAQUÍ VA UNA IMAGENla entrada de la tabla de páginas asociada a la dirección virtual 64K para que apunte a la página física 1861, activa el bit válida y finaliza el manipulador. Por lo tanto el número de bloque de disco permite asociar una entrada de una tabla dbd (y por tanto una entrada de una tabla de páginas) con una entrada de la tabla dmp, lo que justifica el que ambas tablas lo almacenen.\nDe forma similar, el manipulador de fallos de validez (mfv2) no tiene que cargar la página en memoria si otro proceso con anterioridad ha provocado un fallo en la misma página y aún no se ha completado su lectura. El manipulador mfv2 se encontrará a la región asociada a dicha dirección virtual bloqueada por otra instancia del manipulador de fallos de validez (mfv1), por lo que mfv2 duerme hasta que mfv1 se completa. Cuando despierta mfv2 se encuentra con que la página ahora sí es válida y finaliza.\nSi la página se encuentra fuera de memoria principal en un fichero ejecutable en el disco (caso 3), el núcleo leerá la página del fichero ejecutable. El manipulador de fallos accede a la entrada de la tabla dbd asociada a la página y allí obtiene el número de bloque lógico del fichero que contiene la página. Asimismo accede en la tabla de regiones a la región asociada a la dirección virtual que ha provocado el fallo y sigue el puntero al nodo-idel fichero ejecutable. Usa el número de bloque lógico como un desplazamiento dentro de la lista de números de bloques de disco adjuntada al nodo-i durante la llamada al sistema exec. Conocido el número de bloque de disco, lee allí la página y la copia en un marco de memoria principal.Supóngase que un proceso provoca un fallo de validez cuando intenta acceder a la dirección virtual 1K (ver AQUÍ VA UNA IMAGEN9.10). En la tabla dbd asociada a dicha dirección se observa que el tipo de la página es fichero. Esto indica que la página está en un fichero ejecutable, en concreto en el bloque lógico no 3. El manipulador usa el número de bloque lógico como un desplazamiento dentro de la lista de números de bloques de disco adjuntada al nodo-i durante la llamada al sistema exec. Conocido el número de bloque de disco, lee allí la página, la copia en un marco de memoria principal y actualiza el contenido de la entrada de la tabla de páginas.\nSi un proceso incurre en un fallo de página para una página marcada como DF o DZ (casos 4 y 5), el núcleo asigna un marco de página libre en memoria y actualiza la entrada adecuada de la tabla de páginas. Si la página es DZ entonces llena el marco de página con ceros, si es DF llena el marco de página con una página del fichero ejecutable. Finalmente, desactiva el indicador DZ o DF. La página es ahora válida.Supóngase que un proceso provoca un fallo de validez cuando intenta acceder a la dirección virtual 3K (ver AQUÍ VA UNA IMAGEN7-10). En la entrada de la tabla de página asociada a dicha dirección se observa que la página no tenía una dirección física asignada. Esto es debido a que ningún proceso había accedido a ella desde que se había realizado la llamada al sistema exec. Por otra parte, en la tabla dbd asociada a dicha dirección se observa que el tipo de la página es DF y que el bloque lógico del fichero es 5. El manipulador usa el número de bloque lógico como un desplazamiento dentro de la lista de números de bloques de disco adjuntada al nodo-i durante la llamada al sistema exec. Conocido el número de bloque de disco, lee allí la página, la copia en un marco de memoria principal y actualiza el contenido de la entrada de la tabla de páginas.\nPor otra parte, supóngase que un proceso provoca un fallo de validez cuando intenta acceder a la dirección virtual 65K (ver AQUÍ VA UNA IMAGEN7-10). En la entrada de la tabla de página asociada a dicha dirección se observa que la página no tenía una dirección física asignada puesto que ningún proceso había accedido a ella desde que se había realizado la llamada al sistema exec. Por otra parte, en la tabla dbd asociada a dicha dirección se observa que el tipo de la página es DZ (por eso no tiene un número de bloque lógico). El núcleo asigna un marco de página libre en memoria y lo llena con ceros, A continuación actualiza la\nentrada adecuada de la tabla de páginas, la página es ahora válida y no tiene copia ni en un área de intercambio ni en un sistema de ficheros.\nUna vez realizadas las acciones descritas en función del estado en que se encontrará la página, el manipulador de fallos de página activa el bit válida de la página, desactiva el bit modificada y pone a 0 el campo edad. Además recalcula la prioridad del proceso, puesto que el proceso puede haber dormido en el manipulador de fallos en una prioridad a nivel de núcleo, dándole una injusta ventaja de planificación cuando retorna al modo usuario. Finalmente, desbloquea la región bloqueada al comienzo del manipulador.\n ## Manipulador de fallos de protección\nPara tratar un fallo de protección el núcleo invoca al manipulador de fallos de protección, que necesita como argumento de entrada la dirección virtual que al ser accedida ha provocado el fallo de protección. Esta dirección es suministrada al núcleo por la MMU. El núcleo al ejecutar el manipulador en primer lugar busca la región, la entrada de la tabla de páginas, la entrada de la tabla dbd y la entrada de la tabla dmp (edmp1) asociadas a dicha dirección. En segundo lugar bloquea la región para que el ladrón de páginas no pueda seleccionar la página para ser intercambiada mientras el manipulador está trabajando sobre ella. A continuación comprueba si el fallo de protección se ha producido porque se ha intentado acceder a una página válida cuyos bits de protección no permiten acceder a la página. En dicho caso envía una señal SIGBUS21 al proceso que provocó el fallo, desbloquea la región y finaliza. Cuando la señal sea tratada provocará la finalización del proceso.\nPor otra parte, si el manipulador determina que el fallo fue causado porque el bit copiar al escribir estaba activado y si la página física es compartida con otros procesos, el núcleo asigna un nuevo marco de página y copia en él la página que originó el fallo; los otros procesos mantienen sus referencias a la página física original. Después de copiar la página en el nuevo marco y actualizar la entrada de la tabla de páginas con el nuevo número de página física, el núcleo decrementa el contador de referencias de edmp1.Supóngase que tres procesos comparten la página física 828 (ver AQUÍ VA UNA IMAGEN7-12). El proceso B escribe la página e incurre en un fallo de protección, puesto que el bit copiar al escribir estaba activado.\n21 No todas las distribuciones envían esta misma señal.\nEl manipulador de fallos de protección entonces asigna el marco de página 786, copia la página contenida en el marco 838 en el marco 786, decrementa el contador de referencias del marco 828 y actualiza la entrada de la tabla de páginas accedida por el proceso B para que apunte a la página física 786 (AQUÍ VA UNA IMAGEN7-13).\n AQUÍ VA UNA IMAGEN7-12: Detalle de parte del contenido de algunas de las estructuras asociadas a la gestión de memoria mediante demanda de páginas en un determinado instante de tiempo AQUÍ VA UNA IMAGEN7-13: Detalle de parte del contenido de algunas de las estructuras asociadas a la gestión de memoria mediante demanda de páginas después de gestionar el fallo de protección\nSi el bit copiar al escribir está activado pero ningún otro proceso comparte la página, el núcleo permite al proceso reutilizar la página física. Desactiva el bit copiar al escribir y desasocia la página de su copia en el disco, si existe alguna, puesto que otros procesos pueden compartir la copia en el disco. A continuación, en la tabla de intercambio decrementa el contador de entradas para la página, si el contador llega a 0, libera el espacio de intercambio.\nSi una entrada de una tabla de páginas es no válida y su bit copiar al escribir está activado para causar un fallo de protección, se va a suponer que el sistema trata primero el fallo de validez cuando un proceso accede a dicha página. No obstante, el manipulador de fallos de protección debe comprobar que una página es todavía válida, porque podría dormir cuando se bloquea una región y el ladrón de páginas podría mientras tanto intercambiar la página fuera de memoria. Si la página es inválida, el manipulador de fallos retorna inmediatamente y el proceso incurrirá en un fallo de validez. El núcleo tratará el fallo de validez, pero el proceso incurrirá después en un fallo de protección. Lo más probable, es que trate este fallo de protección sin ninguna interferencia más, puesto que la página tardará un tiempo en envejecer lo suficiente para poder ser intercambiada fuera de memoria.Las últimas acciones que realiza el manipulador de fallos de protección antes de finalizar su ejecución son: activar los bits de protección y el bit modificada, desactivar el bit copiar al escribir, recalcular la prioridad del proceso y desbloquear la región que había bloqueado al comienzo de su ejecución."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Explicación desde el punto de vista de la gestión de memoria del cambio de modo de un proceso",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "upóngase que la memoria está organizada en páginas físicas de 1Kbyte, a las que se accede a través de tablas de páginas. Asimismo supóngase que la máquina dispone de un conjunto de registros triples de administración de memoria. El primer registro del registro triple contiene la dirección de memoria de una tabla de páginas en memoria física, el segundo registro contiene la primera dirección virtual que traduce la tabla de páginas y el tercer registro contiene información de control tal como el número de páginas en la tabla de páginas y permisos de acceso a la página (sólo lectura, lectura-escritura). Este modelo se corresponde al modelo de región. Cuando el núcleo prepara a un proceso para ser ejecutado, carga el conjunto de registros triples con los datos correspondientes almacenados en las entradas de la tabla de regiones por proceso.\nAunque el núcleo se ejecuta en el contexto de un proceso, la traducción de la memoria virtual asociada con el núcleo es independiente de todos los procesos. El código y los datos del núcleo residen en el sistema permanentemente y todos los procesos lo comparten. Cuando la maquina es arrancada, carga el código del núcleo dentro de memoria y conAQUÍ VA UNA IMAGENlas tablas y registros necesarios para poder traducir sus direcciones virtuales en direcciones físicas. Las tablas de páginas del núcleo son análogas a las tablas de páginas asociadas a los procesos de usuarios.\nEn muchas máquinas, el espacio de direcciones virtuales de un proceso es dividido en varias clases, incluyendo sistema y usuario y cada clase tiene su propia tabla de páginas. Cuando se ejecuta en modo núcleo, el sistema permite el acceso a las direcciones del núcleo. El acceso a estas direcciones está prohibido cuando se ejecuta en modo usuario. Así, cuando se cambia de modo usuario a modo núcleo como resultado de una interrupción o una llamada al sistema, el sistema operativo colabora con el hardware para permitir referencias a las direcciones del núcleo y cuando se vuelve de modo núcleo a modo usuario se prohiben tales referencias. Otras máquinas cambian la traducción de direcciones virtuales cargando registros especiales cuando se ejecutan en modo núcleo.:\nSupóngase que las direcciones virtuales del núcleo están comprendidas en el rango 0 a 4M-1 y las direcciones virtuales de usuario empiezan a partir de 4M. En la AQUÍ VA UNA IMAGEN7-14 se observan dos conjuntos de registros triples de administración de memoria, uno para las direcciones del núcleo y otro para las direcciones de usuario. Cada registro triple apunta a la tabla de páginas que contiene los números de páginas físicas correspondientes a las direcciones de páginas virtuales.\nAQUÍ VA UNA IMAGEN7-14: Ubicación en memoria de las tablas de páginas del núcleo y de un cierto proceso\nEl sistema permite las referencias de direcciones a través de los registros triples del núcleo solamente cuando se encuentra en modo núcleo. Por lo tanto, el cambio de modo núcleo a modo usuario o viceversa, requiere únicamente que el sistema permita o prohiba las referencias de direcciones a través de los registros triples del núcleo."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Localización en memoria del área U de un proceso",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "Como ya se describió en la sección \n## cada proceso tiene su propia área U. Sin embargo el núcleo accede a ella como si solamente existiera un única área U en todo el sistema, la del proceso actual. El núcleo cambia su mapa de traducción de direcciones virtuales de acuerdo con el proceso que se está ejecutando para acceder al área U correcta. Cuando se compila el sistema operativo, el cargador asigna a la variable u una dirección virtual fija asociada siempre al área U del proceso actual. Luego el núcleo\núnicamente puede acceder simultáneamente al área U de un cierto proceso, el proceso actual.\nEl valor del la dirección virtual del área U es conocida para otras partes del núcleo, en concreto, el módulo que realiza el cambio de contexto. Puesto que el núcleo conoce el lugar exacto, dentro de sus tablas de administración de memoria, donde se realiza la traducción de direcciones virtuales del área U, cuando el núcleo planifica un proceso para ejecutar, encuentra la correspondiente área U en memoria física y la hace accesible por medio de su dirección virtual. Para ello cambia dinámicamente la traducción de direcciones del área U a las direcciones físicas asociadas al área U del nuevo proceso actual.Supóngase que el área U tiene un tamaño de 4 Kbytes y reside en la dirección virtual del núcleo 2M. En la AQUÍ VA UNA IMAGEN7-15 se observa que los dos primeros registros triples se refieren al código y datos del núcleo (las direcciones y punteros no son mostrados). Estos registros nunca cambian, puesto que todos los procesos comparten el código y los datos del núcleo.\nPor otra parte el tercer registro triple del núcleo se refiere al área U del proceso D. Si el núcleo desea acceder al área U del proceso A, entonces copia en este registro triple la información apropiada de la tabla de páginas asociada al área U del proceso A. Por lo tanto, en cualquier instante, el tercer registro triple del núcleo se refiere al área U del proceso actualmente planificado para ejecución.\n  AQUÍ VA UNA IMAGEN7-15: Localización en memoria de las tablas de páginas del área U de diferentes procesos"
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Resumen: ¿Qué hemos aprendido?",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": ". La memoria principal o física es la memoria de acceso aleatorio (RAM). Esta memoria tiene un tiempo de acceso menor, es más costosa y de menor capacidad que la memoria secundaria (discos duros, máquinas en red). Cuando el sistema arranca, el núcleo reserva parte de la memoria principal para su código y estructuras de datos estáticas. El resto de la memoria se administra dinámicamente, asignando porciones de memoria entre procesos y subsistemas del núcleo, y la libera cuando ya no se necesita.\nEl subsistema de administración de memoria es la parte del núcleo responsable de gestionar la memoria principal, e interactúa con la unidad de administración de memoria (MMU), cuya tarea principal es la traducción de direcciones virtuales (mediante tablas de páginas y TLB). Las primeras implementaciones de UNIX empleaban para administrar la memoria una política de intercambio; donde solo pocos procesos podían estar cargados al mismo tiempo en memoria principal. Más tarde, apareció la política mediante demanda de página; donde la memoria principal se divide en bloques de tamaño fijo (página física o marco de página); a la vez que los procesos se dividen en páginas, que son las cargadas en los marcos de páginas conforme son requeridas. Así, la memoria principal contiene algunas de las páginas de cada proceso, que hace que varios procesos puedan estar activos al mismo tiempo.\nComo UNIX es un sistema de memoria virtual, las direcciones del programa son virtuales y son divididas por la MMU en un número de página virtual y un desplazamiento desde el origen de la página. La MMU, junto con el sistema operativo, traduce el número de página virtual en el espacio de direcciones del programa a un número de marco de página para acceder a la localización adecuada.\nOtra política de gestión de memoria que se combina con la paginación es la segmentación, que divide el espacio de direcciones de un proceso en varios segmentos, descrito cada uno de ellos por un descriptor que contiene la dirección física base en la que es cargado, su tamaño y su protección.\n2. El capítulo se centra en la política de gestión de memoria mediante demanda de página implementada en SVR3. El núcleo mantiene fundamentalmente cuatro tipos de estructuras de datos para implementar la política de memoria mediante demanda depágina: las tablas de páginas, las tablas de descriptores de bloques de disco (dbd), la tabla de datos de los marcos de página (dmp) y la tabla de intercambio.\nLas tablas de páginas (almacenadas en memoria principal) relaciones regiones y páginas, existiendo una tabla de páginas por cada entrada de la tabla de regiones. Como ya aprendimos en capítulos anteriores, cada proceso tiene asignada una tabla de regiones de proceso, donde cada una de las entradas contiene la dirección virtual de comienzo y un puntero que señala a la tabla de regiones. En una arquitectura con páginas, cada región se divide en múltiples páginas, y así cada entrada de la tabla de regiones contiene un puntero a una tabla de páginas. Cada entrada de una tabla de páginas contiene los campos: dirección física de inicio de una página, edad, copiar al escribir, modificada, referenciada, válida, bits de protección.\nCada una de las tablas de páginas tiene asignada una tabla de descriptores de bloques de disco (tabla dbd). El número de entradas de una tabla dbd es igual al número de entradas de la tabla de páginas a la que está asignada. La entrada de una tabla dbd tiene información sobre la copia en memoria secundaria, y presenta los campos: dispositivo de intercambio, número de bloque y tipo. Los procesos que comparten una región acceden a las mismas entradas de las tablas de páginas y descriptores de los bloques de disco. El contenido de una página virtual está o bien en un bloque particular en un dispositivo de intercambio, o bien en un bloque de un fichero ejecutable en el disco.\nLa tabla de datos de marcos de páginas (tabla dmp) del núcleo se inicializa al arrancar el sistema y describe cada marco de página de memoria principal. Cada entrada de esta tabla posee los siguientes campos: estado de página, contador de referencias, dispositivo lógico, punteros a otras entradas de la tabla dmp. Cuando se requiere un marco de página libre, el núcleo accede a lista de marcos libres, elimina la entrada de la tabla dmp situada a la cabeza de la lista, actualiza su número de dispositivo y número de bloque y la pone en la cola de dispersión correcta.\nPor último, el núcleo dispone de una tabla de intercambio que contiene una fila por cada copia de una página situada en un dispositivo de intercambio. En cada fila hay un contador de referencias que indica el número de entradas de las tablas de páginas que apuntan a una misma copia de página situada en un dispositivo de intercambio.\n3. Como ya se vio en capítulos anteriores, en la llamada al sistema fork el núcleo duplica cada región del proceso padre y se la asigna al proceso hijo. En el sistema depaginación del System V, el núcleo evita realizar la copia del espacio de direcciones del padre mediante la adecuada manipulación de la tabla de regiones, las tablas de páginas y la tabla dmp. El núcleo incrementa el contador de referencias en la tabla de regiones de las regiones compartidas, mientras que para regiones privadas (región de datos, pila) el núcleo asigna una nueva entrada de la tabla de regiones y una nueva tabla de páginas y después examina cada entrada de la tabla de páginas del padre. Si una página es válida, incrementa el contador de referencias de la entrada de la tabla dmp. Además, si la página existe en un dispositivo de intercambio, incrementa el contador de entradas de la tabla de intercambio.\n4. Cuando un proceso invoca a la llamada al sistema exec, el núcleo carga el fichero ejecutable en memoria principal desde el sistema de ficheros. En un sistema con paginación, el núcleo no preasigna memoria al fichero ejecutable, sino que se la va asignando según se van produciendo fallos de página. En primer lugar, asigna las tablas de páginas y las tablas dbd para las regiones del fichero ejecutable y va marcando las entradas de las tablas dbd como DF o DZ. Cuando el núcleo va cargando el fichero ejecutable en memoria, el proceso incurre en un fallo de página en cada lectura de página. El manipulador de fallos comprueba si la página es DF o DZ para realizar en cada caso las acciones oportunas. Si no existe espacio libre en memoria, el proceso del núcleo denominado ladrón de páginas periódicamente intercambiará páginas a memoria secundaria para hacer sitio para el fichero.\n5. En cuanto a la transferencia de páginas de memoria principal al área de intercambio, el ladrón de páginas es el encargado de realizar la transferencia de las páginas que ya no forman parte del conjunto de trabajo de un proceso. El núcleo crea el ladrón de páginas en la inicialización del sistema y lo invoca cuando disminuye el número de páginas físicas libres. El ladrón de páginas se ejecutará hasta conseguir el valor máximo de espacio libre.\n6. Por otro lado, el sistema puede incurrir en dos tipos de fallos de página: fallos de validez y fallos de protección. Un fallo de validez se produce cuando un proceso intenta acceder a una página cuyo bit válida no está activado. Un fallo de protección se produce cuando un proceso intenta acceder a una página válida cuyos bits de protección no permiten acceder a la página, o cuando intenta escribir una página cuyo bit copiar al escribir esté activado.\n7. En muchas máquinas, el espacio de direcciones virtuales de un proceso es dividido en varias clases (incluyendo sistema y usuario) donde cada una tiene su propia tabla depáginas. Cuando se ejecuta en modo núcleo, el sistema permite el acceso a las direcciones del núcleo. El acceso a estas direcciones está prohibido cuando se ejecuta en modo usuario. Cuando se cambia de modo usuario a modo núcleo como resultado de una interrupción o una llamada al sistema, el sistema operativo permite referencias a las direcciones del núcleo, y cuando se vuelve de modo núcleo a modo usuario se prohíben tales referencias.\n8. Por último, se estudia la localización en memoria del área U de un proceso. Como ya se estudió, cada proceso tiene su propia área U. Si embargo, el núcleo únicamente puede acceder al área U del proceso actual. El núcleo camba su mapa de traducción de direcciones virtuales de acuerdo con el proceso que se está ejecutando."
}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Señala las principales ventajas que presenta la política de gestión de memoria de demanda de página sobre el esquema de intercambio.",
"responses":[                         "Un esquema de demanda de páginas posee las siguientes ventajas con respecto a un esquema de intercambio:\n- El tamaño de un programa está limitado sólo por la memoria virtual, para una máquina de 32 bits este tamaño puede ser cercano a los 4 Gigabytes.\n- El arranque de los programas es rápido puesto que no es necesario que todo el programa se encuentre cargado en memoria principal para comenzar a ejecutarse.\n- Muchos programas pueden estar cargados en memoria principal al mismo tiempo, puesto que solo unas pocas páginas de cada programa necesitan estar en memoria en un cierto instante.\n- Mover páginas dentro y fuera de la memoria principal es mucho menos costoso que intercambiar procesos enteros o segmentos.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe las principales acciones que realiza el núcleo cuando se produce un fallo de página.",
"responses":[                         "Cuando un proceso referencia a una página que no pertenece al conjunto de trabajo se produce una excepción denominada fallo de página en su tratamiento el núcleo realiza principalmente las siguientes acciones:\n- Suspender la ejecución de la instrucción en curso.\n- Buscar la página en memoria secundaria.\n- Cargar la página en un marco de página.\n- Reiniciar la instrucción que se estaba ejecutando en ese momento.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Explica qué describe el campo “edad” de una entrada de una tabla de páginas.",
"responses":[                         "El campo edad, se utiliza para indicar cuanto tiempo lleva la página perteneciendo al conjunto de trabajo de un proceso.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe el campo “tipo” de una entrada de la tabla de descriptores de bloque de disco.",
"responses":[                         "Este campo permite al núcleo conocer dónde se encuentra alojada una página en memoria secundaria: en un área de intercambio (tipo=disco) o en un bloque de disco asociado a un fichero ejecutable (tipo=fichero). Asimismo este campo también permite al núcleo conocer las acciones que debe realizar sobre el marco de página donde se va alojar una página asociada a una región de un fichero ejecutable creada a través de la llamada al sistema exec cuando dicha página es accedida por primera vez por un proceso. Se distinguen dos acciones:\n- Llenar de ceros la página física (tipo=DZ). Si la página pertenece a la región de datos no inicializados del fichero, la página física tiene que ser llenada de ceros cuando la página es cargada en memoria. A esta acción se le denotará por el acrónimo DZ que se deriva del término inglés “Demand Zero”.\n- Cargar el contenido del marco de página con el contenido de una página de un fichero ejecutable. A esta acción se le denotará por el acrónimo DF que se deriva del término inglés “Demand Fill”.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe qué indica el campo “estado de página” de la tabla de datos de marcos\n                    de página.",
"responses":[                         "Estado de página. Indica si la página se encuentra en el área de intercambio o en un fichero ejecutable en el disco. Además indica si la página está siendo leída actualmente del dispositivo de intercambio. También indica si la página puede ser reasignada.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describa qué inconvenientes presenta la llamada al sistema exec en un sistema\n                    de paginación.",
"responses":[                         "Existen varios inconvenientes en la llamada al sistema exec. En primer lugar, un proceso provoca un fallo de página cuando se lee cada una de sus páginas desde el fichero ejecutable. En segundo lugar, el ladrón de páginas puede intercambiar páginas del propio fichero ejecutable fuera de memoria principal antes de que la llamada al sistema exec esté completada, lo que resulta en dos operaciones de intercambio extra si el proceso necesita dicha página de nuevo.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe los tres casos que se pueden presentar cuando el ladrón de páginas pretende realizar una transferencia y debe comprobar si existe ya una copia de una página en el área de intercambio.",
"responses":[                         "Cuando el ladrón de páginas pretende realizar una transferencia de una página al dispositivo de intercambio debe considerar si ya existe una copia de dicha página en el dispositivo, se pueden presentar tres casos:\n- No existe una copia de la página en el dispositivo de intercambio. Entonces el núcleo “planifica” la página para ser transferida, es decir, coloca la página en una lista de páginas que deben ser transferidas. Cuando esta lista alcanza un cierto tamaño (que depende de las capacidades del manejador del disco) el núcleo copia todas las páginas de esta lista en el dispositivo de intercambio.\n- Existe una copia de la página en el dispositivo de intercambio y no se ha modificado el contenido de la página de memoria principal (el campo modificada de la entrada de tabla de páginas asociada a dicha página está sin activar). Entonces el núcleo desactiva el campo válida, decrementa el contador de referencias en la entrada de la tabla dmp y coloca dicha entrada en la lista de marcos de página libres.\n- Existe una copia de la página en el dispositivo de intercambio y se ha modificado el contenido de la página almacenada en memoria principal. Entonces el núcleo “planifica” la página para ser transferida y decrementa el contador de entradas de a tabla de intercambio. Cuando el contador llega a cero, libera el espacio que ocupaba la copia de la página en el dispositivo de intercambio. Cuando se vuelva almacenar la página en el dispositivo de intercambio, su copia se almacenará en otra posición distinta.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Describe el comportamiento del manipulador de fallos de validez.",
"responses":[                         "Para tratar un fallo de validez el núcleo invoca al manipulador de fallos de validez, que necesita como argumento de entrada la dirección virtual que al ser accedida ha provocado el fallo de validez. Esta dirección es suministrada al núcleo por la MMU. El manipulador en primer lugar busca la región, la entrada de la tabla de páginas y la entrada de la tabla dbd asociadas a dicha dirección. En segundo lugar bloquea la región. A continuación comprueba si la dirección que ha provocado el fallo se encuentra fuera del espacio de direcciones virtuales del proceso. En caso afirmativo, el intento de referencia a memoria no es válido y el núcleo envía una señal de violación de segmento (SIGSEGV) al proceso que lo provocó, que al ser tratada provocará la finalización del proceso. Si la referencia a memoria es legal, el núcleo asigna un marco de memoria para la página y lo carga con la página correspondiente que debe ser leída desde el área de intercambio o desde el fichero ejecutable ubicado en el disco.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "SISTEMAS DE ARCHIVOS EN UNIX ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "- Qué es un sistema de ficheros y para qué sirve.\n- Cómo se construye la estructura jerárquica de ficheros (proceso de montaje).\n- Qué es un enlace simbólico y qué tipos de enlaces hay.\n- Cómo se acelera el acceso a los ficheros mediante la caché de bufers de bloques y cuales son las ventajas e inconvenientes de esta técnica.\n- La interfaz nodo-V/SVF que permite al núcleo gestionar distintos sistemas de archivos.\n- El sistema de ficheros System V file systems s5fs.\n- Cómo se arreglan los errores en un sistema de ficheros.\n- El sistema de ficheros FFS o UFS.\n- Algunas de las características de los sistemas de archivos modernos.\nUn sistema de ficheros permite realizar una abstracción de los dispositivos físicos de almacenamiento de la información para que sean tratados a nivel lógico, como una estructura de más alto nivel y más sencilla que la estructura de su arquitectura hardware particular.\nTodas las versiones del UNIX System V, así como las versiones anteriores a BSD4.2 disponían de un único sistema de ficheros, ahora conocido como sistema de ficheros del System V (System V file system s5fs). Con la distribución BSD4.2 se introdujo un nuevo sistema de ficheros denominado sistema de ficheros rápido (Fast File System (FFS)) que suministraba mejores prestaciones y mayor funcionalidad que s5fs. Desde entonces, FFS fue ganando una amplia aceptación, de hecho fue incluido en distribuciones no BSD como SVR4.\nTanto s5fs como FFS resultaban adecuados para aplicaciones generales de tiempo compartido. Sin embargo, resultaban inadecuados para las necesidades de otros tipos de aplicaciones. Por ello fue necesario crear nuevos sistemas de ficheros que mejoraran el FFS y atendieran las necesidades de ciertas aplicaciones específicas. La mayoría de estos sistemas de ficheros modernos usan técnicas sofisticadas que suministran un mejor comportamiento, mayor seguridad y disponibilidad.\nLos sistemas de ficheros anteriormente comentados son locales puesto que almacenan y administran sus datos en dispositivos directamente conectados al sistema. La proliferación de redes de computadoras condujo a un incremento de la necesidad de poder compartir ficheros entre computadoras. Los sistemas de ficheros distribuidos permiten a un usuario acceder a ficheros que residen en máquinas remotas. Ejemplos de sistemas de ficheros distribuidos son: NFS (Sun Microsystems’s Network File System), RFS (AT&T Remote File Sharing) y AFS (Andrew File System).\nAsimismo, surgió una creciente necesidad de que UNIX pudiera soportar sistemas de ficheros de otros sistemas operativos tales como MS-DOS. Esto permitiría a un sistema UNIX ejecutándose en una máquina poder acceder a ficheros en particiones MS-DOS de la misma máquina.\nPuesto que el subsistema de archivos de UNIX solo podía soportar un único tipo de sistema de archivos, se hacía necesario disponer de una interfaz en el subsistema de archivos de UNIX que permitiera soportar múltiples tipos de sistemas de ficheros: UNIX yno-UNIX, locales y distribuidos. Este objetivo se consiguió con la interfaz nodo-v/sfv desarrollado por Sun Microsystems que introdujo los conceptos de nodo virtual (nodo-v) y sistema de ficheros virtual (sfv).\nEl presente capítulo consta de cuatro partes claramente diferenciadas, en la primera se estudian los ficheros especiales, el montaje de sistemas de ficheros, los enlaces simbólicos y la caché de buffers de bloques. En la segunda parte se describe la interfaz nodo-v/sfv del SVR4. La tercera parte se dedica al estudio, debido a su importancia histórica y a su sencillo diseño, del sistema de ficheros s5fs implementado en SVR4.\nLa cuarta parte está dedicada a la comprobación del estado de un sistema de ficheros. La quinta incluye una serie de consideraciones adicionales sobre la interfaz nodo- v/sfv. Y la sexta describe el sistema de ficheros FFS. El capítulo concluye explicando las características más representativas de los sistemas de archivos modernos."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Ficheros especiales",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "Los ficheros especiales o ficheros de dispositivos permiten a los procesos comunicarse con los dispositivos periféricos. Los dispositivos periféricos pueden ser de dos tipos: dispositivos modo bloque (discos, CD-ROM,...) y dispositivos modo carácter (terminales, impresoras, ratón...). La principal diferencia entre ambos tipos de dispositivos es que para realizar la transferencia de datos con los dispositivos modo bloque el núcleo utiliza un área de almacenamiento en la memoria principal denominada caché de buffers de bloques. Usualmente, en el directorio /dev se suelen almacenar todos los ficheros de dispositivos.\nEl sistema también puede soportar dispositivos software (o pseudodispositivos) que no tienen asociados un dispositivo físico. Por ejemplo, si una parte de la memoria del sistema se gestiona como un dispositivo, los procesos que quieran acceder a esa zona de memoria tendrán que usar las mismas llamadas al sistema que existen para el manejo de ficheros ordinarios, pero sobre el fichero de dispositivo /dev/mem (fichero de dispositivo genérico para acceder a memoria). En esta situación la memoria es tratada como un periférico más.\nUna de las características distintivas del sistema de ficheros de UNIX es la generalización del concepto de fichero para incluir todo tipo de objetos relativos a E/S, tales como directorios, enlaces simbólicos, dispositivos hardware, pseudodispositivos y abstracciones de comunicación como las tuberías o los conectores. Cada uno de ellos esaccedido a través de descriptores de ficheros y el mismo conjunto de llamadas al sistema que opera sobre los ficheros ordinarios también manipula estos objetos de E/S. Por ejemplo, un usuario puede enviar datos a una impresora en línea simplemente abriendo el fichero especial asociado con ella y escribiéndolo.\nSin embargo, algunos objetos de E/S no soportan todas las operaciones de ficheros. Por ejemplo, los terminales y las impresoras no tienen noción de acceso aleatorio o búsquedas. Las aplicaciones a menudo necesitan verificar (típicamente a través de la llamada al sistema fstat) a qué tipo de fichero están accediendo.\nLos ficheros de dispositivos, al igual que el resto de ficheros, tienen asociado un nodo-i. En el caso de los ficheros ordinarios o los directorios, este nodo-i contiene, entre otras informaciones, dónde se encuentran los bloques de datos del fichero. Pero en el caso de los ficheros de dispositivo no hay datos a los que referenciar. En su lugar, el nodo-i contiene dos números conocidos como número principal (major number) y número secundario (minor number). El número principal indica el tipo de dispositivo de que se trata (disco, cinta, terminal, etc). El número secundario indica el número de unidad dentro del dispositivo, es decir, la instancia específica del dispositivo.\nPor ejemplo, todos los discos duros pueden tener un número principal igual a 5 y cada disco duro existente tendrá un número secundario diferente. Por otra parte, los dispositivos de modo bloque y los dispositivos de modo carácter tienen conjuntos independientes de números principales. Así un número principal igual a 5 para dispositivos en modo bloque puede referirse a una unidad de disco, mientras que para dispositivos de modo carácter puede referirse a una impresora en línea.\nEl núcleo mantiene dos tablas, la tabla de conmutación de dispositivos modo bloque y la tabla de conmutación de dispositivos modo carácter. Cada entrada de una de estas tablas contiene una estructura cuyos miembros son unos punteros a una colección de rutinas que permiten manejar a un dispositivo. Esta colección de rutinas constituye realmente el driver o manejador del dispositivo.\nCuando un usuario invoca a una llamada al sistema para realizar una operación de E/S (supóngase que se realiza una llamada read) sobre un fichero especial, el núcleo realiza las siguientes acciones:\n- Usa el descriptor del fichero para localizar el objeto de fichero abierto.- Comprueba en el objeto de fichero abierto que el fichero ha sido abierto en un modo tal que permite ser leído.\n- Obtiene en el objeto de fichero abierto el puntero al nodo-i en memoria ( nodo-im22) para esta entrada. Un nodo-im es una estructura de datos del núcleo que duplica la información almacenada en un nodo-i de un disco y que además contiene ciertas informaciones adicionales asociada al fichero activo en memoria.\n- Bloquea el nodo-im para asegurarse temporalmente la exclusividad de acceso al fichero.\n- Comprueba el campo modo del nodo-im para encontrar el tipo del fichero. Supóngase que es un fichero de dispositivo de modo carácter.\n- Utiliza el número principal y el número secundario (almacenados en el nodo-im) como índice en la tabla de conmutación de dispositivos modo carácter para localizar la estructura que contiene los punteros a las rutinas que constituyen el manejador del dispositivo. Supóngase que dicha estructura se denomina cdevsw y que su definición es:\nstruct cdevsw{ int (*d_open)(); int (*d_close)(); int (*d_read)(); int (*d_write)(); ...\n}cdevsw[];\nLos campos de la estructura cdevsw tales como d_read definen una interfaz abstracto. Cada dispositivo lo implementa a través de funciones específicas, por ejemplo, lpread() para una impresora en línea o ttread() para un terminal.\n22 Esta nomenclatura es exclusiva de este libro.- De cdevsw, obtiene el puntero a la rutina que implementa la operación de lectura (d_read) para este dispositivo.\n- Invoca a la rutina d_read para realizar la operación de lectura sobre el dispositivo.\n- Desbloquea el nodo-im y devuelve el resultado al usuario.\nSe observa que muchos de estos pasos son independientes del dispositivo. Los pasos 1 al 4 y el paso 9 se pueden aplicar tanto a los ficheros ordinarios como a los ficheros de dispositivos. Por lo tanto este conjunto de pasos es independiente del tipo de fichero. Los pasos 5 al 7 representan la interfaz entre el núcleo y los dispositivos, que se encuentra encapsulado en la estructura almacenada en una entrada de la tabla de conmutación de dispositivos modo carácter o de la tabla de conmutación de dispositivos modo bloque. Todo el procesamiento dependiente del dispositivo está localizado en el paso 8."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Montaje de sistemas de ficheros ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content":""
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Enlaces simbólicos",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},	"content": "",
"code_url": "ejemplo_8-5"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "La caché de buffers de bloques",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "Las operaciones de E/S en disco son una de las principales causas de los cuellos de botella en cualquier sistema. El tiempo requerido para leer un bloque de 512 bytes de un disco es del orden de unos pocos milisegundos. El tiempo para copiar la misma cantidad de datos de una posición a otra de memoria principal es del orden de unos pocos microsegundos. Los dos difieren en un factor de 1000. Si cada operación de E/S requiriera un acceso a disco, el sistema sería muy lento. Por lo tanto, es necesario minimizar las operaciones de E/S en disco. UNIX consiguió este objetivo implementando, vía software, una memoria caché en un área de memoria principal para almacenar los bloques de discoaccedidos recientemente en el sistema de ficheros. A esta caché se le denomina caché de buffers de bloques.\nLos sistemas UNIX tradicionales usaban esta caché de buffers únicamente para almacenar bloques de disco. Los sistemas UNIX modernos tales como SVR4 y Sun OS (versión 4 o superiores) integran la caché de buffers con el sistema de paginación. En esta sección se describe la caché de buffers de los sistemas UNIX tradicionales tales como SVR3 o anteriores.\nEl tamaño de la caché de buffers es típicamente el 10% de la memoria principal. La caché de buffers está compuesta de buffers de datos usualmente de tamaño fijo (suficientemente grande para contener un bloque de disco).\nUn buffer consta de dos partes: la cabecera del buffer y la copia del bloque de disco que almacena. La cabecera del buffer almacena información que permite identificar al buffer para poder realizar tareas de sincronización y administración de la caché.\nLa caché mantiene un conjunto de colas de dispersión o colas hash basadas en el número de dispositivo y en el número de bloque. El núcleo enlaza los buffers ubicados en una cierta cola de dispersión como una lista circular doblemente enlazada. Cada cola posee un buffer mudo a modo de cabecera para marcar el principio y el final de la lista. El número de buffers en una cola de dispersión varía durante el tiempo de vida del sistema. El núcleo debe usar una función de dispersión que distribuya los buffers uniformemente entre todas las colas de dispersión, además esta función debe ser sencilla para que no se vea afectado el rendimiento del sistema. Los administradores del sistema pueden configurar el número de colas de dispersión de la caché de buffers.En la AQUÍ VA UNA IMAGEN8-3 se representa un esquema simplificado de una caché de buffers de bloques en un sistema de ficheros que utiliza una sola partición. Esta caché consta de cuatro colas de dispersión y actualmente cada cola contiene tres buffers. La cola hash no 0 contiene los buffers marcados con los números 28, 4 y 64, que son los números de los bloques de disco que contiene, obsérvese que todos estos números cumplen la regla\nNo bloque%4=0\nes decir, al dividir el número de bloque por 4 su resto es 0. Se observa que las otras colas siguen reglas similares para los buffers que contienen.    Cabecera de la cola de dispersión no 0 [No bloque%4=0]     Cabecera de la cola de dispersión no 1 [No bloque%4=1]17\n97\n      Cabecera de la cola de dispersión no 2 [No bloque%4=2]98\n50\n10\n      Cabecera de la cola de dispersión no 3 [No bloque%4=3]3\n35\n99\n  AQUÍ VA UNA IMAGEN8-3: Caché de buffers\nEl almacenamiento de apoyo de una caché es la posición permanente de los datos, cuyas copias son almacenadas en la caché. Una caché puede administrar datos de diferentes almacenamientos de apoyo. Para la caché de buffer de bloques, el almacenamiento de apoyo es el sistema de ficheros en disco. Si la máquina está conectada en red, el almacenamiento de apoyo incluye a los ficheros en los nodos remotos.\nGeneralmente, una caché puede soportar dos políticas de escritura: inmediata y post- escritura. La política de escritura inmediata consiste en que cuando hay que realizar una operación de escritura ésta se realiza tanto en la copia de los datos almacenados en la caché como en los datos originales situados en el almacenamiento de apoyo. De esta forma los datos en el almacenamiento de apoyo están siempre actualizados (excepto quizás por la última operación de escritura). Además no hay problemas de pérdida de datos o corrupción del sistema de ficheros en caso de que el sistema se cuelgue. También, la administración de la caché es más simple.\nTodas estas ventajas convierten a la política de escritura inmediata en una buena opción para cachés implementadas por hardware. Sin embargo, esta política no es apropiada para la caché de buffers de bloques, puesto que el rendimiento del sistema se ve seriamente afectado. Se estima que en la operación normal de un sistema cerca de un\n28\n4\n64\n 5\ntercio de las operaciones de E/S son operaciones de escritura y muchas de ellas son transitorias. Por ejemplo, la sobreescritura de un dato o el borrado del contenido de un fichero. Esto causaría muchas escrituras innecesarias, ralentizando al sistema tremendamente.\nPor esta razón, la caché de buffer de UNIX utiliza una política de escritura del tipo post-escritura. Es decir, los bloques modificados son simplemente marcados como “sucios” y son escritos al disco cuando los buffers que los contienen son seleccionados para ubicar otros bloques al no existir buffers libres en la caché. Esto permite a UNIX eliminar muchas de las escrituras y también reorganizar las escrituras de forma que se optimice el rendimiento del disco. Retrasar las escrituras, sin embargo, supone un riesgo potencial de corrupción del sistema de ficheros en caso de que la máquina se cuelgue.\n ## Funcionamiento básico\nCuando un proceso debe leer o escribir un bloque, el núcleo primero busca el bloque en la caché de buffers. Intenta localizar un buffer que tenga la combinación adecuada de número de dispositivo y número de bloque. Si no lo localiza, significará que el bloque no está en la caché. En dicho caso debe ser leído del disco, excepto cuando el bloque entero debe ser sobrescrito (esto ocurre por ejemplo cuando al escribir al final de un archivo se agota el bloque existente y se continua en un bloque nuevo). Para ello, el núcleo escoge un buffer de la caché para almacenar dicho bloque e inicia una operación de lectura en disco.\nSi el bloque es modificado por un proceso, el núcleo aplica las modificaciones a la copia almacenada en la caché de buffers y lo marca como “sucio” activando un indicador en la cabecera del buffer. Cuando un buffer que contiene un bloque “sucio” es seleccionado para ubicar a otro bloque al no existir buffers libres en la caché, se copia el contenido de dicho buffer en el disco antes de traer al otro bloque. Con ello se mantiene el contenido del disco actualizado.\nCuando un proceso obtiene un buffer lo bloquea para que no pueda ser utilizado por otros procesos. Esto sucede antes de iniciar la operación de E/S al disco o cuando el proceso desea leer o escribir en dicho buffer. Si un buffer ya está bloqueado por un proceso (A) y otro proceso (B) intenta acceder a él, el proceso B pasará al estado dormido hasta que el buffer sea desbloqueado por A. Puesto que el manipulador de las interrupciones del disco puede también intentar acceder al buffer, el núcleo desactiva las interrupciones del disco mientras está intentando adquirir el buffer.El núcleo mantiene una lista de buffers libres usando una estrategia del tipo LRU23. Se trata de una lista circular doblemente enlazada que posee un buffer mudo a modo de cabecera para marcar el principio y el final de la lista. El buffer más cercano a la cabecera es el buffer libre usado menos recientemente, mientras que el buffer situado al final de la lista es el buffer libre usado más recientemente. Cuando el núcleo necesita un buffer libre, toma al buffer más cercano a la cabecera de la lista de buffers libres. En ambos casos, el núcleo borra de la lista de buffers libres el buffer que toma.\nCuando un buffer es liberado el núcleo lo coloca al final de la lista de buffers libres, puesto que en ese momento se trata del buffer usado más recientemente. Conforme el núcleo va extrayendo buffers de la lista, dicho buffer avanzará hacia la cabecera de la lista. Inicialmente, cuando el sistema es arrancado, todos los buffers son colocados en la lista de buffers libres.       Cabecera de la cola de dispersión no 0 [No bloque%4=0]28\n4\n64\n      Cabecera de la cola de dispersión no 1 [No bloque%4=1]17\n5\n97\n    Cabecera de la cola de dispersión no 2 [No bloque%4=2]98\n50\n10\n    Cabecera de la cola de dispersión no 3 [No bloque%4=3]3\n35\n99\n  Cabecera de la lista de buffers libres\n  AQUÍ VA UNA IMAGEN8-4: Implementación de la lista de buffers libres dentro de la caché de buffers\n23 LRU es el acrónimo del término inglés “Least Recently Used”, que significa “usado menos recientemente”.      Cabecera de la lista de buffers libres\n3\n98\n5\n28\n64\n  AQUÍ VA UNA IMAGEN8-5: Detalle de la lista de buffers libres\nEn la AQUÍ VA UNA IMAGEN8-4 se representa un esquema de una caché de buffers de bloques resaltando la lista de buffers libres, mientras que en la AQUÍ VA UNA IMAGEN8-5 se representa esta lista aparte. Se observa que forman parte de esta lista los buffers marcados con 3, 98, 5, 28 y 64. En esta lista el buffer libre usado menos recientemente es el más cercano a la cabecera, es decir, el 3. Asimismo el buffer libre usado más recientemente es el situado al final, es decir, el 64.\nExisten dos excepciones en la gestión de la lista de buffers libres descrita. La primera involucra a los buffers que se han vuelto no válidos debido a un error de E/S o porque los bloques que almacenan pertenecen a un fichero que ha sido borrado o truncado. Tales buffers serán situados inmediatamente a la cabeza de la cola, puesto que está garantizado que no volverán a ser accedidos nuevamente.\nLa segunda excepción involucra a los buffers “sucios” que alcanzan la cabeza de la lista, en dicho instante son eliminados de la lista y colocados en la cola de escritura del manejador del disco. Cuando la escritura se completa, el buffer es marcado como “limpio” y puede ser retornado a la lista de buffers libres. Puesto que ya había alcanzado la cabeza de la lista sin ser accedido de nuevo, es colocado en la cabeza de la lista en vez de al final.\n ## Cabeceras de los buffers\nCada buffer consta de dos partes una cabecera y el bloque de datos que almacena. El núcleo utiliza la cabecera para: identificar y localizar al buffer, sincronizar el acceso al mismo y administrar del comportamiento de la caché. La cabecera de un buffer también se utiliza para pasar parámetros al manejador o driver del disco. Cuando el núcleo desea leer o escribir el buffer en el disco, carga los parámetros de la operación de E/S en la cabecera y pasa esta cabecera al driver del disco. La cabecera contiene toda la información requerida por la operación de disco.\nFormalmente, la cabecera de un buffer está implementada mediante una estructura buf cuyos campos más importantes se listan en la Tabla 8-1. El campo b_flags es un mapa de bits de varios indicadores. Por ejemplo, el núcleo usa los indicadores B_BUSY (bloqueado) y B_WANTED (deseado) para sincronizar el acceso al buffer, el indicador B_DELWRI para marcar un buffer como “sucio” y el indicador B_AGE para marcar a un bufferque es un buen candidato para ser reutilizado. Asimismo el driver del disco también usa otros indicadores, como por ejemplo: B_READ, B_WRITE, B_ASYNC, B_DONE y B_ERROR.\n  Campos\n   Descripción\n int b_flags\nstruct buf *b_forw, *b_back\nstructbuf*av_forw,*av_back\ncadrr_t b_addr\ndev_t b_edev\ndaddr_t b_blkno\nint b_error\nunsigned b_resid\nTabla 8-1: Campos de la estructura buf\n ## Ventajas\nIndicadores del estado del buffer Punteros para mantener el buffer en la cola hash Punterosparamantenerelbufferenla lista de buffers libres\nPuntero al bloque de datos del buffer Número de dispositivo\nNúmero de bloque en el dispositivo Estado de error E/S\nNúmero de bytes que restan por transferir\n                Usar la caché de buffers reduce el tráfico con el disco y elimina las operaciones de E/S al disco innecesarias. Asimismo la caché de buffers sincroniza el acceso a los bloques del disco mediante los indicadores B_BUSY (bloqueado) y B_WANTED (deseado). Si dos procesos intentan acceder al mismo bloque, solo uno será capaz de bloquearlo. Asimismo, la caché de buffer ofrece una interfaz modular entre el driver del disco y el resto del núcleo. Ninguna otra parte del núcleo puede acceder al driver del disco y la interfaz entera está encapsulada en los campos de la cabecera del buffer.\n ## Inconvenientes\nA pesar de sus muchas ventajas, existen algunos inconvenientes importantes en la caché de buffers. En primer lugar, la política de escritura de la caché que es del tipo post- escritura implica que los datos se pueden perder si el sistema se cuelga. Esto podría dejar al disco en un estado inconsistente. En segundo lugar, aunque reducir el acceso al disco mejora el rendimiento del sistema, los datos deben ser copiados dos veces, primero del disco al buffer y después del buffer al espacio de direcciones del usuario. La segunda copia es varios órdenes de magnitud más rápida que la primera y normalmente el ahorro de accesos a disco compensa de sobra la copia adicional memoria-memoria que debe realizarse. Esto puede llegar a ser, sin embargo, un factor importante, cuando se lee o se escribe secuencialmente un fichero grande hasta el final y después no se vuelve a acceder a él de nuevo. De hecho, tal operación crea un problema adicional que es la sustitución de todo el contenido de la caché. Puesto que todos los bloques del fichero son leídos en un periodo de tiempo muy pequeño, consume todos los buffers en la caché, borrando todoslos datos que se encontraban allí almacenados. Esto produce un gran número de fallos en la caché durante un rato, ralentizando al sistema hasta que la caché se llena de nuevo con un conjunto de bloques más útiles. Este problema puede ser evitado si el usuario puede predecirlo. El sistema de ficheros Veritas (VxFS), por ejemplo, permitía al usuario suministrar consejos sobre cómo un fichero debía ser accedido. Usando esta característica, un usuario podía desactivar la carga en la caché de buffers de ficheros grandes y pedirle al sistema de ficheros que transfiriera los datos directamente del disco al espacio de usuario."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "La interfaz nodo-V/SFV",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "un Microsystems introdujo la interfaz nodo-v/sfv (nodo virtual/sistema de ficheros virtual) para suministrar un marco de trabajo en el núcleo que permitiera el acceso y la manipulación de diferentes tipos de sistemas de ficheros. Desde su aparición ha ido ganando una amplia aceptación, SVR4 fue la primera distribución del UNIX System V que incluyó esta interfaz.\nLa interfaz nodo-v/sfv permite al sistema UNIX:\n- Soportar diferentes tipos de sistemas de ficheros locales simultáneamente, tanto\nUNIX (s5fs o ufs24) y no-UNIX (como por ejemplo FAT).\n- Soportar sistemas de ficheros distribuidos. Un sistema de ficheros en una máquina\nremota puede ser accedido de igual forma que un sistema de ficheros local.\n- Presentar al usuario una imagen homogénea (árbol) del sistema de ficheros.\n- Poder añadir al núcleo nuevos sistemas de ficheros de una forma modular.\nEn definitiva, la interfaz nodo-v/sfv es una capa de código del subsistema de ficheros del núcleo (ver AQUÍ VA UNA IMAGEN8-6) que se encarga de traducir cualquier llamada al sistema u operación del núcleo sobre un fichero (o sobre un sistema de ficheros) a la función adecuada según el tipo de sistema de ficheros.\nPor ejemplo, cuando un proceso realiza una llamada al sistema read sobre un fichero, el núcleo en primer lugar invoca a una función contenida en la interfaz nodo-v/sfv\n24 ufs es el acrónimo inglés de UNIX file system que es el nombre que recibió el sistema de ficheros FFS cuando se integró en el sistema el interfaz nodo-v/sfv.asociada a esta llamada al sistema que realiza un primer conjunto de operaciones independientemente del sistema de ficheros al que pertenezca el fichero. A continuación, esta función invoca a otra función cuya implementación depende del sistema de ficheros al que pertenece el fichero que se encarga de realizar la operación de lectura sobre el fichero.\n Interfaz de llamadas al sistema\n    s5fs\nSubsistema de archivos\nInterfaz nodo-v/sfv\n FFS\nDOS\n   Drivers de dispositivos modo carácter\n Drivers de dispositivos modo bloque\nAQUÍ VA UNA IMAGEN8-6: Ubicación de la interfaz nodo-v/sfv dentro del núcleo\n ## Una breve introducción a la programación orientada a objetos\nLa interfaz nodo-v/sfv fue diseñado usando conceptos de programación orientada a objetos. Estos conceptos han sido ampliados a otras áreas del núcleo de UNIX, tales como la administración de memoria, la comunicación basada en mensajes y la planificación de procesos. Por lo tanto se hace necesario revisar brevemente los fundamentos de la programación orientada a objetos en la forma en que se aplica al núcleo de UNIX. Aunque tales técnicas se desarrollan de forma natural mediante lenguajes orientados a objetos tales como C++, los programadores de UNIX han preferido implementarlos en el lenguaje C para ser consistentes con el resto del núcleo de UNIX.\nCaché de buffers\n Control de hardware\nLa aproximación orientada a objetos está basada en la noción de clases y objetos. Una clase es un tipo de dato complejo que consta de campos de datos miembros y un conjunto de funciones miembros. Un objeto es una instancia de una clase. Las funciones miembros de una clase operan sobre los objetos individuales de la clase. Cada miembro (campo de datos o función) de una clase puede ser público o privado. Sólo los miembros públicos son visibles externamente a los usuarios de la clase. Los datos y funciones privados pueden ser únicamente accedidos internamente por las otras funciones de la clase.\nPara una clase cualquiera dada, podemos generar una o más clases derivadas, llamadas subclases (ver AQUÍ VA UNA IMAGEN8-7). Una subclase puede ser en sí misma una base para clases adicionales derivadas, estableciéndose por tanto una jerarquía de clases. Una subclase hereda todos los atributos (datos y funciones) de la clase base. También puede añadir sus propios datos y funciones. Además puede borrar algunas de las funciones de la clase base y suministrar su propia implementación de éstas.\nPuesto que una subclase contiene todos los atributos de la clase base, un objeto del tipo subclase es también un objeto de la clase base. Por ejemplo, la clase directorio puede ser una clase derivada de la clase base fichero. Esto significa que cada directorio es también un fichero. Por lo tanto, un puntero a un objeto directorio es también un puntero a una objeto fichero. Los atributos añadidos por la clase derivada no son visibles por la clase base. Por tanto un puntero a un objeto base no puede ser usado para acceder a los datos y las funciones de la clase derivada.\nClase base\nSubclase\n Datos\n Funciones\n Datos heredados de la clase base\nDatos adicionales de la subclase\nFunciones heredadas de la clase base\n Funciones\nadicionales de la subclase\nFunciones de la clase base redefinidas por la subclase\nAQUÍ VA UNA IMAGEN8-7: Relación entre una clase base y su subclase\nFrecuentemente, se usa una clase base simplemente para representar una abstracción y definir una interfaz, con clases derivadas suministrando implementaciones específicas de las funciones base. Así la clase fichero puede definir una función llamada create(), pero cuando un usuario llama a esta función para un fichero arbitrario, seinvoca a una rutina diferente dependiendo de si el fichero es un fichero regular, un directorio, un enlace simbólico, un fichero de dispositivo, etc. De hecho, se puede no tener una implementación genérica de create() que cree un fichero arbitrario. A tal función se le denomina una función virtual pura.\nLos lenguajes orientados a objetos suministran estos servicios. En C++, por ejemplo, es posible definir una clase base abstracta como aquella que contiene al menos una función virtual pura. Puesto que la clase base no tiene ninguna implementación para esta función, no puede ser instanciada. Puede solamente ser usada para derivar subclases, que suministran implementaciones específicas para las funciones virtuales. Todos los objetos son instancias de una subclase u otra, pero el usuario puede manipularlos usando un puntero a la clase base, sin conocer a qué subclase pertenece. Cuando una función virtual es invocada por tal objeto, la implementación automáticamente determina a qué función específica debe llamar, dependiendo del subtipo actual del objeto.\n ## Perspectiva general de la interfaz nodo-v/sfv\nLa abstracción nodo virtual (nodo-v) representa a un fichero en el núcleo de UNIX. Por su parte, la abstracción sistema de ficheros virtual (sfv) representa a un sistema de ficheros. Ambas son consideradas como clases bases abstractas, a partir de las cuales se pueden derivar subclases que suministran implementaciones específicas para los diferentes tipos de sistemas de ficheros tales como s5fs, ufs, FAT (el sistema de ficheros de MS-DOS),...\nEn C, una clase base es implementada como una estructura más un conjunto de funciones del núcleo globales (y macros) que definen las funciones no virtuales públicas. La clase base contiene un puntero a otra estructura que consiste en un conjunto de punteros a funciones, uno por cada función virtual.\n ###  La clase nodo-v\nLa AQUÍ VA UNA IMAGEN8-8 muestra la clase nodo-v en SVR4. Los campos datos en la base nodo- v contienen información que no depende del tipo de sistema de ficheros. Las funciones miembros pueden ser divididas en dos categorías. La primera es un conjunto de funciones virtuales que define la interfaz dependiente del sistema de ficheros. Cada sistema de ficheros diferente debe suministrar su propia implementación de estas funciones. La segunda es un conjunto de rutinas de utilidad y macros que pueden ser usadas por otros subsistemas del núcleo para manipular los ficheros. Estas funciones a su vuelta llaman a rutinas dependientes del sistema de ficheros para realizar tareas de bajo nivel.La base nodo-v tiene dos campos que permiten implementar subclases. El primero es v_data, que es un puntero (de tipo caddr_t) a una estructura de datos privada que mantiene datos del sistema de ficheros específico del nodo-v. Para s5fs y ufs, esta estructura es simplemente la tradicional estructura inode (nodo-i). NFS utiliza una estructura rnode, etc. Puesto que esta estructura es accedida indirectamente a través de v_data, es opaca a la clase base vnode y sus campos son únicamente visibles a las funciones internas al sistema de ficheros específico.\n Campos de datos (struct vnode)\nFunciones virtuales (struct vnodeops)\nRutinas de utilidad y macros\n v_count v_data v_type v_op v_vfsmountedhere ...\n  vop_open\nvop_read\nvop_getattr\nvop_lookup vop_mkdir ...\n vn_open VN_HOLD vn_link VN_RELE ...\nDatos privados dependientes del sistema de ficheros\nImplementación dependiente del sistema de ficheros\nde las funciones vnodeops\n   AQUÍ VA UNA IMAGEN8-8: La abstracción nodo-v\nEl campo v_op apunta a la estructura vnodeops, que consta de un conjunto de punteros a las funciones que implementan el interfaz virtual del nodo-v. Tanto el campo v_data como el campo v_op son configurados cuando el nodo-v es inicializado, típicamente durante una llamada al sistema open o creat. Cuando el código independiente del sistema de ficheros llama a una función virtual para un nodo-v arbitrario, el núcleo usando el puntero v_op llama a la función correspondiente de la implementación del sistema de ficheros adecuada. Por ejemplo, la operación VOP_CLOSE permite al proceso invocador cerrar el fichero asociado con el nodo-v, que es accedida mediante una macro. Una vez que los nodos-v han sido apropiadamente inicializados, esta macro asegura que invocando a la operación VOP_CLOSE se llamaría a la rutina ufs_close para un fichero ufs, a la rutina nfs_close para un fichero NFS, etc. De forma general un objeto nodo-v se implementa mediante la siguiente estructura de dato:\n   struct vnode  {...\n};"
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "La interfaz nodo-V/SFV 2",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},
"content": "###  La clase sfv",
"code_url": "ejemplo_8-7-2"     }
},
{
"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "La interfaz nodo-V/SFV 3",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Nodos virtuales y ficheros abiertos\nstruct vnode\nnodo-v de “/”\ndel sistema de ficheros montado\nv_vfsp v_vfsmountedhere ...\nEl nodo virtual (nodo-v) es la abstracción fundamental que representa a un fichero activo en el núcleo. Define la interfaz al fichero y canaliza todas las operaciones sobre el fichero a las funciones específicas del sistema de ficheros apropiado. Hay dos formas mediante las cuales el núcleo accede a un nodo-v. La primera es mediante las llamadas al sistema asociadas a E/S, que localizan el nodo-v a través de su descriptor de fichero, como se describirá en esta sección. La segunda es mediante las rutinas de análisis de rutas de acceso (ver sección 8.10.5), que utilizan las estructuras de datos dependientes del sistema de ficheros para localizar el nodo-v.\nvfs_next vfs_vnodecovered ...\n VROOT\nv_vfsp v_vfsmountedhere ...\n AQUÍ VA UNA IMAGEN8-11: Estructuras independientes del sistema de ficheros\nUn proceso debe abrir un fichero antes de leer o escribir en él. La llamada al sistema open devuelve un descriptor de fichero al proceso invocador. Este descriptor, que es típicamente un entero pequeño, actúa como un manejador para el fichero y representa una sesión independiente, o flujo, para el fichero. El proceso debe pasar el descriptor a las llamadas al sistema write o read que realice.\nLa tabla de descriptores del fichero es un objeto para cada proceso, que contiene un índice de los archivos que tiene abiertos un proceso (incluyendo los ficheros especiales de entrada, salida y error estándar stdin, stdout, stderr respectivamente). La tabla se encuentra indexada por su descriptor de fichero abierto y contiene un puntero (ver AQUÍ VA UNA IMAGEN8-11) a un objeto de fichero abierto (struct file). Asimismo, contiene un conjunto de indicadores por descriptor. Entre los indicadores implementados se encuentran FCLOSEXEC, que pide al núcleo que cierre el descriptor cuando el proceso invoca a la llamada al sistema exec y U_FDLOCK que se utiliza para bloquear el fichero.\nEl objeto de fichero abierto almacena la información necesaria que permite administrar una sesión con el fichero. Si varios usuarios tienen el fichero abierto (o el mismo usuario lo ha abierto varias veces), cada uno tiene su propio objeto de fichero abierto. Sus campos incluyen:\nPuntero de lectura/escritura desde el origen del fichero, para indicar donde debe comenzar la siguiente operación de lectura o escritura sobre el fichero.Contador de referencias que indica el número de descriptores de ficheros que apuntan a él. Normalmente es 1, pero podría ser mayor si los descriptores son clonados mediante dup o fork.\nPuntero al nodo-v del fichero.\nModo de apertura del fichero. El núcleo comprueba este modo en cada operación de E/S. Por tanto si un usuario ha abierto un fichero de sólo lectura, él no podrá escribir en el fichero usando este descriptor incluso aunque tenga los privilegios necesarios.\nLos sistemas UNIX tradicionales usan una tabla de descriptores de ficheros de tamaño fijo y estática que se aloja en el área U. El descriptor devuelto al usuario es un índice dentro de esta tabla. El tamaño de la tabla (típicamente 64 elementos) limita el número de ficheros que el usuario puede tener abiertos al mismo tiempo. En los sistemas UNIX modernos, la tabla de descriptores puede tener un tamaño mucho mayor.\nAlgunas implementaciones, tales como SVR4 o SunOS, alojan los descriptores en tablas de 32 entradas normalmente y guardan estas tablas en listas enlazadas, con la primera tabla alojada en el área U del proceso. De este modo, en vez de simplemente usar el descriptor como un índice en una única tabla, el núcleo primero tiene que localizar la tabla apropiada y después acceder a la entrada adecuada dentro de dicha tabla. Este esquema elimina las restricciones sobre el número de ficheros que un proceso puede tener abierto, pero aumenta la complejidad del código y disminuye el rendimiento del sistema.\nAlgunas nuevas distribuciones basadas en SVR4 alojan la tabla de descriptores dinámicamente y la extienden cuando es necesario llamando a la rutina kmen_realloc(), que o extiende la tabla en el mismo lugar o la copia en una nueva localización donde su espacio haya aumentado.\n ## El contador de referencias del nodo-v\nEl campo v_count del nodo-v mantiene un contador de referencias que determina hasta cuándo el nodo-v debe permanecer en el núcleo. Un nodo-v es alojado y asignado a un fichero cuando el fichero es accedido por primera vez. Por lo tanto, otros objetos pueden mantener punteros, o referencias, a este nodo-v y esperar para acceder al nodo-v usando el puntero. Esto significa que si esta referencia existe, el núcleo debe retener el nodo-v y no reasignarlo a otro fichero.Este contador de referencias es una de las propiedades genéricas de un nodo-v y es manipulado por el código independiente del sistema de ficheros. Dos macros, VN_HOLD y VN_RELE, incrementan y decrementan el contador de referencias, respectivamente. Cuando el contador de referencias alcanza el valor 0, el fichero está inactivo y el nodo-v puede ser liberado o reasignado.\nEs importante distinguir entre referencia y bloqueo. Bloquear un objeto impide que otros procesos accedan a él de una cierta forma, dependiendo de si el bloqueo es exclusivo o de lectura/escritura. Mantener una referencia a un objeto simplemente asegura la persistencia del objeto. El código independiente del sistema de ficheros bloquea un nodo- v durante periodos de tiempo cortos, típicamente durante la duración de una única operación sobre un nodo-v. Una referencia es típicamente mantenida durante un tiempo largo, no solamente a través de múltiples operaciones con el nodo-v sino también a través de multiples llamadas al sistema. Algunas de las operaciones que requieren la referencia de un nodo-v son:\nLa apertura de un fichero requiere la adquisición de una referencia, en consecuencia el contador de referencias del nodo-v se incrementa. Por el contrario cerrar el fichero libera la referencia, es decir, se decrementa el contador de referencias del nodo-v.\nUn proceso siempre mantiene una referencia a su directorio de trabajo actual. Cuando el proceso cambia de directorio de trabajo, adquiere una referencia al nuevo directorio y libera la referencia al directorio viejo.\nCuando un nuevo sistema de ficheros es montado, adquiere una referencia al directorio de punto de montaje. Desmontar el sistema de ficheros libera dicha referencia.\nLa rutina de análisis de rutas de acceso adquiere una referencia en cada directorio intermedio que se encuentra en su búsqueda. Mantiene la referencia mientras busca el directorio y la libera después de adquirir una referencia al siguiente componente de la ruta.\nEl contador de referencias asegura la persistencia del nodo-v y también del fichero que subyace. Cuando un proceso borra un fichero que otro proceso (o quizás el mismo proceso) había abierto, el fichero no se borra físicamente. La entrada del directorio de dicho fichero es eliminada, así que nadie más puede abrirlo usando el nombre borrado. El fichero en sí mismo continúa existiendo puesto que el nodo-v tiene un contador de referencias distinto de cero. Los procesos que actualmente tenían el fichero abierto pueden continuar accediendo a él hasta que lo cierren. Cuando la última referencia sea liberada, el códigoindependiente del sistema de ficheros invocará la operación VOP_INACTIVE para completar el borrado del fichero. Para un fichero ufs o s5fs, por ejemplo, el nodo-i y los bloques de datos serán liberados en este momento."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "El sistema de ficheros del unix system v (s5fs) ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Organización en el disco del s5fs\nEl sistema de ficheros reside en un único disco lógico o partición y cada disco lógico puede contener un sistema de ficheros como máximo. Cada sistema de ficheros está autocontenido y completo, con su propio directorio raíz, subdirectorios, ficheros y todos sus datos y metadatos asociados. El árbol de ficheros que es visible por el usuario está formado por la unión de uno o varios de estos sistemas de ficheros.\nLa AQUÍ VA UNA IMAGEN8-12 muestra la estructura de una partición de disco para el sistema de ficheros del UNIX System V (s5fs). Una partición puede ser vista desde un punto de vista lógico como un array lineal de bloques. El tamaño de un bloque de disco es 512 bytes multiplicado por alguna potencia de dos (diferentes versiones han usado bloques de 512, 1024 o 2048 bytes). El número de bloque físico (o simplemente el número de bloque) es un índice dentro de este array, e identifica de forma única a un bloque en una partición de disco dada. Este número debe ser traducido por el manejador o driver del disco en cilindro, pista y número de sector. La traducción depende de las características físicas del disco (número de cilindros y pistas, sectores por pista, etc) y la localización de la partición en el disco.\nArea de arranque Superbloque\nBS\nAQUÍ VA UNA IMAGEN8-12: Estructura en el disco del s5fs\nAl comienzo de la partición se encuentra el área de arranque, que puede contener el código requerido para arrancar (carga e inicialización) el sistema operativo. De todas las particiones existentes solamente una de ellas necesita contener esta información, posiblemente el resto de particiones tendrá su área de arranque vacía.\nA continuación del área de arranque se encuentra el superbloque, que contiene atributos y metadatos del propio sistema de ficheros. A continuación del superbloque se\n  Lista de nodos-i\n Bloques de datosencuentra la lista de nodos-i, que es un array lineal de nodos-i. Hay un nodo-i por cada fichero. Cada nodo-i puede ser identificado por su número de nodo-i, que es igual al índice en la lista de nodos-i. El tamaño de un nodo-i es 64 bytes, luego varios nodos-i se pueden almacenar dentro de un bloque de disco.\nLa lista de nodos-i tiene un tamaño fijo (que se conAQUÍ VA UNA IMAGENcuando se crea el sistema de ficheros en esta partición) que limita el número máximo de ficheros que la partición puede contener. El espacio después de la lista de nodos-i es el área de datos, que contiene bloques de datos para ficheros y directorios, así como bloques indirectos, que contienen punteros para bloques de datos de ficheros."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "code",
"name": "## Directorios",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},
"content": "",
"code_url": "ejemplo_8-8-2"     }
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "El sistema de ficheros del unix system v (s5fs) 2",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,"content": ""
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Comprobación del estado de un sistema de ficheros",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "iertos programas tales como newfs o mkfs permiten crear un sistema de ficheros UNIX en un disco físico. Para evitar errores con cierta frecuencia se debe revisar el sistema de ficheros para verificar su consistencia y asegurar que todos sus bloques son accesibles. Esto se consigue con el programa fsck. Su sintaxis es la siguiente:\n$ fsck [-opciones] [sistema...]Fsck revisa y repara de forma interactiva las posibles inconsistencias que encuentra en los sistemas de ficheros UNIX. En el caso de que no existan inconsistencias, fsck informa sobre el número de ficheros, número de bloques usados y número de bloques libres de que dispone el sistema. Si el sistema presenta inconsistencias, fsck proporciona mecanismos para corregirlo.\nFsck revisa los sistemas de ficheros que se le indican en la línea de órdenes. Si no se especifica ningún sistema, fsck revisa los sistemas que se especifican en la tabla de montaje.\nLas inconsistencias que revisa fsck son las siguientes:\n- Bloques reclamados por más de un nodo-i o la lista de bloques libres.\n- Bloques reclamados por un nodo-i o la lista de bloques libres, pero que están fuera del rango del sistema.\n- Contadores de enlaces incorrectos.\n- Número de bloques demasiado grande y tamaño de directorios inadecuados.\n- Formato inadecuado para los nodos-i.\n- Bloques no registrados por nadie (nodos-i, lista de bloques libres, etc).\n- Revisión de los directorios en busca de ficheros que apuntan a nodos-i no asignados o números de nodo-i fuera de rango.- Existencia en el superbloque de más bloques para nodos-i de los que hay en el sistema de ficheros.\n- Formato incorrecto de la lista de bloques libres.\n- Total de bloques libres o contador de nodos-i incorrecto.\nSi fsck encuentra un fichero o directorio cuyo directorio padre no puede determinarse, colocará el fichero huérfano en el directorio lost+found perteneciente al sistema que se está revisando. Puesto que el nombre del fichero se registra en su directorio home y éste es desconocido, a la hora de guardarlo en lost+found se nombrará con su número de nodo-i.\nAparte de revisar un sistema de ficheros recién creado fsck se utiliza principalmente para revisar sistemas estropeados por alguna causa accidental como una parada imprevista del sistema. El núcleo mantiene copias en memoria tanto del superbloque como de algunos nodos-i (nodos-im). Además el acceso a disco se realiza a través de la caché de buffers de bloques de disco. Esto crea inconsistencias de contenido entre el disco y la memoria. Estas inconsistencias se corrigen periódicamente con la intervención de los procesos demonio syncer o update que se encargan de invocar a la llamada al sistema sync para actualizar el disco con la memoria. Si por cualquier circunstancia el sistema deja de funcionar antes de que se produzca una actualización, la próxima vez que se intente utilizar ese sistemas de ficheros, será necesario repararlo dentro de lo posible con la ayuda de fsck."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Consideraciones adicionales sobre la interfaz nodo-v/sfv del SVR4 ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Partes dependientes del sistema de ficheros de un objeto nodo-v\nEl nodo-v es un objeto abstracto que no puede existir por sí solo sino que debe ser instanciado en el contexto de un fichero específico. Los campos v_op y v_data del nodo- v enlazan a la parte dependiente del sistema de ficheros. v_data apunta a una estructura de datos privada que mantiene información dependiente del sistema de ficheros. La estructura de datos depende del sistema de ficheros al que pertenece el fichero, por ejemplo para ficheros s5fs y ufs se utiliza la estructura que define su nodo-i.\nv_data es un puntero opaco, lo que significa que el código independiente del sistema de ficheros no puede directamente acceder al objeto dependiente del sistema deficheros. El código dependiente del sistema de ficheros, sin embargo, sí que puede acceder a los objetos nodo-v base. Se necesita, por lo tanto, una forma de localizar al nodo-v a través del objeto de datos privado. Puesto que los dos objetos son siempre asignados conjuntamente, es eficiente combinarlos en uno solo. De esta forma en las implementaciones estándar de la referencia de la capa del nodo-v, el nodo-v es simplemente una parte del objeto dependiente del sistema de ficheros.\nPor otra parte, la interfaz del nodo-v define un conjunto de operaciones sobre un fichero genérico. El código independiente del sistema de ficheros manipula el fichero usando estas operaciones únicamente. Este código no puede acceder a los objetos dependientes del sistema de ficheros directamente. La estructura vnodeops, que implementa esta interfaz se define de la siguiente forma:\nstruct vnodeops{int (*vop_open)(); int (*vop_close)(); int (*vop_read)(); int (*vop_write)(); int (*vop_create)(); int (*vop_remove)(); int (*vop_link)(); int (*vop_mkdir)(); int (*vop_rmdir)(); int (*vop_lookup)(); int (*vop_inactive)(); int (*vop_rwlock)(); int (*vop_rwunlock)(); int (*vop_getpage)(); ...\n};\nCada sistema de ficheros implementa esta interfaz de una forma distinta suministrando su propio conjunto de funciones. Por ejemplo, ufs implementa la operaciónVOP_READ leyendo el fichero del disco local mientras que NFS envía una petición a un servidor remoto para obtener el dato. Por lo tanto cada sistema de ficheros suministra una instancia de la estructura vnodeops, por ejemplo, ufs define el objeto:\nstruct vnodeops ufs_vnodeops = { ufs_open,ufs_close, ...\n};\nEl campo v_op del nodo-v apunta a la estructura vnodeops para el tipo de sistema de ficheros asociado. Como se muestra en la AQUÍ VA UNA IMAGEN8-19, todos los ficheros del mismo tipo de sistema de ficheros comparten una misma instancia de esta estructura y acceden al mismo conjunto de funciones.\nstruct inode struct inode struct inode\nStruct vnodeops\nAQUÍ VA UNA IMAGEN8-19: Objetos de un nodo-v dependientes del sistema de ficheros\nComo el nodo-v, el objeto sfv tiene punteros a sus datos privados y a su vector de operaciones. El campo vfs_data es un puntero opaco que apunta a una estructura de datos por cada sistema de ficheros. A diferencia de los nodos-v, el objeto sfv y su estructura de datos privada normalmente se asignan por separado. El campo vfs_op apunta a una estructura vfsops, que se define de la siguiente forma:\nstruct vfsops { int (*vfs_mount)(); int (*vop_unmount)();\n   i_vnode:\ni_vnod:\n  v_data v_op ...\nv_data v_op ...\ni_vnode:\nv_data v_op ...\n     ufs_open ufs_close ...\nnfs_open nfs_close ...\nint (*vop_root)(); int (*vop_statvfs)(); int (*vop_sync)(); ...\n};\n   struct ufs_vfsdata\nstruct ufs_vfsdata\nCada tipo de sistema de ficheros suministra su propia implementación de estas operaciones. Por lo tanto existe una instancia de la estructura vfsops por cada tipo de sistema de ficheros: ufs_vfsops para ufs, nfs_vfsops para NFS, etc. La AQUÍ VA UNA IMAGEN8-20 muestra las estructuras de datos de la capa sfv para un sistema que contiene dos sistemas de ficheros del tipo ufs y un sistema de ficheros del tipo NFS.\n ## El conmutador del sistema de ficheros virtual\nEL SVR4 mantiene una tabla global denominada conmutador del sistema de ficheros virtual que contiene una entrada por cada tipo de sistema de ficheros existente en el sistema. En cada entrada se almacena una estructura vfssw, cuya definición es:\nstruct vfssw {char *vsw_name; /* Tipo del sistema de ficheros */ int (*vsw_init)(); /* Dirección de la rutina de\ninicialización */\nstruct vfsops *vsw_vfsops; /* Vector de operaciones para este sistema de ficheros*/\nstruct vfs\nstruct vfsops\n  AQUÍ VA UNA IMAGEN8-20: Estructuras de datos de la capa sfv\nstruct mntinfo\n   vfs_data vfs_next vfs_op ...\nvfs_data vfs_next vfs_op ...\nvfs_data vfs_next vfs_op ...\n   rootvfs\nufs_mount ufs_unmount ...\nnfs_mount nfs_unmount ...\n} vfssw[];\nEl núcleo usa esta tabla para poder encaminar hacia las implementaciones específicas de cada sistema de ficheros las operaciones sobre los objetos nodo-v y sfv.\n ## Implementación de mount\nLa llamada al sistema mount obtiene el nodo-v del directorio punto de montaje llamando a la rutina lookuppn(). Esta rutina comprueba que el nodo-v representa a un directorio y que no existe ningún otro sistema de ficheros montado en sobre él. Después busca la tabla vfssw[] para encontrar la entrada que se ajusta al nombre dado por el argumento tipo.\nUna vez localizada la entrada en esta tabla, el núcleo invoca a su operación vsw_init, que llama a una rutina de inicialización específica del sistema de ficheros que asigna las estructuras de datos y los recursos necesarios para operar con el sistema de ficheros. A continuación, el núcleo asigna una nueva estructura vfs y la inicializa de la siguiente forma:\nAñade la estructura a la lista enlazada encabezada por rootvfs.\nConAQUÍ VA UNA IMAGENel campo vfs_ops para apuntar al vector vfsops especificado en la\nentrada de la tabla de conmutación.\nConAQUÍ VA UNA IMAGENel campo vfs_vnodecovered para apuntar al nodo-v del directorio punto de montaje.\nDespués el núcleo almacena un puntero a la estructura vfs en el campo v_vfsmountedhere del nodo-v del directorio cubierto. Finalmente invoca a la operación VFS_MOUNT del sfv para realizar el procesamiento dependiente del sistema de ficheros de la llamada mount.\n ## ProcesamientoVFS_MOUNT\nCada sistema de ficheros suministra su propia función para implementar la operación\nVFS_MOUNT. Esta función debe realizar las siguientes operaciones:\n- Verificar permisos para la operación.\n- Asignar e inicializar el objeto de datos privados del sistema de ficheros.\n- Almacenar un puntero a este objeto en el campo vfs_data del objeto sfv.\n- Acceder al directorio raíz del sistema de ficheros e inicializar su nodo-v en memoria. La única forma de que el núcleo acceda a la raíz de un sistema de ficheros montado es mediante la operación VFS_ROOT. La parte de sfv dependiente del sistema de ficheros debe mantener la información necesaria para localizar el directorio raíz.\nTípicamente, los sistemas de ficheros locales pueden implementar VFS_MOUNT leyéndola en los metadatos del sistema de ficheros (como por ejemplo el superbloque en el s5fs) desde el disco, mientras que los sistemas de ficheros distribuidos pueden enviar una petición de montaje remoto al servidor.\n ## Análisis de rutas de acceso\nLa función independiente del sistema de ficheros lookuppn() traduce una ruta de acceso y devuelve un puntero al nodo-v del fichero deseado. También establece una referencia sobre este nodo-v. El punto de comienzo del análisis de la ruta de acceso depende de si ésta es relativa o absoluta. Para rutas de acceso relativas, lookuppn() comienza en el directorio de trabajo actual, obteniendo el puntero a su nodo-v del área U. Para rutas absolutas, comienza en el directorio raíz, cuyo puntero a su nodo-v se encuentra en la variable global rootdir.\nlookuppn()incrementa el contador de referencias del nodo-v del directorio de comienzo de la búsqueda, y después ejecuta un bucle para ir analizando de uno en uno cada componente de la ruta de acceso. En cada iteración del lazo debe realizar las siguientes tareas:\n- Asegurarse de que el nodo-v es un directorio (excepto si se ha alcanzado el último componente de la ruta). El campo v_type en el nodo-v contiene esta información.\n- Si el componente es “..” y el directorio actual es el raíz del sistema, se pasa a analizar el siguiente componente de la ruta. El directorio raíz del sistema actúa como su propio directorio padre.- Si el componente es “..” y el directorio actual es el directorio raíz de un sistema de ficheros montado, accede al directorio punto de montaje. Si un directorio es raíz de un sistema de ficheros entonces tendrá su indicador VROOT activado. El campo v_vfsp apunta a la estructura vfs para dicho sistema de ficheros, que contiene un puntero al punto de montaje en el campo vfs_vnodecovered.\n- Invocar a la operación VOP_LOOKUP sobre este nodo-v, que realiza una llamada a la función de búsqueda específica del sistema de ficheros al que pertenezca (s5lookup() para s5fs, ufs_lookup() para ufs, etc). Esta función busca el componente de la ruta dentro del directorio, y si lo encuentra devuelve un puntero al nodo-v de dicho fichero (alojándolo en el núcleo si no estaba ya alojado allí). También establece una referencia sobre este nodo-v.\n- Si el componente no fue encontrado, comprueba si se trataba del último componente de la ruta. Si es así, finaliza con éxito devolviendo un puntero al directorio pero sin eliminar la referencia que había creado. En caso contrario devuelve el error ENOENT.\n- Si el nuevo componente es un punto de montaje (para ello comprueba que el valor almacenado en v_vfsmountedhere es distinto del valor nulo) sigue el puntero al objeto sfv del sistema de ficheros montado e invoca su operación vfs_root para obtener el nodo-v del directorio raíz de este sistema de ficheros.\n- Si el nuevo componente es un enlace simbólico (v_type==VLNK), se invoca a su operación VOP_SYMLINK para traducir el enlace simbólico. Se adjunta el resto de la ruta de acceso a los contenidos del enlace y se reinicia la iteración. Si el enlace contiene una ruta de acceso absoluta, la búsqueda debe retomarse desde el directorio raíz del sistema.\n- Libera el directorio si ya ha finalizado la búsqueda. La referencia fue realizada por la operación VOP_LOOKUP. Para el punto de comienzo de la búsqueda, la referencia fue obtenida de forma explícita por lookuppn().\n- Finalmente, vuelve al principio del lazo y busca el siguiente componente en el directorio representado por el nuevo nodo-v.- El análisis termina cuando ya no quedan más componentes en la ruta, o si un componente no fue encontrado. Si la búsqueda se realizó con éxito, no libera la referencia del nodo-v final y devuelve al proceso invocador un puntero a este nodo-v.\n ## La caché de búsqueda de nombres en directorios\nLa caché de búsqueda de nombres en directorios es un recurso global del núcleo disponible para todos los sistemas de ficheros que deseen utilizarlo. Se trata de una caché software LRU de objetos que contienen: un puntero al nodo-v de un directorio, el nombre de un fichero en este directorio, y un puntero al nodo-v de dicho fichero.\nSi un sistema de ficheros desea utilizar la caché de búsqueda de nombres en directorios, su función de búsqueda, es decir aquella que implementa la operación VOP_LOOKUP, primero busca el nombre deseado en la caché. Si lo encuentra, simplemente incrementa el contador de referencias del nodo-v y se lo devuelve al proceso invocador. De esta forma se evita buscar en el directorio y por lo tanto se ahorra varias lecturas a disco.\nLos aciertos en la caché son bastante probables puesto que los programadores típicamente hacen varias peticiones de unos pocos ficheros y directorios que se utilizan frecuentemente. En el caso de un fallo en la caché, la función de búsqueda específica de cada sistema de ficheros buscará el nombre en el directorio padre. Cuando la componente es encontrada, se añade una nueva entrada en la caché de nombres con la información adecuada por si es necesitada de nuevo en el futuro.\n ## La operación VOP_LOOKUP\nVOP_LOOKUP es la interfaz a la función específica del sistema de ficheros que busca una componente de una ruta de acceso en un directorio. Se invoca a través de una macro de la siguiente forma:\nerror=VOP_LOOKUP(vp,componente,&tvp,...);\ndonde vp es un puntero al nodo-v del directorio padre y componente es el nombre de un componente en la ruta de acceso. Si se ejecuta con éxito, tvp debe apuntar al nodo- v de componente y su contador de referencias debe ser incrementado.\nComo otras operaciones en esta interfaz, esto resulta en una llamada a un función de búsqueda de un sistema de ficheros específico. Usualmente, esta función busca elnombre en la caché de búsqueda de nombres en directorios. Si se produce un acierto, incrementa el contador de referencias y devuelve el puntero al nodo-v. En caso de fallo, busca el nombre en el directorio padre. Los sistemas de ficheros locales implementan la búsqueda iterando a través de las entradas del directorio bloque a bloque. Los sistemas de ficheros distribuidos envían una petición de búsqueda al nodo del servidor.\nSi el directorio contiene el nombre que se buscaba, la función de búsqueda comprueba si el nodo-v del fichero se encuentra ya en memoria. Cada sistema de ficheros tiene su propio método para mantener la pista de sus objetos en memoria. En ufs, por ejemplo, la búsqueda en el directorio resulta en un número de nodo-i, que ufs utiliza como índice de búsqueda para buscar el nodo-i en una tabla de dispersión. El nodo-im en memoria contiene el nodo-v. Si el nodo-v es encontrado en memoria, la función de búsqueda incrementa su contador de referencias y retorna a su invocador.\nA menudo la búsqueda en el directorio produce un acierto, pero el nodo-v no está en memoria. La función de búsqueda debe asignar e inicializar un nodo-v, así como las estructuras de datos privados dependientes del núcleo. Usualmente, el nodo-v es parte de la estructura de datos privados, y por lo tanto ambos son alojados como una sola unidad. Los dos objetos son inicializados leyendo los atributos del fichero. El campo v_op del nodo- v es configurado para que apunte al vector vnodeops para este sistema de ficheros, y una referencia es añadida al contador de referencias v_count del nodo-v. Finalmente, la función de búsqueda añade una entrada a la caché de búsqueda de nombres en directorios y la sitúa al final de la lista LRU de la caché.\n ## Apertura de un fichero\nLa implementación de open es tratada casi por completo en la capa independiente del sistema de ficheros. El algoritmo es el siguiente:\nAsignar un descriptor de fichero.\nAsignar un objeto de fichero abierto (struct file) y almacenar un puntero a él en el descriptor del fichero. SVR4 asigna este objeto dinámicamente. Las distribuciones anteriores utilizaban una tabla estática de tamaño fijo (tabla de archivos).\nLlamar a lookuppn()para analizar la ruta de acceso y devolver el nodo-v del fichero para ser abierto. lookuppn() también devuelve un puntero al nodo-v del directorio padre.\nComprobar el nodo-v (mediante la invocación de su operación VOP_ACCESS) para asegurarse de que el invocador tiene los permisos necesarios para el tipo de acceso deseado.\nComprobar que no se realizan ciertas operaciones ilegales, tales como abrir un directorio o un fichero ejecutable activo para escribir (de lo contrario, el usuario ejecutando el programa obtendría resultados inesperados).\nSi el fichero no existe, comprobar si la opción O_CREAT estaba especificada. Si es así, invocar VOP_CREATE sobre el directorio padre para crear el fichero. En caso contrario, devolver el código de error ENOENT.\nInvocar la operación VOP_OPEN de este nodo-v para realizar el procesamiento dependiente del sistema de ficheros. Típicamente esta rutina no hace nada, pero algunos sistemas de ficheros pueden desear realizar tareas adicionales en este momento. Por ejemplo, el sistema de ficheros specfs, que trata todos los ficheros de dispositivo, podría desear llamar a la rutina open de un driver de dispositivo.\nSi la opción O_TRUNC ha sido especificada, invocar a VOP_SETATTR para configurar el tamaño del fichero a 0. El código dependiente del sistema de ficheros realizará las operaciones de limpieza necesarias tales como liberar los datos de bloques del fichero.\nInicializar el objeto de fichero abierto. Almacenar el puntero al nodo-v y los indicadores del modo de apertura en su interior, configurar su contador de referencias a 1 y su puntero de desplazamiento a 0.\nFinalmente, retornar el índice del descriptor de fichero al usuario.\nConviene darse cuenta de que lookuppn() incrementa el contador de referencias en el nodo-v y también inicializa su puntero v_op. Esto asegura que las siguientes llamadas al sistema puedan acceder al fichero usando el descriptor del fichero (el nodo-v permanece en memoria) y que las funciones dependientes del sistema de ficheros estarán adecuadamente encaminadas."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "El sistema de ficheros FFS (o UFS)",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "os problemas que presenta el sistema de ficheros s5fs condujeron al desarrollo de un nuevo sistema de ficheros en el UNIX BSD. Se trata del sistema de ficheros FFS (Fast File System) también conocido como sistema de ficheros UFS (Universal File System) que fue incorporado por primera vez en el BSD4.2.\n     \n ## Organización\nLas unidades de disco son el principal soporte de la memoria secundaría del computador y en ellos se ubica el sistema de archivos. El número de platos o discos de grabación en una unidad de disco varía en función de su capacidad. Todos los discos de una unidad de disco, giran a la misma velocidad constante (típicamente 3600 rpm). Los datos se leen o se escriben mediante cabezas de lectura/escritura montadas de forma que contacten con la parte del disco que contiene los datos. Cada disco tiene dos superficies (o caras) por lo que existen dos cabezas de lectura y escritura para cada disco. Los datos se almacenan en las superficies magnéticas del disco en forma de círculos concéntricos llamados pistas. Se llama cilindro al conjunto de pistas de todas las superficies de todos los discos de la unidad que se encuentran situadas a la misma distancia del eje de rotación del disco. Las pistas se dividen en sectores y cada sector contiene varios centenares de bytes.\nUna partición de un disco se compone de un conjunto de cilindros consecutivos del disco. Asimismo, una partición formateada contiene un sistema de ficheros. Un sistema de ficheros FFS divide adicionalmente la partición en uno o más grupos de cilindros, cada uno de los cuales contiene un pequeño conjunto de cilindros consecutivos llamados exents. Esto permite a UNIX almacenar datos relacionados en el mismo grupo de cilindros, disminuyendo así los movimientos de la cabeza lectora del disco.\nEl superbloque de un sistema de ficheros FFS contiene información sobre el sistema de ficheros completo, como por ejemplo, el número, tamaño y posición de cada grupo de cilindros, el tamaño de un bloque, el número total de bloques y nodos-i, etc. Adicionalmente, cada grupo de cilindros tiene una estructura de datos que contiene información sobre el grupo, incluyendo las listas de nodos-i libres y de bloques libres. Los datos del superbloque son muy importantes y deben ser protegidos de posibles errores del disco. Por ello, aparte de ubicarse el superbloque en su localización habitual, es decir, al comienzo de una partición (después del área de arranque), cada grupo de cilindros contiene una copia del superbloque. FFS mantiene estas copias en diferentes posiciones en cada grupo de cilindros de tal forma que ninguna pista, cilindro o plato contenga todas las copias del superbloque. El espacio entre el comienzo de un grupo de cilindros y la copia del superbloque es utilizada para bloques de datos, excepto en el caso del primer grupo de cilindros.\nEs conocido que si el tamaño de los bloques de datos de un disco es grande se mejora el rendimiento del sistema ya que se estarían transmitiendo más datos en unaoperación de E/S. Sin embargo, se desperdiciaría más espacio (en promedio, cada fichero desperdicia medio bloque). FFS intenta mejorar el rendimiento del sistema y disminuir el espacio desperdiciado dividiendo los bloques en fragmentos. En FFS, aunque todos los bloques en un sistema de ficheros deben tener el mismo tamaño, diferentes sistemas de ficheros en la misma máquina pueden tener diferentes tamaños de bloques. El tamaño de un bloque es una potencia de dos mayor o igual a 4096. La mayoría de las implementaciones añaden un límite superior de 8192 bytes. Este valor es mucho más grande que el usado en s5fs (512 o 1024), además incrementa la productividad permitiendo ficheros tan grande como 232 bytes (4 Gbytes) que son direccionados con dos niveles de indirección únicamente. FFS no utiliza la indirección triple, aunque algunas variantes soportan tamaños de ficheros mayores de 4 Gbytes.\nLos sistemas UNIX típicos tienen numerosos ficheros pequeños que requieren ser almacenados eficientemente. Un tamaño de bloque de 4 Kbytes desperdicia mucho espacio en el caso de estos ficheros. FFS resuelve este problema permitiendo que cada bloque sea dividido en dos o más fragmentos. El tamaño de un fragmento es fijo para un sistema de ficheros y se especifica cuando se crea dicho sistema. El número de fragmentos por bloque puede ser configurado a 1, 2, 4 o 8 permitiendo un límite inferior de 512 bytes, el mismo que el tamaño de un sector del disco. Cada fragmento puede ser individualmente direccionado y asignado. Para ello es necesario sustituir la lista de bloques libres por un mapa de bits con un bit por fragmento.\nUn fichero FFS está compuesto por completo por bloques de disco, excepto en el caso del último bloque, que puede contener uno o más fragmentos consecutivos. El bloque de un fichero debe estar completamente contenido dentro de un único bloque de disco. Incluso si dos bloques de disco adyacentes tiene suficientes fragmentos libres consecutivos para almacenar un bloque de un fichero, ellos no se pueden combinar. Adicionalmente, si el último bloque de un fichero contiene más de un fragmento, éstos deben ser contiguos y parte del mismo bloque.\nEste esquema reduce el desperdicio de espacio pero produce un duplicado ocasional de datos del fichero. Considérese un fichero llamado prueba cuyo último bloque ocupa un único fragmento. Los fragmentos restantes de ese bloque pueden ser asignados a otros ficheros. Si prueba aumenta su tamaño en otro fragmento, será necesario encontrar otro bloque con dos fragmentos libres consecutivos. El primer fragmento debe ser copiadodesde su posición original y el segundo rellenado con los nuevos datos. Si prueba crece usualmente en pequeños incrementos, sus fragmentos pueden tener que ser copiados varias veces, empeorando el rendimiento del sistema. FFS controla este problema forzando a que los fragmentos únicamente puedan ser contenidos por bloques con direccionamiento directo.\n ## Políticas de asignación\nA diferencia de s5fs, FFS intenta tener bien organizada la información sobre el disco, así como optimizar los accesos secuenciales a dicha información. FFS suministra un mayor control en la asignación de bloques de disco y nodos-i, así como en los directorios. Estas políticas de asignación utilizan el concepto de grupo de cilindros y requieren que el sistema de ficheros conozca varios parámetros asociados con el disco. A continuación se recogen las principales reglas de estas políticas de asignación:\nIntentar situar los nodos-i de todos los ficheros de un mismo directorio en el mismo grupo de cilindros. Muchos comandos (ls -l sería el mejor ejemplo) acceden a todos los nodos-i de un directorio en una rápida sucesión. Los usuarios tienden a exhibir una cierta localidad en sus accesos, trabajando sobre muchos ficheros en el mismo directorio (directorio de trabajo actual) antes de moverse a otro.\nCrear cada nuevo directorio en un grupo de cilindros diferente al de su directorio padre, para así conseguir una distribución homogénea de los datos sobre el disco. La rutina de asignación elige el nuevo grupo de cilindros de entre los grupos con un número de nodos-i libres superior a la media; de estos, selecciona aquel que posea el menor número de directorios.\nIntentar situar los bloques de datos de un fichero en el mismo grupo de cilindros que el nodo-i, porque típicamente el nodo-i y los datos serán accedidos conjuntamente.\nEvitar rellenar un grupo de cilindros entero con un fichero grande, cambiar el grupo de cilindros cuando el tamaño del fichero alcance los 48 Kbytes y de nuevo en cada megabyte. Este límite de 48 Kbytes fue elegido porque para un bloque de tamaño 4096 bytes, las entradas de bloques directos del nodo-i describen los primeros 48 Kbytes. En FFS el número de bloques directos en el array de direcciones fue incrementado de 10 a 12. La selección de un nuevo grupo de cilindros está basado en el número de bloques libres.Asignar bloques secuenciales de un fichero en posiciones óptimas rotacionalmente, si es posible. Cuando un fichero está siendo leído secuencialmente, hay un retardo de tiempo entre que la lectura de un bloque se completa y el núcleo procesa la terminación de la E/S e inicia la siguiente lectura. Puesto que el disco está girando durante este tiempo, uno o más sectores pueden haber pasado bajo la cabeza del disco. La optimización rotacional intenta determinar el número de sectores que se deben dejar pasar por debajo de la cabeza del disco hasta que el sector deseado esté bajo la cabeza del disco cuando se inicia la operación de lectura. A este número se le conoce como factor de entrelazado del disco.\nLa política de asignación utilizada por un sistema de ficheros FFS es muy efectiva cuando el disco tiene bastante espacio libre, pero se deteriora rápidamente si el disco está cerca del 90% de su capacidad. Cuando existen pocos bloques libres, es difícil encontrar bloques libres en localizaciones óptimas. Por lo tanto, FFS debe mantener una reserva de espacio, usualmente el 10% de la capacidad del disco. Sólo el superusuario puede asignar espacio de esta reserva.\n ## Mejoras en la funcionalidad de un sistema de ficheros FFS\nUna de las principales mejoras en la funcionalidad de un sistema de ficheros FFS con respecto a un sistema de ficheros s5fs es la posibilidad de usar nombres de ficheros largos. FFS cambió la estructura de los directorios para permitir que los nombres de ficheros fuesen mayores de 14 caracteres. Las entradas de un directorio FFS varían en longitud. La parte fija de la entrada consiste del número de nodo-i, el tamaño asignado y el tamaño del nombre del fichero en la entrada. Éste está seguido por un nombre de fichero terminado en un carácter nulo con espacio extra de 4 bytes. El tamaño máximo de un nombre de fichero es de 255 caracteres. Cuando se borra un nombre de fichero, FFS fusiona el espacio liberado con una entrada previa. Por lo tanto, el campo de tamaño asignado almacena el espacio total consumido por la parte variable de la entrada. El propio directorio está asignado en trozos de 512 bytes y ninguna entrada puede ocupar varios trozos. Finalmente para facilitar la escritura de código portable, la librería estándar añade un conjunto de rutinas de acceso a directorios que permiten el acceso independiente del sistema de ficheros a la información del directorio.\nOtras de las principales mejoras en la funcionalidad de un sistema de ficheros FFS es la implementación de enlaces simbólicos, los cuales solucionaban muchas de las limitaciones de los enlaces duros.Por otra parte BSD4.2 añadió una llamada al sistema rename para permitir el renombramiento atómico de ficheros y directorios, lo cual requería una llamada al sistema link seguida de una llamada unlink. Esto añadía un mecanismo de cuota para limitar los recursos disponibles del sistema de ficheros para cualquier usuario. Las cuotas se aplican tanto a los nodos-i como a los bloques de disco y tienen un límite suave que dispara un aviso, junto con un límite duro que el núcleo hace respetar.\nAlgunas de las mejoras comentadas han ido siendo incorporadas dentro de s5fs. En SVR4, s5fs permitía enlaces simbólicos y soporte atómico para renombrar un fichero. No obstante no soporta nombre de ficheros largos o cuotas de disco.\n ## Análisis\nEn general, FFS posee mayores ventajas que s5fs, lo que ha contribuido a su aceptación. De hecho, UNIX System V añadió en SVR4 a FFS como sistema de ficheros soportado. Por ejemplo, medidas realizadas en un VAX/750 mostraban que la productividad de lectura se incrementaba de 29 Kbytes/s en un s5fs (con bloques de 1 Kbyte) a 221 Kbytes/s en un FFS (con bloques de 4 Kbytes y fragmentos de 1 Kbyte). Además la utilización de la CPU se incrementaba de 11% a 43%. Con la misma configuración la productividad de escritura se incrementaba de 48 a 142 Kbytes/s y el uso de CPU de 29% a 43%.\nCon respecto al espacio desperdiciado en promedio en el disco, un sistema de ficheros s5fs desperdicia medio bloque por fichero. Mientras que un sistema FFS desperdicia medio fragmento por fichero. La ventaja de tener bloques grandes es que se requiere menos espacio para alojar todos los bloques de un fichero grande. Por lo tanto el sistema de ficheros requiere de menos bloques indirectos. En contraposición, se requiere más espacio para monitorizar los bloques libres y los fragmentos. Por lo tanto estos dos factores tienden a cancelarse por lo que el resultado neto de utilización del disco llega a ser prácticamente el mismo cuando el tamaño de un fragmento se iguala al de un bloque de s5fs. La reserva de espacio libre necesaria para FFS, no obstante, debe ser contabilizada como espacio desperdiciado, puesto que no está disponible para los ficheros de los usuarios. Cuando se contabiliza este factor, el porcentaje de espacio desperdiciado en un s5fs con bloques de 1 Kbyte se hace aproximadamente igual al de un FFS con bloques de 4 Kbytes y fragmentos de 512 bytes y reserva de espacio libre del 5 %.8.12 Características de algunos sistemas de archivos modernos\nEn la actualidad existe una gran variedad de sistemas de archivos en los sistemas UNIX, siendo los más representativos ext4 y sus predecesores ext2 y ext3, Btrfs, JFS, resiserFS, reiser 4, ZFZ o HAMMER.\nUn estudio en profundidad de cada uno de estos sistemas de archivos escapa de los objetivos de este libro, no obstante en este apartado se mostrarán las características más importantes que aportan estos nuevos sistemas de archivos sobre sus predecesores.\n ## Transacciones\nComo se vio en el apartado 8.9 la comprobación de un sistema de ficheros es una operación larga y compleja, además, en muchas ocasiones resulta imposible resolver satisfactoriamente los problemas que se presentan. Para facilitar la restauración del sistema de ficheros en caso de fallo algunos sistemas de ficheros modernos como por ejemplo ext3 o reiserFS implementan una técnica conocida como transacciones.\nLas transacciones consisten en tratar las escrituras como operaciones atómicas, de tal forma que una vez acabado el proceso o bien la escritura se ha completado o bien no se ha realizado ningún cambio en absoluto. De este modo se garantiza la consistencia del sistema de archivos cuando la operación de escritura se ve interrumpida por algún tipo de error como puede ser una caída de tensión.\nImplementar transacciones supone una sobrecarga para el sistema por lo que comúnmente sólo se protegen las estructuras más importantes del sistema de ficheros como son los directorios, descriptores de archivos y la cola de bloques libres.\n ###  Journaling\nEl Journaling o registro por diario consiste en mantener un diario con las operaciones escritura en el disco que utilizan los sistemas de archivos ext3, ext4, resiserFS y reiser 4.\nAntes de hacer una operación se bloquean las estructuras involucradas y se reservan uno o varios bloques de disco para albergar el diario donde se registra la operación a realizar.A continuación se realizan las distintas operaciones necesarias para llevar a cabo la escritura (copiar datos, modificar los metadatos como la fecha de modificación o el tamaño del archivo, asignar espacio modificando a su vez la lista de bloques libres, actualizar la lista de i-nodos si es necesario, etc..).\nAntes de hacer cada operación el sistema almacena en el diario la información necesaria para poder deshacerla y antes de pasar a la operación siguiente se asegura que la operación se ha completado.\nSi no se produce ningún fallo, al completarse la escritura el journal puede borrarse y las estructuras se desbloquean. En caso contrario la transacción se puede abortar en cualquier momento deshaciendo las operaciones parciales con la información que hay en el journal. De este modo se garantiza la atomicidad de la operación de escritura.\nDurante la operación de escritura puede producirse un fallo, como por ejemplo un corte de tensión, que haga detenerse el sistema. En ese caso cuando el sistema se reinicie e intente montar el sistema de ficheros comprobará en primer lugar si existe algún diario, y en caso afirmativo usará la información del mismo para deshacer la operación interrumpida y devolver el sistema de ficheros a un punto estable.\n ## Copy-on-write y snapshots\nUna técnica usada en los sistemas de archivos modernos como pueden ser Btrfs, ZFS y HAMMER consiste en mantener varias versiones de los mismos datos de tal modo que las versiones nuevas no sobrescriben a las antiguas.\nPara mantener varias versiones y al mismo tiempo aprovechar al máximo el espacio de almacenamiento se emplea la técnica copy-on-write, del siguiente modo:\nCuando una operación de escritura necesita modificar los datos que se encuentran en un bloque de archivo, el bloque no se modifica, en su lugar se reserva un bloque nuevo donde se copiaran los datos, de tal forma que el bloque que contiene los datos antiguos no se sobrescribe.\nPuesto que se ha creado un bloque de archivos nuevo que substituye al antiguo, los bloques de metadatos (por ejemplo los i-nodos que apuntaban al bloque antiguo) deberán ser modificados para reflejar el cambio, esto obliga a reubicarlos de la misma forma. De este modo las modificaciones se van propagando hasta llegar al superbloque.Si esto se hiciera con cada escritura en un archivo la sobrecarga del sistema sería enorme ya que una sola escritura obligaría a reubicar muchos bloques de datos e implicaría muchas escrituras en disco. Para evitar la sobrecarga las operaciones se agrupan en bloques de transacciones, dichas transacciones son tratadas un log o registro de transacciones de forma parecida a como hacen los sistemas con journaling.\nCuando se completa una transacción existen dos versiones completas distintas del sistema de archivos, una de las cuales apunta hacia los datos antiguos y la otra a los nuevos.\nEste sistema preserva dos versiones distintas de los archivos cambiados pero es eficiente en el uso de espacio ya que los bloques que no se modifican se comparten en ambas versiones. Esto permite crear instantáneas (snapshots) que registran el estado del sistema de archivos en un instante dado con un consumo mínimo de espacio y tiempo.\nCada bloque de datos tiene asociado un código de redundancia cíclica o un hash que permite verificar el contenido del bloque durante la lectura. En caso de que el sistema de archivos se corrompa o aparezca una inconsistencia es posible regresar en muy poco tiempo a una versión anterior de los datos y recuperar así la consistencia.\n ## Espacios de almacenamiento\nEn los sistemas de ficheros convencionales el sistema de ficheros se monta en el interior de una partición del disco, de este modo en cada disco físico puede haber varios discos lógicos cada uno de los cuales tiene su propio sistema de archivos.\nCuando se trabaja con grandes volúmenes de datos resulta interesante poder crear sistemas de archivos que utilicen más de un disco físico. Esto puede hacerse por medio de hardware dedicado de tal forma que se oculta al sistema operativo la existencia de los discos. En este caso el sistema operativo que solo ve un disco duro más grande, además dichos sistemas pueden implementar redundancia y capacidad de recuperación en caso de fallo. Sin embargo también es posible hacer lo mismo utilizando las características de los sistemas de archivos en UNIX.\nUna forma simple para crear un sistema de ficheros que utilize varios discos es utilizar el mecanismo de montaje de un sistema de ficheros que se describe en el apartado 8.4 sin embargo esta estructura almacenamiento es poco flexible. Supóngase que se tienen dos discos de 100GB uno de ellos alberga el sistema de ficheros raíz / y el otro se monta en el directorio /home/, el espacio de almacenamiento total es de 200Gb sin embargo el directorio /home/ solo puede albergar 100GB de archivos.\nUna forma más flexible de usar el almacenamiento es usar los espacios de almacenamiento o storage pools tal y como hace BRTF o ZFF. En este caso el sistema de archivos integra todo el espacio de almacenamiento disponible en una sola unidad de almacenamiento llamada espacio de almacenamiento o pool que permite albergar los datos.\nLa estructura del pool es mucho más flexible ya que en su interior pueden crearse varios sistemas de ficheros cuya única limitación es el espacio total disponible (por el contrario de lo que ocurre con las particiones en las cuales cada sistema de ficheros posee un espacio de almacenamiento fijo). Además es posible agregar nuevos dispositivos aumentando el espacio de almacenamiento.\nSupóngase que crea un pool con los mismos discos del ejemplo anterior, entonces se tendría un espacio de almacenamiento de 200Gb que se podría repartir arbitrariamente entre los distintos archivos y carpetas. Esto permitiría tener un archivo de 150GB en el directorio /home/ cosa que no era posible en el ejemplo anterior. Además, si se necesita espacio adicional podría añadirse otro disco de tal forma que la capacidad del sistema de archivos pasaría a ser de 300GB.\nGeneralmente los sistemas de archivos que usan pools poseen modelos de redundancia y replicación de datos (como por ejemplo RAID5 y RAID6) que permiten añadir y quitar discos o substituir los discos dañados sin necesidad de detener el funcionamiento de los mismos, característica muy importante en servidores de datos.\nAdemás también permiten distribuir la carga de trabajo entre los diferentes discos aumentando así la eficiencia en la lectura y escritura ya que es posible escribir y leer varios discos al mismo tiempo."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Resumen: ¿Qué hemos aprendido?",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": ". Un sistema de ficheros es una abstracción del almacenamiento que permite trabajar con la información sin necesidad de conocer los detalles de bajo nivel de los dispositivos. Los datos son tratados a nivel lógico, como una estructura de alto nivel organizada de forma jerárquica en archivos y directorios.En UNIX los dispositivos son tratados como archivos especiales, de este modo se puede acceder a un disco, un cdrom, o a la memoria de los procesos leyendo un archivo (/proc). Los archivos pueden ser de modo bloque (como los discos) o de modo carácter (como impresoras o terminales). El directorio /dev contiene todos los archivos de dispositivo.\nA cada archivo se asocia una estructura de datos llamada nodo-i que contiene la información necesaria para acceder al archivo (como por ejemplo la dirección de los bloques que contiene). A cada nodo-i se le asocia un número de nodo-i que permite identificar a un archivo. Cuando el archivo es un dispositivo el nodo-i contiene el número principal (que indica el tipo de dispositivo) y el número secundario que distingue a los dispositivos del mismo tipo. El sistema utiliza el número principal para seleccionar el driver adecuado para la operación de lectura o escritura.\nUn directorio es una estructura que permite organizar jerárquicamente el sistema de archivos. A nivel lógico un directorio es un contenedor de archivos o directorios. De este modo la estructura del sistema de archivos es un árbol que parte del directorio raíz /.\nDesde el punto de vista físico un directorio es un archivo especial que contiene una lista de nombres y números de nodo-i de los archivos contenidos en el mismo. Esto permite al sistema operativo realizar la conversión entre el nombre y el nodo-i correspondiente. El directorio contiene también el nodo-i de el mismo “.” y del directorio que lo contiene “..”\n2. Un disco físico es un dispositivo de modo bloque que almacena un array de bloques. El espacio de almacenamiento del disco puede dividirse en particiones mediante el comando fdisk. Cada partición es tratada como un disco lógico y en ella se puede crear un sistema de archivos con newfs o mkfs. La partición que almacena el arranque es la partición activa. La partición que almacena el área de intercambio es la partición swap.\nEn UNIX la estructura del sistema de archivos no es rígida sino que se construye sobre la marcha mediante un procedimiento de montaje. El proceso de montaje parte de un directorio raíz / y agrega los archivos que se encuentran en un disco lógico a la estructura de archivos general en un directorio llamado punto de montaje. Para ello se usa el comando mount.De forma automática, durante el arranque UNIX monta todos los sistemas de ficheros definidos en el archivo /etc/mtab.Sólo el superusuario puede modificar este archivo y en el mismo se definen los permisos de cada sistema de archivos y las operaciones que cada usuario puede realizar sobre él.\n3. En UNIX un mismo fichero puede tener varios nombres, cada uno de ellos se denomina enlace duro. Todos los enlaces duros apuntan al mismo nodo-i y dicho nodo-i tiene un contador de referencias. Cuando el contador de referencias es 0 el fichero puede borrarse.\nOtra forma de acceder a un fichero desde varios directorios es usar un enlace simbólico (link). El enlace simbólico contiene la ruta del fichero al que apunta. Como el enlace simbólico no contiene un enlace el nodo-i se pueden crear enlaces entre sistemas de ficheros distintos. El problema de los enlaces es que si el fichero se cambia de nombre o posición el enlace se rompe y deja de funcionar.\nPara crear enlaces se usa ln [–s] fichero enlace donde la opción –s establece que el enlace sea simbólico (en caso contrario es un enlace duro).\n4. El acceso al disco es muy lento comparado con la memoria principal, por ese motivo los sistemas de archivos utilizan la memoria principal como caché para acceso al disco a este mecanismo se llama caché de buffers de bloques.\nLa caché de buffers de bloques mantiene una estructura en memoria organizada en colas de dispersión doblemente enlazadas lo que hace rápida la búsqueda de los bloques. Cada entrada de la cola contiene una copia de los bloques de disco y un bit de control B_DELWRI que indica si el bloque está “sucio”. Cuando el sistema necesita leer un bloque busca el bloque primero en la cola de dispersión correspondiente y si no lo encuentra lo lee del disco y lo coloca en la cola.\nGeneralmente los programas modifican un disco más de una vez por lo que se implementa una post-escritura, esto significa que las modificaciones no se aplican inmediatamente al disco sino que se escribe en el buffer y se marca como “sucios”.\nEl núcleo mantiene una lista doblemente enlazada con los buffers libres y la utiliza para localizar buffers libres cuando necesita leer bloques de archivo nuevos. Cuando es necesario liberar espacio en la caché se buscan bloques limpios, si un bloque está “sucio”se pone en la cola de escritura del disco para actualizar el contenido en el disco antes de borrarlo de la caché.\nEl problema principal de la caché de buffers de bloques es la coherencia en el disco ya que si se cuelga el sistema o una unidad no se desmonta adecuadamente los bloques que estaban en memoria no se han actualizado en el disco. Además si se lee un archivo de gran tamaño secuencialmente y los bloques no se reutilizan puede vaciarse la caché lo que disminuye la eficiencia.\n5. La interfaz nodo-V/SVF es una interfaz estándar al sistema de ficheros que se introdujo en el System V y permite que el núcleo gestione de una forma idéntica varios sistemas de ficheros tanto locales como remotos de forma homogénea y modular. La interfaz define las operaciones a realizar en el sistema de archivos con independencia de la implementación concreta de las mismas.\nCuando se realiza una llamada al sistema que trabaja con ficheros el núcleo realiza las operaciones independientes del sistema de ficheros y luego invoca las funciones correspondientes en la interfaz nodo-V/SVF que se encarga de traducir cualquier operación del núcleo sobre un fichero (o sobre un sistema de ficheros) a la función adecuada según el tipo de sistema de ficheros.\nPara la construcción de la interfaz se utiliza el concepto de programación orientada a objetos, aunque el lenguaje C lo permite explícitamente por lo que los objetos se implementaban usando punteros a funciones.\nLa clase nodo-v abstrae el concepto de fichero abierto y contiene todas las operaciones que se realizan sobre él. Contiene una base nodo-v con todos los datos independientes de la implementación y un conjunto de funciones que se dividen en funciones virtuales (estructura de punteros a función). Las funciones virtuales son siempre las mismas, pero su implementación depende del sistema de ficheros en particular. También contiene un conjunto de rutinas de utilidad y macros que son específicas de cada sistema y pueden ser usadas por otros subsistemas del núcleo.\nLa clase svf representa al sistema de ficheros activo y hay uno por cada sistema de ficheros activo. Contiene los campos vfs_data y vfs_op donde la primera es independiente del sistema de ficheros y la segunda contiene los punteros a las funciones dependientes del sistema de ficheros.6. El sistema de ficheros s5fs se caracteriza por una estructura fija (área de arranque, superbloque, lista de nodos-i y bloques de datos). El área de arranque contiene el código que se ejecuta cuando se inicia el sistema. El superbloque alberga los metadatos del sistema de fichero (tamaño total, tamaño de los bloques, número de bloques libres, etc...) y la primera parte de la lista enlazada de bloques libres. La lista de nodos-i contiene todos los nodos-i del sistema de archivos mientras que los bloques de datos albergan los archivos.\nLos nodos-i se almacenan como una lista de indirección, las primeras 9 entradas de un nodo-i son directas (apuntan directamernte al bloque de datos) la siguiente es indirecta simple (apunta a un bloque que a su vez tiene punteros a bloques de datos) la siguiente indirecta doble (apunta a bloques que apuntan a bloques de punteros a bloques de datos) y la siguiente es indirecta triple (apunta a bloques que apuntan a bloques que a su vez apuntan a otros bloques que contienen punteros a los bloques de datos) .\nLos directorios son archivos que tienen una entrada 16 bytes por cada archivo que contienen el número de nodo-i de 2 bytes (lo que limita el sistema a 65535 ficheros por partición) y el nombre de 14 caracteres. El sistema de ficheros utiliza la caché de buffers de bloques y a cada copia del nodo-i que se encuentra en memoria se le llama nodo-im.\ns5fs es sencillo pero tiene algunos problemas. Primero están las limitaciones en el tamaño del sistema de ficheros y nombres, segundo que si se deteriora el superbloque se destruye el sistema de ficheros.\nAdemás el rendimiento no es demasiado bueno por que nodos-i están lejos de los datos de modo que al leer un archivo el cabezal de disco tiene que realizar muchos movimientos. Además la lista de bloques libres se rellena en un orden aleatorio por lo que la asignación de espacio no es óptima.\n7. UFS mejora s5fs en varios aspectos al tener en cuenta la geometría del disco en la asignación del espacio. Para ello, divide las particiones crean grupos de cilindros llamados consecutivos llamados exents e intenta escribir todos los datos relacionados en el mismo exent (como por ejemplo los nodos-i y los bloques de datos). Además para proteger el sistema de ficheros contiene varias copias del superbloque.\nPor otra parte los bloques se dividen en framgentos lo que hace que se puedan usar tamaños de bloque grandes sin desperdiciar mucho espacio. Cada archivo ocupa unconjunto de bloques completos y el resto se guarda en fragmentos consecutivos de otro bloque.\nAdemás UFS coloca los bloques consecutivos de datos en posiciones rotacionalmente óptimas, aumenta el tamaño del nombre de un archivo a 255 bytes e implementa por primera vez los enlaces simbólicos.\n8. Los sistemas de archivos modernos como ext4 , Btrfs, JFS, resiserFS, reiser 4, ZFZ o HAMMER. Tienen características mejoradas como es la implementación de transacciones para resolver los errores de lectura y escritura y mantener la coherencia del disco. Algunas implementacioes usan el registro por diario o journaling y otras la técnica copy-on-write. En el segundo caso es posible crear instantáneas (snapshots) del sistema de archivos con poco esfuerzo para restaurarlo a un punto anterior.\nAdemás, algunos sistemas de archivos permiten crear espacios de almacenamiento o pools que permiten utilizar varios discos y particiones como si se tratara de un único disco lógico. Esto permite flexibilizar el almacenamiento, implementar políticas de replicación como por ejemplo RAID5 o RAID6 y repartir la carga de trabajo entre varios discos aumentando el rendimiento."
}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué es un sistema de archivos?",
"responses":[                         "Un sistema de archivos es una abstracción del almacenamiento que permite trabajar con la información sin necesidad de conocer los detalles de bajo nivel de los dispositivos. Los datos son tratados a nivel lógico, como una estructura de alto nivel organizada de forma jerárquica en archivos y directorios.\n",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cómo se accede a los dispositivos en UNIX y que tipos de dispositivos hay?",
"responses":[                         "Los ficheros especiales o ficheros de dispositivos permiten a los procesos comunicarse con los dispositivos periféricos. Los dispositivos periféricos pueden ser de dos tipos: dispositivos modo bloque (discos, CD-ROM,...) y dispositivos modo carácter (terminales, impresoras, ratón...).\nLa manipulación de los dispositivos se realiza de la misma forma que si se escribiese en un archivo. Usualmente, en el directorio /dev se suelen almacenar todos los ficheros de dispositivos.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué es un nodo-i , que información contiene y para que sirve?",
"responses":[                         "Un archivo es una secuencia de datos relacionados. Aunque generalmente los archivos se acceden de forma secuencial, la colocación de los datos en el disco no lo es, por este motivo se utiliza un índice.\nUn nodo-i o nodo índice es una estructura de datos que contiene información administrativa, o metadatos del fichero, el elemento fundamental es el array de direcciones de bloques de datos di_addr (el índice), aunque también almacena el número de enlaces duros, el modo del ficheros, su tamaño, el número de generación y las fechas y horas del último acceso, modificación y modificación del nodo-i.\nCuando se trata de un archivo especial o de dispositivo el nodo-i contiene el número principal (que indica el tipo de dispositivo) y el número secundario que distingue a los dispositivos del mismo tipo. El sistema utiliza el número principal para seleccionar el driver adecuado para la operación de lectura o escritura.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿En qué consiste el proceso de montaje y para que sirve el fichero /etc/mtab?",
"responses":[                         "El proceso de montaje es el modo en el que se construye el sistema de archivos en UNIX a partir de varios sistemas de archivos que se encuentran en diferentes dispositivos o particiones. Se parte de un directorio raíz / y se agregan los archivos que se encuentran en un disco lógico a la estructura de archivos general en un directorio llamado punto de montaje (dir) . Para ello se usa el la llamada al sistema mount.\nresultado = mount(dispositivo,dir,flags); O elcomando mount :\nmount dispositivo dir\nEl argumento flags es una máscara de bits que permite especificar diferentes\nopciones, resultado vale 0 si el montaje es correcto y -1 en caso contrario.\nDe forma automática, durante el arranque UNIX monta todos los sistemas de ficheros definidos en el archivo /etc/mtab.Sólo el superusuario puede modificar este archivo y en el mismo se definen los permisos de cada sistema de archivos y las operaciones que cada usuario puede realizar sobre él.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cómo se desmonta un sistema de archivos?",
"responses":[                         "La función complementaria a la llamada a sistema mount es la llamada al sistema umount :\numount(dispositivo);\nO en forma de comando umount dispositivo",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué diferencia hay entre enlaces duros y simbólicos?",
"responses":[                         "Un enlace duro es cada uno de los nombres que puede tener un fichero en UNIX. Todos los enlaces duros apuntan al mismo nodo-i .\nUn enlace simbólico (link) es un archivo cuyo contenido es la ruta del fichero al que apunta.La diferencia entre enlaces duros y simbólicos es que el enlace duro no es un archivo (solo es una entrada en el directorio correspondiente) mientras que el simbólico si lo es. Además al borrar un enlace duro no se modifica el archivo original mientras que cuando se borra el último enlace duro el fichero también se borra.\nAdemás como el enlace simbólico no contiene un enlace el nodo-i se pueden hacer enlaces entre sistemas de ficheros distintos. El problema de los enlaces es que si el fichero se cambia de nombre o posición el enlace se rompe y deja de funcionar.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué es un directorio y para que sirve?",
"responses":[                         "Un directorio es una estructura que permite organizar jerárquicamente el sistema de archivos. A nivel lógico un directorio es un contenedor de archivos o directorios. De este modo la estructura del sistema de archivos es un árbol que parte del directorio raíz /\nDesde el punto de vista físico un directorio es un archivo especial que contiene una lista de nombres y números de nodo-i de los archivos contenidos en el mismo. Esto permite al sistema operativo realizar la conversión entre el nombre y el nodo-i correspondiente. El directorio contiene también el nodo-i de él mismo “.” y del directorio que lo contiene “..”",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué es la estructura vnodeops de la clase nodo-v?",
"responses":[                         "vnodeops, es una estructura de punteros a las funciones que implementan el interfaz\nvirtual del nodo-v que es aputnada por el campo v_op de la estructura nodo-v.\nCuando el código independiente del sistema de ficheros llama a una función virtual para un nodo-v arbitrario, el núcleo usando el puntero v_op llama a la función correspondiente de la implementación del sistema de ficheros adecuada. De este modo se separan las operaciones del nucleo y la implementación del sistema de ficheros.\nEsta estructura se inicializa cuando se abre el archivo con la llamada al sistema open o creat.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué es la caché de buffers de bloques? ¿ y la caché de nombres de ruta?",
"responses":[                         "El acceso al disco es muy lento comparado con la memoria principal, por ese motivo los sistemas de archivos utilizan la memoria principal como caché para acceso al disco a este mecanismo se llama caché de buffers de bloques.La caché de buffers de bloques mantiene una estructura en memoria organizada en colas de dispersión doblemente enlazadas lo que hace rápida la búsqueda de los bloques. Cada entrada de la cola contiene una copia de los bloques de disco y un bit de control B_DELWRI que indica si el bloque está “sucio”. Cuando el sistema necesita leer un bloque busca el bloque primero en la cola de dispersión correspondiente y si no lo encuentra lo lee de la memoria principal y lo coloca en la cola.\nLas escrituras se aceleran mediante una política de post-escritura, aplicando las modificaciones en el disco cuando es necesario liberar el buffer y no antes.\nLa caché de búsqueda de nombres en directorios es un recurso global del núcleo disponible para todos los sistemas de ficheros que deseen utilizarlo. Se trata de una caché software LRU de objetos que contienen: un puntero al nodo-v de un directorio, el nombre de un fichero en este directorio, y un puntero al nodo-v de dicho fichero.\nSi un sistema de ficheros desea utilizar la caché de búsqueda de nombres en directorios, su función de búsqueda, es decir aquella que implementa la operación VOP_LOOKUP, primero busca el nombre deseado en la caché, si lo encuentra se ahorra las lecturas correspondientes del disco.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cuándo se borra un fichero?",
"responses":[                         "El campo v_count del nodo-v mantiene un contador de referencias que determina hasta cuándo el nodo-v debe permanecer en el núcleo. Un nodo-v es alojado y asignado a un fichero cuando el fichero es accedido por primera vez. Por lo tanto, otros objetos pueden mantener punteros, o referencias, a este nodo-v y esperar para acceder al nodo-v usando el puntero. Esto significa que si esta referencia existe, el núcleo debe retener el nodo-v y no reasignarlo a otro fichero.\nEl contador de referencias asegura la persistencia del nodo-v y también del fichero que subyace. Cuando un proceso borra un fichero que otro proceso (o quizás el mismo proceso) había abierto, el fichero no se borra físicamente. La entrada del directorio de dicho fichero es eliminada, así que nadie más puede abrirlo usando el nombre borrado. El fichero en sí mismo continúa existiendo puesto que el nodo-v tiene un contador de referencias distinto de cero. Los procesos que actualmente tenían el fichero abierto pueden continuar accediendo a él hasta que lo cierren.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cuántos bloques de disco hay que leer para obtener la dirección de un bloque con\n                    indirección triple?",
"responses":[                         "Una indirección triple significa que el nodo-i tiene un puntero a un bloque de indirección triple que a su vez apunta a otro bloque de indirección doble, éste que a su vez apunta a otro bloque de indirección simple que contiene el puntero al bloque de datos.\nDe este modo para obtener la dirección del bloque de datos hay que leer el nodo índice y tres bloques de indirección. Esto supone un total de 4 lecturas en el disco en el peor de los casos. (En general no es necesario leer cuatro veces del disco ya que si la lectura es secuencial es muy probable que los bloques se encuentren cargados en la caché de buffers de bloques).",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿qué es el superbloque y para qué sirve?",
"responses":[                         "El superbloque es un bloque esencial en un sistema de ficheros ya que contiene los metadatos del mismo. El núcleo lee el superbloque cuando monta el sistema de ficheros y lo almacena en memoria hasta que el sistema de ficheros es desmontado. El superbloque contiene básicamente información administrativa y estadística del sistema de archivos, como por ejemplo el tamaño en bloques del sistema de ficherosy de la lista de nodos-i tamaño en bloques de la lista de nodos-i, número de bloques libres y nodos-i libres, comienzo de la lista de bloques libres y lista parcial de nodos-i libres.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿para qué sirve la función independiente del sistema de ficheros lookuppn?",
"responses":[                         "Los ficheros son accedidos a través de su nombre de ruta, sin embargo para manipularlos el sistema operativo necesita conocer el nodo-v del fichero. El proceso de traducción de nombres de ruta es llevado a cabo por la función lookuppn.\nCuando se invoca lookuppn también establece una referencia sobre este nodo-v.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"Enumere las operaciones realizadas por la rutina VFS_MOUNT",
"responses":[                         "VFS_MOUNT es la rutina dependiente del sistema de ficheros encargada de realizar el montado del mismo. Esta función debe realizar las siguientes operaciones:\n- Verificar permisos para la operación.- Asignar e inicializar el objeto de datos privados del sistema de ficheros.\n- Almacenar un puntero a este objeto en el campo vfs_data del objeto sfv.\n- Acceder al directorio raíz del sistema de ficheros e inicializar su nodo-v en memoria. La única forma de que el núcleo acceda a la raíz de un sistema de ficheros montado es mediante la operación VFS_ROOT. La parte de sfv dependiente del sistema de ficheros debe mantener la información necesaria para localizar el directorio raíz.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿qué mejoras aporta FFS sobre s5fs?",
"responses":[                         "FFS tiene en cuenta la geometría del disco en la asignación del espacio. Para ello divide las particiones, crean grupos de cilindros llamados consecutivos llamados exents e intenta escribir todos los datos relacionados en el mismo exent (como por ejemplo los nodos-i y los bloques de datos).\nComo los i-nodos se encuentran cerca de los bloques de datos el cabezal de lectura realiza movimientos pequeños al leer un archivo. Además UFS coloca los bloques consecutivos de datos en posiciones rotacionalmente óptimas lo que hace que las lecturas secuenciales sean muy eficientes.\nPor otra parte los bloques se dividen en fragmentos lo que hace que se puedan usar tamaños de bloque grandes sin desperdiciar espacio.\nPara proteger el sistema de ficheros contiene varias copias del superbloque.\nUFS también aumenta el tamaño del nombre de un archivo respecto a s5fs e implementa por primera vez los enlaces simbólicos.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿por qué hizo falta crear la interfaz nodo-v/svf?",
"responses":[                         "Sun Microsystems introdujo la interfaz nodo-v/sfv (nodo virtual/sistema de ficheros virtual) para suministrar un marco de trabajo en el núcleo que permitiera el acceso y la manipulación de diferentes tipos de sistemas de ficheros.\nEl objetivo fundamental era separar las tareas del núcleo que eran independientes del sistema de ficheros de aquellas que dependen de una implementación concreta. Esto permite que UNIX Soporte diferentes tipos de sistemas de ficheros localessimultáneamente, utilice sistemas de ficheros distribuidos, mantenga una estructura homogénea en el árbol de directorios y sea fácil de extender añadiendo implementaciones de sistemas de ficheros nuevos.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿qué es un sistema de ficheros transaccional?",
"responses":[                         "Un sistema de ficheros es transacional si utiliza transacciones para implementar las operaciones en el disco. Al menos con las estructuras más importantes como los nodos- i y los directorios.\nLas transacciones consisten en tratar las escrituras como operaciones atómicas, de tal forma que una vez acabado el proceso o bien la escritura se ha completado o bien no se ha realizado ningún cambio en absoluto.\nDe este modo se garantiza la consistencia del sistema de archivos cuando la operación de escritura se ve interrumpida por algún tipo de error como puede ser una caída de tensión.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿qué diferencia existe entre una copia de seguridad y un snapshot en un sistemaque implementa copy-on-write?",
"responses":[                         "Una instantánea o snapshot es una imagen del sistema de archivos en un instante dado, en ese aspecto es parecida a una copia de seguridad en tanto en cuanto es posible restaurar los archivos a su estado anterior en caso de necesidad.\nCuando se usa la técnica copy-on-write la creación de una instantánea es muy rápida y ocupa espacio a medida que los archivos van cambiando, mientras que la copia de seguridad lleva bastante tiempo y suele requerir más espacio. Lo mismo ocurre con la recuperación ya que para volver a un estado anterior del sistema de ficheros basta con montar una instantánea mientras que con la copia de seguridad hay que copiar todos los archivos.\nNo obstante las instantáneas en un sistema con copy-on-write residen en el mismo disco físico que los datos a copiar de modo que si se daña el disco los datos se pierden. Esto no ocurre en las copias de seguridad que normalmente se realizan en un medio de almacenamiento independiente.",
null,
null,
null
],
"correctAnswer":1              } ,"code_url":null, "content":""}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "GESTIÓN DE ENTRADA/SALIDA EN UNIX ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "- Qué es la entrada/salida y como se gestiona.\n- Para que sirven las interrupciones de dispositivo.\n- Cuál es el cometido de un driver.\n- Cómo se organiza el subsistema de entradas y salidas.\n- Cómo los procesos se comunican con los drivers a través de Un streams.\nEl subsistema de entrada/salida de UNIX se encarga de la transferencia de datos entre la memoria principal y los dispositivos periféricos (discos duros, impresoras, terminales,...). El núcleo interactúa con estos dispositivos mediante los drivers de dispositivos. Un driver controla uno o más dispositivos y es la única interfaz existente entre el dispositivo y el resto del núcleo. Esta separación permite ocultar al núcleo las complejidades del hardware de cada dispositivo. Así el núcleo puede acceder al dispositivo usando una interfaz consistente y de funcionamiento simple.\nEn este capítulo en primer lugar se realizan unas consideraciones generales sobre la entrada/salida en UNIX. En segundo lugar se describen los drivers de dispositivos. En tercer lugar se analiza la implementación del subsistema de entrada/salida de UNIX. El capítulo finaliza con una introducción a los STREAMS que suministran, entre otras muchas funcionalidades, una aproximación modular a la escritura de drivers de dispositivos."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Consideraciones generales",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "n driver de dispositivo es una parte del núcleo que consiste en una colección de estructuras de datos y funciones que controlan a uno o más dispositivos, e interactúa con el resto del núcleo mediante una interfaz bien definida. El driver es el único módulo del núcleo que puede interactuar con el dispositivo y no interactúa con otros drivers. Suele estar escrito por el fabricante del dispositivo. El núcleo puede acceder al driver mediante una interfaz de pequeño tamaño pero bien definida. Muchas son las ventajas de usar esta aproximación:- Es posible aislar el código especifico de cada dispositivo en módulos separados.\n- Es fácil añadir nuevos dispositivos.\n- Los fabricantes pueden añadir dispositivos a una computadora sin el código fuente del núcleo.\n- El núcleo dispone de una vista consistente de todos los dispositivos y accede a todos ellos mediante la misma interfaz.\nLa AQUÍ VA UNA IMAGEN9-1 ilustra el papel del driver de un dispositivo. Las aplicaciones de usuario se comunican con los dispositivos periféricos a través del núcleo, usando la interfaz de las llamadas al sistema. El subsistema de entrada/salida del núcleo trata estas peticiones. Y utiliza la interfaz del driver de dispositivo para comunicarse con los dispositivos.\nProcesos de usuarios\nP P P P P P\n  Interfaz de llamadas al sistema\nNúcleo\n Subsistema de E/S\n Interfaz de drivers de dispositivos\n   Driver de Driver de Driver de terminales discos cintas\nAQUÍ VA UNA IMAGEN9-1: Papel de un driver de dispositivo\nCada capa tiene un entorno y unas responsabilidades bien definidas. Las aplicaciones de usuario no necesitan conocer si se están comunicando con un dispositivo o con un fichero ordinario. Un programa que escribe datos en un fichero debería ser capaz de escribir el mismo dato en un terminal o en una impresora sin tener que ser modificado o recompilado. Por lo tanto, el sistema operativo suministra una vista de alto nivel consistente de todo el hardware de la máquina a los procesos de usuarios.\nEl núcleo delega todas las operaciones con los dispositivos al subsistema de E/S, que es responsable de realizar todos el procesamiento independiente del dispositivo. El subsistema de E/S desconoce las características de cada dispositivo individual. Consideraa los dispositivos como abstracciones de alto nivel manipuladas por la interfaz del driver de dispositivo y se encarga de tareas tales como el control de acceso, el almacenamiento temporal de datos y la identificación de los dispositivos.\nEl driver es responsable de toda la interacción, propiamente dicha, con el dispositivo. Cada driver maneja a uno o varios dispositivos de características similares. Por ejemplo, un driver de un disco duro puede manejar varios discos duros de características similares. Únicamente conoce las características del hardware del dispositivo tales como, el número de sectores, pistas y cabezas de lectura.\nEl driver acepta ordenes del subsistema de E/S a través de la interfaz del driver del dispositivo. También recibe mensajes de control procedentes del dispositivo, los cuales incluyen la terminación de una operación, el estado del dispositivo y las notificaciones de errores. El dispositivo consigue la atención del driver mediante la generación de una interrupción. Cada driver tiene asociado un manipulador de interrupciones, que el núcleo invoca cuando recibe la interrupción apropiada.\n ## Configuración del hardware\nLos drivers de dispositivos son, por naturaleza, extremadamente dependientes del hardware. La estructura del driver tiene en cuenta como la CPU interactúa con el dispositivo. En la AQUÍ VA UNA IMAGEN9-2 se esquematiza la configuración del hardware de un sistema típico.\nBUS\nAQUÍ VA UNA IMAGEN9-2: Configuración del hardware de un sistema típico\nEl bus del sistema es un canal de comunicación al que están conectados la CPU, a través de la MMU y los controladores de los dispositivos.\n CPU\n MMU\n     Dispositivo 1\n Dispositivo 4\n  Dispositivo 3\n   Dispositivo 2\nDispositivo 5\nControlador 3 Controlador 2\nControlador 1\nSe puede considerar que un dispositivo está compuesto de dos componentes: una parte electrónica, que es denominada controlador o adaptador; y una parte mecánica, que es el propio dispositivo. El controlador es normalmente un circuito impreso en una tarjeta que se conecta a la computadora y al bus. Una computadora de sobremesa típica tendrá un controlador de disco, una tarjeta gráfica, una tarjeta de E/S y posiblemente una tarjeta de red.\nCada controlador puede tener conectados uno o más dispositivos, que suelen ser del mismo tipo, aunque no tiene porque ser necesariamente así. Por ejemplo, un controlador SCSI (Small Computer Systems Interface) puede controlar discos duros, disqueteras, unidades de CD-ROM y unidades de cinta.\nEl controlador tiene un conjunto de registros de control y de estado (RCE) para cada dispositivo. Cada dispositivo puede tener uno o varios RCE y sus funciones son completamente dependientes del dispositivo. El driver escribe en los RCE para mandar órdenes a los dispositivos y los lee para conocer el estado del dispositivo o la aparición de algún error. Estos registros son bastante diferentes de otros registros de propósito general. Escribir directamente en un registro de control genera una acción sobre el dispositivo, como por ejemplo iniciar una operación de E/S con un disco. Leer un registro de estado puede tener diferentes efectos, como por ejemplo, limpiar el registro. Por lo tanto, el driver no obtiene los mismos resultados si lee un registro de dispositivo dos veces seguidas. Por el contrario, si intenta leer un registro que acaba de ser escrito, el valor leído puede ser bastante diferente del valor escrito.\nEl espacio de E/S de una computadora incluye el conjunto de todos los registros de dispositivo, así como buffers para almacenamiento temporal de datos. Cada registro tiene una dirección bien definida en el espacio de E/S. Estas direcciones son usualmente asignadas cuando se arranca la máquina, usando un conjunto de parámetros especificados en un fichero de configuración utilizado para montar el sistema. El sistema podría asignar un rango de direcciones a cada controlador que a su vez podría asignar espacio para cada dispositivo que controla.\nExiste dos formas de configurar el espacio de E/S en un sistema. En algunas arquitecturas como la Intel 80x86, el espacio de E/S está separado del espacio de memoria principal y es accedido por instrucciones de E/S especiales. A esta configuración se le denomina E/S aislada de memoria. En otras arquitecturas como Motorola 680x0, se utiliza una configuración denominada E/S localizada en memoria, que consiste en reservar unconjunto del espacio de direcciones de memoria para el espacio de E/S, de esta forma se usan instrucciones de acceso a memoria ordinarias para escribir y leer en los registros.\nAsimismo, existen dos formas de transferir datos entre el núcleo y el dispositivo. El método utilizado depende del propio dispositivo. Es posible clasificar a los dispositivos en dos categorías en función del método de transferencia de datos utilizado:\n- Dispositivos de E/S controlada por programa. Requieren que la CPU se encargue de la transferencia de datos byte a byte. Cuando el dispositivo está listo para enviar o recibir el siguiente byte, activa una interrupción. Ejemplos típicos de este tipo de dispositivos son los modems y las impresoras en línea.\n- Dispositivos con acceso directo a memoria (DMA). El núcleo puede dar la localización (fuente y destino) del dato en memoria, la cantidad de datos a transferir y otras informaciones relevantes. El dispositivo completará la transferencia accediendo directamente a memoria, sin la intervención de la CPU. Cuando la transferencia está completa, el dispositivo interrumpe a la CPU para indicarle que ya se encuentra listo para realizar la siguiente operación. Ejemplos típicos de este tipo de dispositivos son los discos.\n ## Interrupciones asociadas a los dispositivos\nLos dispositivos utilizan interrupciones para conseguir la atención de la CPU. La manipulación de las interrupciones es altamente dependiente de la máquina, aunque es posible dar una serie de principios generales. Muchos sistemas UNIX definen un conjunto de niveles de prioridad de interrupción (npi). El número de npis soportado es diferente para cada sistema. El npi más bajo es cero; de hecho, todo el código de usuario y la mayoría del código normal del núcleo se ejecuta a npi 0. El npi más alto depende de cada implementación. Algunos valores bastante comunes son 6, 7, 15 y 31. Si llega una interrupción con un npi menor que el npi actual, la interrupción es bloqueada hasta que el npi del sistema se reduzca a un nivel inferior al npi de la interrupción pendiente. De esta forma el sistema establece una prioridad a la hora de atender las interrupciones.\nCada dispositivo interrumpe siempre con un mismo npi; usualmente, todos los dispositivos conectados a un mismo controlador tienen el mismo npi. Cuando el núcleo trata una interrupción, primero conAQUÍ VA UNA IMAGENel npi del sistema al valor del npi de la interrupción, para así bloquear las posibles interrupciones adicionales de ese dispositivo, así como las de otros con un npi inferior. Además, algunas rutinas del núcleo elevan el npitemporalmente para bloquear ciertas interrupciones. Por ejemplo, la rutina que manipula las colas de dispersión de la caché de buffers de bloques de disco eleva el npi para bloquear las interrupciones del disco. Ya que de otra forma, una interrupción del disco podría ocurrir mientras la cola se encuentra en un estado inconsistente, confundiendo por tanto al driver del disco.\nEl núcleo utiliza un conjunto de rutinas para manipular el npi. Por ejemplo, spltty() eleva el npi hasta el npi asignado a la interrupción de un terminal. La rutina splx() disminuye el npi al valor de npi anteriormente almacenado. Estas rutinas son usualmente implementadas como macros por motivos de eficiencia.\nUsualmente todas las interrupciones invocan a una rutina común en el núcleo y le pasan alguna información que identifica a dicha interrupción. Esta rutina salva el contexto a nivel de registros, eleva el npi del sistema al mismo npi que el de la interrupción e invoca al manipulador de la interrupción. Cuando el manipulador finaliza, se restaura el npi al valor que tenía anteriormente y se restaura el contexto del proceso.\nEn un sistema con interrupciones vectorizadas, cada dispositivo suministra al núcleo un número único denominado número del vector de interrupción que se utiliza como un índice en una tabla, denominada tabla de vectores de interrupción. Cada entrada de esta tabla es un vector de interrupción, que contiene, entre otras informaciones, un puntero al manejador o rutina de servicio de la interrupción apropiada.\nEl tratamiento de las interrupciones es una de las tareas más importantes del sistema, por ello un manipulador se ejecuta preferentemente a cualquier proceso de usuario o del sistema. Puesto que el manipulador interrumpe todas las otras actividades (excepto las interrupciones de mayor npi al suyo), debe ser extremadamente rápido. La mayoría de las implementaciones de UNIX no permiten que los manipuladores duerman. Si un manipulador necesita un recurso que podría estar retenido, debe intentar adquirirlo de un modo no bloqueante.\nEstas consideraciones influyen el trabajo que el manipulador debe hacer. En primer lugar, su código debe ser de pequeño y rápido de ejecutar, en consecuencia debe hacer lo mínimo posible. Por otra parte, debe asegurarse que el dispositivo no se encuentra ocioso en una situación de carga pesada. Por ejemplo, cuando una operación de E/S se completa, el disco interrumpe al sistema. El manipulador debe notificar al núcleo los resultados de la operación. También debe iniciar la siguiente operación de E/S si existía alguna peticiónpendiente. En caso contrario, el disco permanecería ocioso hasta que el núcleo recuperara el control y comenzase la siguiente petición.\nAunque estos mecanismos son comunes en un gran número de distribuciones de UNIX, distan mucho de ser universales. Solaris 2.x, por ejemplo, va más allá del uso de npi (salvo en un número pequeño de casos) y utiliza hebras para tratar las interrupciones. Asimismo, permite que estas hebras se bloqueen si fuera necesario."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Drivers de dispositivos",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "## Clasificación de los dispositivos y de los drivers\nEl subsistema de E/S gestiona la parte independiente del dispositivo de todas las operaciones de E/S. Requiere una vista de alto nivel del funcionamiento de los dispositivos. Desde esta perspectiva, un dispositivo es una caja negra que soporta un conjunto estándar de operaciones. Cada dispositivo implementa estas operaciones de forma diferente, pero el subsistema de E/S no es consciente de ello. En términos de programación orientada a objetos, la interfaz del driver forma una clase base abstracta, cada driver es una subclase o implementación especifica de la clase base. En la práctica, una única interfaz no es apropiada para todos los dispositivos, puesto que varían bastante en cuanto al método de acceso y funcionalidad. Así, UNIX divide a los dispositivos en dispositivos modo bloque y dispositivos modo carácter. Existiendo una interfaz para cada uno.\nEn los dispositivos modo bloque, el dispositivo contiene un array de bloques de tamaño fijo (generalmente un múltiplo de 512 bytes). La transferencia de datos entre el dispositivo y el núcleo, o viceversa, se realiza a través de un espacio en la memoria principal denominado caché de buffers de bloques que es gestionado por el núcleo. Esta caché está implementada por software y no debe confundirse con las memorias caché hardware que poseen muchas c(omputadoras. El uso de esta caché permite regular el flujo de datos lográndose así un incremento en la velocidad de transferencia de los datos. Ejemplos típicos de dispositivos modo bloque son los discos y las unidades de cinta.\nLos dispositivos modo carácter son aquellos dispositivos que no utilizan un espacio intermedio de almacenamiento en memoria principal para regular el flujo de datos con el núcleo. En consecuencia las transferencias de datos se van a realizar a menor velocidad. Ejemplos típicos de dispositivos modo carácter son los terminales serie y las impresoras en línea. En los ficheros de dispositivos modo carácter la información no se organiza según una estructura concreta y es vista por el núcleo o por el usuario, como una secuencia lineal de bytes.No todos los dispositivos caen claramente en una de estas dos categorías. En UNIX, cada dispositivo que no tiene las propiedades de un dispositivo modo bloque es clasificado como de modo carácter. Algunos dispositivos no tienen ninguna E/S en absoluto. El reloj del hardware, por ejemplo, es un dispositivo cuyo trabajo es simplemente interrumpir a la CPU a intervalos de tiempo fijos, típicamente 100 veces por segundo.\nUn driver no tiene porque controlar un dispositivo físico. Es posible simplemente usar la interfaz del driver para suministrar una funcionalidad especial. El driver men, por ejemplo, permite a los usuarios leer o escribir en posiciones de memoria principal. El dispositivo null es un sumidero de bits, es decir, solamente deja escribir y simplemente se deshace de todos los datos que se escriben en él. A tales dispositivos se les denomina pseudodispositivos.\nLa mayoría de las distribuciones UNIX modernas soportan una tercera clase de drivers, denominados drivers STREAMS que típicamente controlan las interfaces de red y los terminales. En las distribuciones UNIX clásicas estos elementos eran controlados con drivers de carácter. Por motivos de compatibilidad la interfaz de los drivers STREAMS se deriva de la de los drivers de carácter.\n ## Invocación del código del driver\nEl núcleo puede invocar a un driver de dispositivo por varios motivos:\n- Configuración. El núcleo llama al driver cuando se arranca el sistema para comprobar e inicializar el dispositivo.\n- Entrada/Salida. El subsistema de E/S llama al driver para escribir o leer datos.\n- Control. El usuario puede hacer peticiones de control tales como la apertura o cierre\nde un dispositivo o el rebobinado de una cinta magnética.\n- Interrupciones. El dispositivo genera interrupciones una vez que se ha completado una operación de E/S o se produce algún cambio en el estado del dispositivo.\nLas funciones de configuración son llamadas una única vez, cuando el sistema arranca. La funciones de entrada/salida y control son operaciones síncronas. Son invocadas en respuesta a peticiones de usuario especificas y se ejecutan en el contexto del proceso invocador. La rutina d_strategy del driver de modo bloque es una excepcióna esta norma. Las interrupciones son eventos asíncronos, el núcleo no puede predecir cuando ocurrirán y se ejecutan en el contexto de cualquier proceso.\nEsto sugiere dividir el driver en dos partes:\n- Parte superior del driver. Contiene las rutinas síncronas. Se ejecutan en el contexto del proceso. Pueden acceder al espacio de direcciones y al área U del proceso invocador y pueden poner al proceso a dormir si fuese necesario\n- Parte inferior del driver. Contiene las rutinas asíncronas. Se ejecutan en el contexto del sistema y usualmente no tienen ninguna relación con el proceso actualmente en ejecución y en consecuencia no pueden acceder al espacio de direcciones de dicho proceso o a su área U. Además, no pueden poner a dormir a ningún proceso puesto que podrían bloquear a un proceso no relacionado.\nLas dos partes del driver necesitan sincronizar sus actividades. Si un objeto es accedido por ambas partes, entonces las rutinas de la parte superior deben bloquear las interrupciones (mediante la elevación del npi) mientras manipulan el objeto. En caso contrario, el dispositivo podría interrumpir mientras el objeto se encuentra en un estado inconsistente, con lo que el resultado sería impredecible.\n ## Los conmutadores de dispositivos\nUn conmutador de dispositivo es una estructura de datos que define puntos de entrada para cada dispositivo que debe soportar. Existen dos tipos de conmutadores: struct bdevsw para dispositivos modo bloque y struct cdevsw para dispositivos modo carácter. Su definición típica es la siguient:\n   struct bdevsw{int (*d_open)();\n     int (*d_close)();\n     int (*d_strategy)();\n     int (*d_size)();\n     int (*d_xhalt)();\n...\n    } bdevsw[];\n    struct cdevsw{int (*d_open)();\n     int (*d_close)();     int (*d_read)();\n     int (*d_write)();\n     int (*d_ioctl)();\n     int (*d_mmap)();\n     int (*d_segmap)();\n     int (*d_xpoll)();\n     int (*d_xhalt)();\n     struct streamtab* d_str;\n...\n} cdevsw[];\nEl núcleo mantiene un array separado para cada tipo de conmutador, cada driver de dispositivo tiene una entrada en el array apropiado. Si un driver suministra una interfaz modo bloque y otra modo carácter, dispondrá de una entrada en cada array.\nEl conmutador define la interfaz abstracta. Cada driver suministra la implementación especifica de estas funciones. Cuando el núcleo desea realizar una acción sobre un dispositivo, localiza el driver en la tabla de conmutadores e invoca la función apropiada del driver. Por ejemplo, para leer datos desde un dispositivo de modo carácter, el núcleo invoca la función d_read() del dispositivo. En el caso del driver de un terminal, éste referenciaría a una rutina llamada ttread().\nLos drivers de dispositivos siguen una convención estándar para nombrar a las funciones del conmutador. Cada driver utiliza una abreviatura de dos letras para describirse a si mismo. Ésta es un prefijo para cada una de sus funciones. Por ejemplo, el driver de disco utiliza el prefijo dk y nombra a sus rutinas como dkopen(), dkclose(), dkstrategy() y dksize().\nUn driver puede no soportar todos los puntos de entrada. Por ejemplo, una impresora en línea no permite normalmente leer. Para ese punto de entrada, el driver puede usar la rutina global nodev(), que simplemente retorna el código de error ENODEV. Para algunos puntos de entrada, el driver puede desear no tener ninguna acción. Por ejemplo, muchos dispositivos no suministran ninguna acción especial cuando su cerrados. En dicho caso, el driver puede usar la rutina global nulldev(), que simplemente devuelve el valor 0 (que indica éxito).\nComo se ha mencionado con anterioridad, los drivers STREAMS son nominalmente tratados y accedidos como drivers de dispositivo modo carácter. Se identifican con elcampo d_str, que vale NULL para los drivers de dispositivos de modo carácter ordinarios. Para un driver STREAMS, este campo apunta a la estructura streamtab, que contiene punteros a funciones y datos específicos del STREAMS.\n ## Puntos de entrada de un driver\nA continuación se describen las funciones de dispositivo accedidas a través del conmutador de dispositivo:\n- d_open(). Se invoca cada vez que el dispositivo es abierto y puede traer dispositivos en línea o inicializar estructuras de datos. Los dispositivos que requieren acceso exclusivo (tales como impresoras o unidades de cinta) pueden activar un indicador cuando son abiertos y desactivar dicho indicador cuando son cerrados. Si el indicador ya se encuentra activado, d_open()puede bloquearse o fallar. Es común tanto a los dispositivos modo bloque como modo carácter.\n- d_close(). Se invoca cuando se libera la última referencia al dispositivo, es decir, cuando ningún proceso tiene este dispositivo abierto. Puede apagar el dispositivo o dejarlo fuera de línea. Un driver de una unidad de cinta puede rebobinar la cinta. Es común tanto a los dispositivos modo bloque como modo carácter.\n- d_strategy(). Punto de entrada común para peticiones de lectura o escritura a un dispositivo modo bloque. Se llama así ya que el driver puede usar alguna estrategia para reordenar las peticiones pendientes con objeto de optimizar el rendimiento del dispositivo. Opera asíncronamente, si el dispositivo está ocupado esta rutina simplemente coloca en una cola la petición y retorna. Cuando la operación de E/S se completa, el manipulador de la interrupción quitará de la cola la siguiente petición e iniciará la siguiente operación de E/S.\n- d_size(). Es utilizado por los discos para determinar el tamaño de una partición.\n- d_read(). Lee datos de un dispositivo modo carácter.\n- d_write(). Escribe datos en un dispositivo modo carácter.\n- d_ioctl(). Punto de entrada genérico para operaciones de control sobre un dispositivo modo carácter. Cada driver puede definir un conjunto de comandos e invocarlos mediante la interfaz ioctl. Los argumentos de esta función incluyen cmd,un entero que especifica que comando ejecutar; y arg un puntero a un conjunto de argumentos específicos del comando. Se trata de un punto de entrada bastante versátil que soporta operaciones arbitrarias sobre el dispositivo.\n- d_segmap(). Traduce la memoria del dispositivo en una dirección del espacio de direcciones del proceso. Es utilizado por dispositivos modo carácter traductores de memoria para configurar la traducción en respuesta a la llamada al sistema mmap.\n- d_mmap(). No es utilizado si se suministra la rutina d_segmap(). Si d_segmap es NULL, la llamada al sistema mmap sobre un dispositivo modo carácter invoca a spec_segmap(), que cuando retorna llama a d_mmap(). Comprueba si el desplazamiento en el dispositivo es válido y devuelve la dirección virtual correspondiente.\n- d_xpoll(). Encuesta al dispositivo para comprobar si ha ocurrido algún evento de interés. Puede ser usado para comprobar si un dispositivo está listo para leer o escribir sin bloquearlo, si ha ocurrido alguna condición de error, etc.\n- d_xhalt(). Apaga el dispositivo controlado por el driver. Es invocado durante el apagado del sistema o cuando se descarga un driver desde el núcleo.\n- Salvo d_xhalt() y d_strategy(), todas las demás son rutinas de la parte superior del driver.\n- Los puntos de entrada de un driver para manipulación de interrupciones e inicialización no suelen accederse a través de la tabla del conmutador. De hecho, son especificados en un fichero de configuración maestro, que es usado para construir el núcleo. Este fichero contiene una entrada por cada controlador y driver. La entrada también contiene información como por ejemplo el npi, el número del vector de interrupción y la dirección base de los RCE para el driver. Los contenidos específicos y el formato de este fichero son diferentes para cada distribución de UNIX.\n- SVR4 define dos rutinas de inicialización para cada driver: init y start. Cada driver registra estas rutinas en los arrays io_init[] y io_start[], respectivamente. El código de arranque del sistema invoca todas las funciones init antes de inicializar el núcleo y todas las funciones start después de que el núcleo es inicializado."
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "El subsistema de entrada/Salida",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": "l subsistema de E/S es la porción del núcleo que controla la parte independiente del dispositivo de las operaciones de E/S e interactúa con los drivers de dispositivos para tratar la parte dependiente del dispositivo. Es también responsable de nombrar y proteger a los dispositivos. Además se encarga de suministrar a las aplicaciones de usuario una interfaz consistente para todos los dispositivos.\n ## Número principal y número secundario de un dispositivo\nEl espacio de nombres de dispositivos describe cuantos dispositivos diferentes son identificados y referenciados. El espacio de nombres del hardware identifica a los dispositivos por el controlador al que se encuentra conectados y el número lógico de dicho controlador. El núcleo utiliza un esquema numérico para nombrar a los dispositivos. Los usuarios requieren un espacio de nombre simple y familiar y utilizan las rutas de acceso de los sistemas de ficheros con este propósito. El subsistema de E/S define la semántica de los espacios de nombres del núcleo y del usuario, además realiza la traducción entre ellos.\nEl núcleo identifica cada dispositivo mediante el tipo de dispositivo (bloque o carácter), más un par de números denominados número principal (mayor number) y número secundario (minor number) del dispositivo. El número principal del dispositivo identifica el tipo de dispositivo, o más específicamente, el driver. El número secundario del dispositivo identifica la instancia especifica del dispositivo.\nPor ejemplo, todos los discos duros pueden tener un número principal igual a 5 y cada disco duro existente tendrá un número secundario diferente. Por otra parte, los dispositivos de modo bloque y los dispositivos de modo carácter tienen conjuntos independientes de números principales. Así un número principal igual a 5 para dispositivos en modo bloque puede referirse a una unidad de disco, mientras que para dispositivos de modo carácter puede referirse a una impresora en línea.\nEl número principal es el índice de dicho driver en la tabla de conmutación apropiada. En el ejemplo anterior, si el núcleo desea invocar una operación open de un driver de disco, localiza la entrada número 5 de bdevsw[] y llama a su función d_open[]. Normalmente, los números principal y secundario son combinados dentro de una misma variable de tipo dev_t. Los bits más significativos contienen el número principal, mientras que los bits menos significativos contienen el número secundario. Las macros getmajor() y getminor() permiten extraer estos números de la variable donde están almacenados.El núcleo pasa el número de dispositivo como un argumento de la rutina d_open() del driver. El driver del dispositivo mantiene varias tablas internas para traducir el número secundario a un RCE especifico o a un número de puerto del controlador. Extrae el número secundario de dev_t y lo utiliza para acceder al dispositivo correcto.\nUn mismo driver puede ser configurado con varios números principales. Esto resulta útil si el driver gestiona diferentes tipos de dispositivos que realizan algún procesamiento común. Asimismo, un mismo dispositivo puede ser representado por varios números secundarios. Por ejemplo, una unidad de cinta puede usar un número secundario para seleccionar un modo de autorebobinado y otro para un modo de no-rebobinado. Finalmente, si un dispositivo tiene tanto una interfaz de modo bloque como de modo carácter, utilizará entradas distintas en ambas tablas de conmutación con números principales distintos para acceder a cada una.\nEn las primeras distribuciones de UNIX, dev_t tenía un campo de 16 bits, con 8 bits para el número principal y 8 bits para el número secundario. Esto imponía un límite de 256 números secundarios por cada número principal, lo cual resultaba demasiado restrictivo para algunos sistemas. Para evitar esto, los drivers utilizaban varios números principales.\nOtro problema es que las tablas de conmutación pueden hacerse de un tamaño muy grande si contienen entradas por cada dispositivo posible, incluyendo aquellos que no están conectados al sistema o aquellos cuyos drivers no están enlazados al núcleo. Esto sucedía porque los fabricantes no deseaban ajustar la tabla de conmutación para cada configuración diferente que fabricaban y tendían a colocar toda la información posible en las tablas de conmutación.\nSVR4 realizó varios cambios para resolver este problema. El tipo dev_t fue aumentado a 32 bits, normalmente divido en 14 bits para un número principal y 18 para un número secundario. También introdujo la noción de números de dispositivos externos e internos. Los números de dispositivos internos identifican al driver y sirven como índice dentro de la tabla de conmutación. Los números de dispositivos externos forman la representación de un dispositivo visible para el usuario. y son almacenados en el campo i_rdev del nodo-i de un fichero especial de dispositivo.\nEn muchos sistemas, como por ejemplo Intel x86, los números externos e internos son idénticos. En otros que soportan autoconfiguración, como AT&T 3B2, estos números son distintos. En estos sistemas, bdevsw[] y cdevsw[] son construidos dinámicamentecuando el sistema arranca y sólo contienen entradas para los drivers que están configurados en el sistema. El núcleo mantiene un array llamado MAJOR[], el cual es indexado mediante el número principal externo. Cada elemento de este array almacena el número principal interno correspondiente.\n ## Ficheros de dispositivos\nEl par <número principal, número secundario> proporciona al núcleo un espacio de nombres de dispositivo simple y efectivo. A nivel de usuario, sin embargo, es bastante inútil, ya que los usuarios no desean recordar un par de números por cada dispositivo. Además, los usuarios desean usar las mismas aplicaciones y comandos para leer y escribir tanto ficheros ordinarios como dispositivos. La solución natural es usar el espacio de nombres del sistema de ficheros para describir tanto a los ficheros ordinarios como a los dispositivos.\nUNIX suministra una interfaz consistente a los ficheros y a los dispositivos a través de la introducción de la noción de fichero de dispositivo. Este es un fichero especial localizado en cualquier parte del sistema de ficheros y asociado con un dispositivo especifico. Por convención, todos los ficheros de dispositivos son mantenidos en el directorio /dev o en un subdirectorio del mismo.\nDesde el punto de vista de un usuario, un fichero de dispositivo no es muy diferente de un fichero ordinario. No tiene bloques de datos en el disco pero tiene un nodo-i permanente en el sistema de ficheros en el cual está localizado (normalmente, el sistema de ficheros raiz). El campo di_mode del nodo-i muestra de que tipo es cada uno: IFBLK (para dispositivos modo bloque) o IFCHR (para dispositivos modo carácter). En vez de la lista de números de bloques, el nodo-i contiene un campo llamado di_rdev que almacena los números principal y secundario del dispositivo al que representa. Esto permite al núcleo traducir el nombre del fichero a nivel de usuario (ruta de acceso del fichero) al nombre interno del dispositivo (el par <número principal, número secundario>).\nUn fichero de dispositivo no se puede crear de la forma usual. Sólo el superusuario puede crear un fichero de dispositivo usando la llamada al sistema\nmknod(path, mode, dev)\ndonde path es la ruta de acceso del fichero especial, mode especifica el tipo de\nfichero (IFBLK o IFCHR) y los permisos. Dev es el número que combina el número principaly el número secundario. Esta llamada al sistema crea un fichero especial e inicializa los campos di_mode y di_rdev a partir de los argumentos.\nUnificar los espacios de nombres de ficheros y dispositivos tienen grandes ventajas. La E/S con los dispositivos utilizan el mismo conjunto de llamadas al sistema que la E/S con un fichero. Así los programadores pueden escribir aplicaciones sin preocuparse sobre si la entrada y la salida es sobre un dispositivo o sobre un fichero. Los usuarios ven una vista consistente del sistema y pueden usar cadenas de caracteres descriptivas como nombres para referenciar a los ficheros.\nOtro beneficio importante es el control de acceso y la protección. Cada fichero de dispositivo tiene asignados los permisos estándar de lectura/escritura/ejecución para el propietario, el grupo y otros usuarios. Estos permisos son inicializados y modificados de la forma usual, tal y como se hace en los ficheros. Típicamente, algunos dispositivos tales como los discos son directamente accesibles únicamente por el superusuario, mientras que otros como las unidades de cinta puede ser accedidas por todos los usuarios.\n ## El sistema de ficheros specfs\nCómo se estudio en el Capítulo 8 UNIX dispone de la interfaz nodo-v/sfv que permite tener diferentes tipos de sistemas de ficheros en el mismo núcleo. Esta aproximación asocia un objeto del núcleo denominado nodo-v con cada fichero abierto. La interfaz define un conjunto de operaciones abstractas en cada nodo-v. Cada sistema de ficheros suministra su propia implementación de estas funciones. Por ejemplo, el nodo-v de fichero de un sistema ufs apunta a un vector llamado ufsops que contiene punteros a las funciones del sistema ufs tales como ufslookup(), ufsclose() y ufslink().\nEs necesario una forma especial de tratar los ficheros de dispositivos. Un fichero de dispositivo reside en el sistema de ficheros raíz el cual, para el propósito de la siguiente discusión, se va a considerar que es un sistema ufs. Por tanto su nodo-v es un nodo-v ufs y apunta a ufsops. Cualquier operación sobre este fichero será tratado mediante las funciones del sistema ufs.\nEsta forma de proceder, no obstante, no es la más correcta. El fichero de dispositivo no es un fichero ordinario, sino un fichero especial que representa un dispositivo. Todas las operaciones en el fichero deben ser implementadas mediante la correspondiente acción sobre el dispositivo, usualmente a través del conmutador de dispositivos. Por lo tanto, senecesita una forma de traducir todos los accesos del fichero de dispositivo al dispositivo que subyace.\nSVR4 utiliza un tipo de sistema de ficheros especial llamado specfs. Implementa todas las operaciones a los nodos-v buscando en el conmutador de dispositivo e invocando a la función apropiada. El nodo-v spefcs tiene una estructura de datos privada llamada nodo-s (de hecho, el nodo-v es parte del nodo-s). El término nodo-s viene de node shadow (nodo ensombrecido). El subsistema de E/S debe asegurarse que, cuando un usuario abre un fichero de dispositivo, adquiere una referencia al nodo-v specfs y que todas las operaciones sobre el fichero son encaminadas hacia él.Supóngase que un usuario desea abrir el fichero del fichero /dev/lp. El directorio /dev se encuentra en el sistema de ficheros raíz, que se supone que es del tipo ufs. La llamada al sistema open traduce la ruta de acceso usando repetidamente la rutina ufs_lookup(), en primer lugar localiza el nodo-v del directorio dev. Después el nodo-v de lp. Cuando ufs_lookup()obtiene el nodo-v para lp, descubre que el tipo de fichero es IFCHR. Entonces, extrae del nodo-i los números principal y secundario del dispositivo y se los pasa a la rutina llamada specvp().\nEl sistema de ficheros specfs mantiene todos los nodos-s en una tabla de dispersión, indexada por los números de dispositivos. specvp() busca en la tabla de dispersión y sino encuentra el nodo-s, crea un nuevo nodo-s y un nuevo nodo-v.\nEl nodo-s tiene un campo llamado s_realvp, en el cual specvp() almacena un puntero al nodo- v de /dev/lp. Finalmente, devuelve un puntero al nodo-v specfs. El nodo-v specfs oculta el nodo-v de /dev/lp y su campo v_op apunta al vector de las operaciones specfs (como por ejemplo spec_read() y spec_write()), que a su vuelta llama a los puntos de entrada del dispositivo. En la AQUÍ VA UNA IMAGEN9-3 se ilustra la configuración resultante.\n       Tabla de descriptores de ficheros en el área U\nstruct file\nnodo–v de\n/dev/lp\nsepc_vnops[]ufs_vnodeops[]f_vnode\nstruct snode\nv_op\n  v_rdev v_op\n   AQUÍ VA UNA IMAGEN9-3: Estructuras de datos después de abrir /dev/lp\ns_realvp\nAntes de retornar, open invoca la operación VOP_OPEN sobre el nodo-v, la cual llama a spec_open() en el caso de un fichero de dispositivo. La función spec_open() llama a la rutina d_open() del driver, la cual realiza los pasos necesarios para abrir el dispositivo.\n ## El nodo-s común\nEl sistema specfs tal y como se ha descrito hasta ahora está bastante incompleto y dista de ser correcto. Se ha supuesto una relación uno a uno entre los ficheros de dispositivos y los dispositivos que subyacen. En la práctica, es posible tener varios ficheros de dispositivos, cada uno representando al mismo dispositivo (sus campos di_rdev tendrán el mismo valor). Estos ficheros pueden estar en el mismo o en diferentes sistemas de ficheros.\nEsto crea varios problemas. La operación de dispositivo close, por ejemplo, debe ser invocada solamente cuando el último descriptor del dispositivo es cerrado. Supóngase que dos procesos abren el dispositivo usando diferentes ficheros de dispositivo. El núcleo debería ser capaz de reconocer esta situación y llamar a la operación close del dispositivo solamente después de que ambos ficheros sean cerrados.\nOtro problema está relacionado al direccionamiento de páginas. En SVR4, el nombre de una página en memoria está definido mediante el nodo-v que pertenece a la página y el desplazamiento de la página en el fichero.\nPara una página asociada con un dispositivo, el nombre es ambiguo si múltiples ficheros se refieren al mismo dispositivo. Dos procesos accediendo al dispositivo a través de diferentes ficheros de dispositivo podrían crear dos copias de la misma página en memoria, produciendo un problema de consistencia de datos.\nCuando se tienen varios nombres de ficheros para un mismo dispositivo, se pueden clasificar las operaciones sobre el dispositivo en dos grupos. La mayoría de las operaciones son independientes del nombre del fichero utilizado para acceder al dispositivo. Así pueden ser canalizadas a través de un objeto común. Al mismo tiempo, existen unas pocas operaciones que dependen del fichero utilizado para acceder al dispositivo. Por ejemplo, cada fichero puede tener un propietario y unos permisos diferentes; por lo tanto, es importante mantener la pista del nodo-v “real” (el del fichero del dispositivo) y encaminar todas las operaciones hacia él.\nTema 9: Gestión de Entrada/Salida en UNIX   struct file\nstruct file\n Tabla de descriptores de ficheros del proceso A\nstruct snode\nTabla de descriptores de ficheros del proceso B\nstruct snode\n  s_commonvp\n   s_realvp\n  f_vnode\n   spec_vnops[]          ufs_vnodeops[]nodo–v de\n/dev/lp1\ns5_vnodeops[]NULL\nnodo–v de\n/dev/lp2\n  AQUÍ VA UNA IMAGEN9-4: El nodo-s común\nstruct snode\nnodo-s común\nEl sistema de ficheros specfs utiliza la noción de nodo-s común para permitir ambos tipos de operaciones. La AQUÍ VA UNA IMAGEN9-4 describe las estructuras de datos. Cada dispositivo tiene solamente un nodo-s común, creado cuando se accede al dispositivo por primera vez. Existen también un nodo- s por cada fichero de dispositivo. Los nodos-s de todos los ficheros representando al mismo dispositivo comparten el nodo-s común y referencian a él a través del campo s_commonvp.\nLa primera vez que un usuario abre un fichero de dispositivo para un dispositivo en particular, el núcleo crea un nodo-s y un nodo-s común. Posteriormente, si otro usuario abre el mismo fichero, compartirá estos objetos. Si un usuario abre otro fichero que representa al mismo dispositivo, el núcleo creará un nuevo nodo-s, que referenciará al nodo-s común a través del campo s_commonvp. El nodo-s común no está directamente asociado con un fichero de dispositivo; por lo tanto, su campo s_realvp es NULL. Su campo s_commonvp apuntará a si mismo.\nf_vnode\n  v_op\ns_commonvp\n s_realvp\nv_op\n  v_rdev v_op\nv_rdev v_op\n v_op\ns_commonvp\n s_realvp"
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Streams ",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content":""
}
},
{

"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "document",
"name": "Resumen: ¿Qué hemos aprendido?",
"properties":
{"card": {"back": null, "front": null},"quiz": {"question": null, "responses": [null, null, null, null], "correctAnswer": 0},"code_url":null,
"content": ". El subsistema de entrada/salida de UNIX se encarga de la transferencia de datos entre la memoria principal y los dispositivos periféricos. UNIX ofrece un conjunto estándar de operaciones de entrada/salida, pero cada dispositivo funciona de una forma distinta y requiere un código específico para comunicarse con él.\nPara que el diseñador núcleo no tenga que conocer todos los detalles de cada uno de los periféricos existentes (lo cuál sería prácticamente imposible) se divide el problema de entrada/salida en dos partes.\nUna parte es llevada a cabo por núcleo se denomina Subsistema de E/S y realiza todas las operaciones independientes del dispositivo. La otra parte está formada por los drivers del dispositivo. Un driver es un programa (típicamente creado por el fabricante del hardware) que proporciona las funciones básicas para trabajar con él.\nPara que el núcleo interactúe correctamente con los drivers existe una interfaz estándar de drivers de dispositivo que cada driver debe implementar y cada driver es un módulo independiente que se enlaza al núcleo.\n2. La forma en la que el procesador se comunica con los dispositivos es a través del bus. El dispositivo se conecta al bus a través de un dispositivo electrónico denominado controlador o adaptador.\nLa entrada salida puede ser controlada por programa o bien hacer uso del acceso directo a memoria. En el primer caso esde readsdsafdfasdfsdfasf la CPU la que se encarga de ir recogiendo los datos del controlador y ponerlos en la memoria. En el segundo caso la CPU envía una señal al controlador indicando dónde debe colocar los datos del dispositivo, éste manipula directamente la memoria y cuando acaba produce una señal de interrupción para que la CPU detecte el fin de la operación de E/S.\nComo hay varios dispositivos que pueden producir interrupciones UNIX establece un conjunto de niveles de prioridad de interrupción (npi). Las interrupciones se atienden de acuerdo a su prioridad de modo que si el npi del sistema es inferior npi de la interrupción que llega no se detiene el trabajo en curso y se deja para más tarde.Cada interrupción tiene un código numérico llamado número del vector de interrupción, el núcleo utiliza este número para buscar en una tabla de vectores de interrupción el vector de interrupción que apunta a la rutina adecuada.\n3. Los dispositivos se dividen en dispositivos modo bloque (que leen bloques de datos y los gestionan por medio de la caché de buffers de bloque del núcleo) , dispositivos modo carácter (que son más lentos al no existir un espacio intermedio de almacenamiento) y streams (que deriva de los drivers de carácter). Existiendo una interfaz distinta para cada uno.\n4. Un conmutador de dispositivo es una estructura de datos que define puntos de entrada para cada dispositivo que debe soportar. Existen dos tipos de conmutadores: struct bdevsw para dispositivos modo bloque y struct cdevsw para dispositivos modo carácter. Las operaciones básicas que implemenrtan los drivers en el conmutador del dispositivo són:\nd_open() y d_close() para iniciar y cerrar el dispositivo, y d_xhalt() para apagarlo. Cuando se trata de un dispositivo de modo bloque se usa d_strategy() para leer y escribir, d_size() para determinar el tamaño de una partición de disco, d_segmap() para traducir la memoria del dispositivo en una dirección del espacio de direcciones del proceso o d_mmap() (Si no se suministra la rutina d_segmap()). Cuando se está en modo bloque se usa d_read() y d_write()para leer, d_ioctl() como punto de entrada genérico para operaciones de control y d_xpoll() para encuestar al dispositivo en busca de eventos.\n5. El subsistema de E/S es la parte del núcleo que gestiona la parte independiente del dispositivo de la E/S apoyándose en los drivers y se encarga de identificar los dispositivos mediante el número principal (que especifica el tipo y por tanto el driver) y el secundario que identifica la instancia, ambos se conminan en la variable dev_t.\nEl acceso a los dispositivos se realiza a través del sistema de archivos de modo que a cada dispositivo se le hace corresponder un archivo especial creado con mknod y situado en el directorio /dev, en el nodo-i correspondiente se encuentran los números principal y secundario.\nLos dispositivos son tratados por la interfaz del sistema de ficheros nodo-v/svf como un sistema de ficheros especial denominado specfs. En la práctica, es posible tener variosficheros de dispositivos, cada uno representando al mismo dispositivo por lo que se usa la noción de nodo-s común. La primera vez que un usuario abre un fichero de dispositivo para un dispositivo en particular, el núcleo crea un nodo-s y un nodo-s común que apunta al anterior. Si un usuario abre otro fichero que representa al mismo dispositivo, el núcleo creará un nuevo nodo-s, que referenciará al mismo nodo-s común.\n6. En las versiones de UNIX modernas se usa el concepto de streams para mejorar la interfaz de los drivers, en especial las de modo carácter y los dispositivos de red y se usan además para implementar los ficheros FIFO, tuberías y los conectores (sockets) para el trabajo en red.\nUn stream es un procesamiento full-duplex y un camino de transferencia de datos entre un driver en el espacio del núcleo y un proceso en el espacio de usuario. El stream estructura de forma modular y en cada módulo hay una cola de lectura y otra de escritura. Los streams utilizan el paso de mensajes como único mecanismo de comunicación.\nAdemás los streams pueden multiplexarse, lo que significa que un driver de multiplexión puede conectar múltiples streams en lo alto o en lo bajo, esto ocurre por ejemplo si se implementa TCP/IP con streams. En este caso un mismo stream IP puede interactuar a la vez con varios drivers de bajo nivel en la capa física y con varios drivers TCP para cada conexión."
}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Por qué los drivers son una parte separada del núcleo de UNIX?",
"responses":[                         "Cada hardware necesita un código específico que permita controlarlo, la separación entre el subsistema de E/S y el driver permite que los fabricantes de dispositivos puedan fabricar drivers para los misos sin necesidad de que el diseñador núcleo tenga que conocer todos los detalles de cada uno de los periféricos existentes.\nAdemás, utilizar drivers hace que la utilización del hardware sea más sencilla ya que la interfaz estándar de drivers del núcleo permite gestionar la entrada/salida de forma ordenada y modular y hace más sencillo agregar dispositivos nuevos."
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué tipos de dispositivos considera UNIX?",
"responses":[                         "Esencialmente UNIX separa los dispositivos en dispositivos modo bloque (que leen bloques de datos y los gestionan por medio de la caché de buffers de bloque del núcleo) y dispositivos modo carácter (que son más lentos al no existir un espacio intermedio de almacenamiento). El sistema mantiene dos conmutadores de dispositivos: bdevsw para dispositivos modo bloque y cdevsw para dispositivos modo carácter cuya interfaz debe implementar cada tipo de driver.\n"
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué es un controlador de dispositivo y para qué sirve?",
"responses":[                         "Cada dispositivo físico (disco, cinta, tarjeta de red, etc) necesita un dispositivo electrónico denominado controlador o adaptador que conecte al dispositivo con el bus del sistema. El sistema operativo se comunica con el dispositivo a través del driver que a su vez envía órdenes al controlador para manejar el dispositivo.\n"
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Cuándo puede el núcleo invocar a un driver?",
"responses":[                         "El núcleo puede invocar a un driver de dispositivo por varios motivos:\n- Configuración. El núcleo llama al driver cuando se arranca el sistema para comprobar e inicializar el dispositivo.\n- Entrada/Salida. El subsistema de E/S llama al driver para escribir o leer datos.-\n- Control. El usuario puede hacer peticiones de control tales como la apertura o cierre de un dispositivo o el rebobinado de una cinta magnética.\nInterrupciones. El dispositivo genera interrupciones una vez que se ha completado una operación de E/S o se produce algún cambio en el estado del dispositivo."
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué operación implementa la entrada d_strategy() de un driver de modo\n                    bloque?",
"responses":[                         "d_strategy() es el punto de entrada común para peticiones de lectura o escritura a un dispositivo modo bloque, es el equivalente a d_read() y d_write() en modo carácter.\nSe llama así ya que el driver puede usar alguna estrategia para reordenar las peticiones pendientes con objeto de optimizar el rendimiento del dispositivo (por ejemplo leer los bloques del disco en orden rotacionalmente óptimo).\nd_strategy() opera asíncronamente, si el dispositivo está ocupado esta rutina simplemente coloca en una cola la petición y retorna. Cuando la operación de E/S se completa, el manipulador de la interrupción quitará de la cola la siguiente petición e iniciará la siguiente operación de E/S."
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿qué es un pseudodispositivo?",
"responses":[                         "Un pseudodispositivo es un driver que proporciona una funcionalidad especial sin controlar un verdadero dispositivo físico.\nEjemplos de pseudodispositivos son el driver mem, que permite a los usuarios leer o escribir en posiciones de memoria principal (típicamente usada en los depuradores) y el dispositivo null que es un sumidero de bits que absorbe todos los datos de entrada y no hace nada con ellos."
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿En qué partes se suele dividir un driver?",
"responses":[                         "El driver se suele dividir en dos partes:- Parte superior del driver. Contiene las rutinas síncronas. Se ejecutan en el contexto del proceso. Pueden acceder al espacio de direcciones y al área U del proceso invocador y pueden poner al proceso a dormir si fuese necesario\n- Parte inferior del driver. Contiene las rutinas asíncronas. Se ejecutan en el contexto del sistema y usualmente no tienen ninguna relación con el proceso actualmente en ejecución y en consecuencia no pueden acceder al espacio de direcciones de dicho proceso o a su área U. Además, no pueden poner a dormir a ningún proceso puesto que podrían bloquear a un proceso no relacionado."
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿De qué se encarga el Subsistema de E/S?",
"responses":[                         "El subsistema de E/S es la parte del núcleo que gestiona la parte independiente del dispositivo de la E/S apoyándose en los drivers. Se encarga de: Identificar los dispositivos mediante el número principal (que especifica el tipo y por tanto el driver) y el secundario que identifica la instancia, ambos se conminan en la variable dev_t.\nEl acceso a los dispositivos se realiza a través del sistema de archivos de modo que a cada dispositivo se le hace corresponder un archivo especial creado con mknod y situado en el directorio /dev, en el nodo-i correspondiente se encuentran los números principal y secundario."
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿De forma sabe el núcleo que driver usar con un determinado dispositivo?",
"responses":[                         "El número principal y el secundario se combinan en la variable dev_t que se encuentran en el nodo-i del archivo especial del dispositivo.\nLos bits más significativos contienen el número principal, mientras que los bits menos significativos contienen el número secundario. Las macros getmajor() y getminor() permiten extraer estos números de la variable donde están almacenados.\nPuesto que el número principal es el que identifica el driver el núcleo usa getmajor()para obtener el identificador del driver que hay que usar para acceder al dispositivo."
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué diferencia hay entre un archivo común y un archivo de dispositivo?",
"responses":[                         "El acceso a los dispositivos se realiza a través del sistema de archivos de modo que a cada dispositivo se le hace corresponder un archivo especial.\nLos dispositivos son tratados por la interfaz del sistema de ficheros nodo-v/svf como un sistema de ficheros especial denominado specfs .\nLas diferencias fundamentales frente a un archivo ordinario es que los archivos de dispositivo sólo pueden ser creados por el superusuario usando mknod y se encuentran situados en el directorio /dev.\nAdemás el nodo-i del dispositivo no contiene una lista de bloques y atributos del archivo sino los números principal y secundario que identifican al dispositivo y al driver que maneja el mismo."
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿qué es un nodo-s común?",
"responses":[                         "Un nodo-s común es un mecanismo para asignar a cada dispositivo un nodo-s que centralice todas las operaciones sobre el mismo.\nDado que es posible tener varios ficheros de dispositivos, cada uno representando al mismo dispositivo existirán varios nodos-s que corresponden al mismo dispositivo, para coordinar todas las operaciones sobre el dispositivo se utiliza un nodo-s común.\nLa primera vez que un usuario abre un fichero de dispositivo para un dispositivo en particular, el núcleo crea un nodo-s y un nodo-s común asociado. Si un usuario abre otro fichero que representa al mismo dispositivo, el núcleo creará un nuevo nodo-s, que referenciará al mismo nodo-s común."
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Para qué sirven los streams?",
"responses":[                         "Un stream es un procesamiento full-duplex y un camino de transferencia de datos entre un driver en el espacio del núcleo y un proceso en el espacio de usuario. El stream estructura de forma modular y en cada módulo hay una cola de lectura y otra de escritura.\nEn las versiones de UNIX modernas se usa el concepto de streams para mejorar la interfaz de los drivers, en especial las de modo carácter y los dispositivos de red y se usan además para implementar los ficheros FIFO, tuberías y los conectores (sockets) para el trabajo en red."
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz": {
"question":"¿Qué mecanismos de comunicación usan los streams?",
"responses":[                         "Los streams utilizan el paso de mensajes como único mecanismo de comunicación.\n"
],
"correctAnswer":1              }, "code_url":null, "content":""}
},
{"course_id": 1,
"points": 0,
"chapter_id": null,
"type": "quiz",
"name": "Autoevaluación. Comprueba lo que has aprendido",
"properties": {"card": {"back": null, "front": null},"quiz":
{
"question":"Qué significa que un stream esté multiplexado?",
"responses":[                         "Los streams soportan una funcionalidad llamada multiplexión. Un driver de multiplexión puede conectar múltiples streams en lo alto o en lo bajo. Hay tres tipos de multiplexores:\n- Multiplexor superior o fan-in. Puede conectar a varios streams sobre él.\n- Multiplexor inferior o fan-out, Puede conectar múltiples streams por debajo de él.\n- Multiplexor de doble-sentido. Soporta múltiples conexiones tanto por encima como por debajo de él."
],
"correctAnswer":1              },"code_url":null, "content":""}
}


]
